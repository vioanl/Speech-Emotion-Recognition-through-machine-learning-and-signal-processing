{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import soundfile as sf\n",
    "import os\n",
    "import errno\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need a function to remove dead space from audio files\n",
    "# Checks a rolling average of signal over 1/10 sec and compares to threshold\n",
    "# Returns a mask of True and False values that can be used to filter audio signals\n",
    "\n",
    "def envelope(y, sr, threshold):\n",
    "    mask = []\n",
    "    y_abs = pd.Series(y).apply(np.abs)\n",
    "    y_mean = y_abs.rolling(window = int(sr/10), min_periods = 1, center = True).mean()\n",
    "    for mean in y_mean:\n",
    "        if mean > threshold:\n",
    "            mask.append(True)\n",
    "        else:\n",
    "            mask.append(False)\n",
    "    return np.array(y[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "savee_file_list = glob.glob('/Users/ioann/saveelist/*.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_files(file_list):\n",
    "    count = 0\n",
    "\n",
    "    for file in file_list:\n",
    "        y, sr = librosa.load(file)\n",
    "        y = envelope(y, sr, 0.0005)\n",
    "        save_file = 'clean/' + file\n",
    "        \n",
    "        if not os.path.exists(os.path.dirname(save_file)):\n",
    "            try:\n",
    "                os.makedirs(os.path.dirname(save_file))\n",
    "            except OSError as exc: # Guard against race condition\n",
    "                if exc.errno != errno.EEXIST:\n",
    "                    raise\n",
    "        \n",
    "        with open(save_file, 'w') as new_file:\n",
    "            sf.write(save_file, y, sr)\n",
    "            new_file.close()\n",
    "            \n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('cleaned and saved 100 files')\n",
    "    \n",
    "    print(\"cleaning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned and saved 100 files\n",
      "cleaned and saved 100 files\n",
      "cleaned and saved 100 files\n",
      "cleaned and saved 100 files\n",
      "cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "clean_files(savee_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "savee_clean_list = glob.glob('clean/Users/ioann/saveelist/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_savee_index(file_list):\n",
    "    \n",
    "    emotion_key = {'n': 'neutral', 'h': 'happy', 'sa': 'sad', 'a': 'angry', 'f': 'fearful', 'd': 'disgusted', 'su': 'surprised'}\n",
    "    df = { 'emotion': [] }\n",
    "   \n",
    "\n",
    "    for file in file_list:\n",
    "        \n",
    "\n",
    "        props = file.split('/')[3][10:]\n",
    "       \n",
    "        df['emotion'].append(emotion_key[props[ :-9]])\n",
    "       \n",
    "\n",
    "       \n",
    "\n",
    "    file_properties = pd.DataFrame(df)\n",
    "    \n",
    "    return file_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_list = build_savee_index(savee_clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion\n",
       "0        angry\n",
       "1        angry\n",
       "2        angry\n",
       "3        angry\n",
       "4        angry\n",
       "5        angry\n",
       "6        angry\n",
       "7        angry\n",
       "8        angry\n",
       "9        angry\n",
       "10       angry\n",
       "11       angry\n",
       "12       angry\n",
       "13       angry\n",
       "14       angry\n",
       "15       angry\n",
       "16       angry\n",
       "17       angry\n",
       "18       angry\n",
       "19       angry\n",
       "20       angry\n",
       "21       angry\n",
       "22       angry\n",
       "23       angry\n",
       "24       angry\n",
       "25       angry\n",
       "26       angry\n",
       "27       angry\n",
       "28       angry\n",
       "29       angry\n",
       "..         ...\n",
       "450  surprised\n",
       "451  surprised\n",
       "452  surprised\n",
       "453  surprised\n",
       "454  surprised\n",
       "455  surprised\n",
       "456  surprised\n",
       "457  surprised\n",
       "458  surprised\n",
       "459  surprised\n",
       "460  surprised\n",
       "461  surprised\n",
       "462  surprised\n",
       "463  surprised\n",
       "464  surprised\n",
       "465  surprised\n",
       "466  surprised\n",
       "467  surprised\n",
       "468  surprised\n",
       "469  surprised\n",
       "470  surprised\n",
       "471  surprised\n",
       "472  surprised\n",
       "473  surprised\n",
       "474  surprised\n",
       "475  surprised\n",
       "476  surprised\n",
       "477  surprised\n",
       "478  surprised\n",
       "479  surprised\n",
       "\n",
       "[480 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion\n",
       "0        angry\n",
       "1        angry\n",
       "2        angry\n",
       "3        angry\n",
       "4        angry\n",
       "5        angry\n",
       "6        angry\n",
       "7        angry\n",
       "8        angry\n",
       "9        angry\n",
       "10       angry\n",
       "11       angry\n",
       "12       angry\n",
       "13       angry\n",
       "14       angry\n",
       "15       angry\n",
       "16       angry\n",
       "17       angry\n",
       "18       angry\n",
       "19       angry\n",
       "20       angry\n",
       "21       angry\n",
       "22       angry\n",
       "23       angry\n",
       "24       angry\n",
       "25       angry\n",
       "26       angry\n",
       "27       angry\n",
       "28       angry\n",
       "29       angry\n",
       "..         ...\n",
       "450  surprised\n",
       "451  surprised\n",
       "452  surprised\n",
       "453  surprised\n",
       "454  surprised\n",
       "455  surprised\n",
       "456  surprised\n",
       "457  surprised\n",
       "458  surprised\n",
       "459  surprised\n",
       "460  surprised\n",
       "461  surprised\n",
       "462  surprised\n",
       "463  surprised\n",
       "464  surprised\n",
       "465  surprised\n",
       "466  surprised\n",
       "467  surprised\n",
       "468  surprised\n",
       "469  surprised\n",
       "470  surprised\n",
       "471  surprised\n",
       "472  surprised\n",
       "473  surprised\n",
       "474  surprised\n",
       "475  surprised\n",
       "476  surprised\n",
       "477  surprised\n",
       "478  surprised\n",
       "479  surprised\n",
       "\n",
       "[480 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "\n",
    "\n",
    "\n",
    "path = '/Users/ioann/saveelist/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "      \n",
    "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
    "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark=bookmark+1\n",
    "        \n",
    "       \n",
    "     \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-320.56489703094303, 110.93380247868102, 12.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-244.65867781061723, 104.24924778351834, 0.65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-269.98304089788536, 100.68981219664313, 4.81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-564.5403264861648, 104.18191308304459, 26.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-299.4085271173833, 120.05930557550765, -7.83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-268.41515221876404, 102.6471846342612, -6.83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-270.43346188219135, 102.25127566034016, -7.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-578.9710836117222, 153.1407478680532, 12.843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-337.16074928048477, 96.86674029531615, 4.881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-313.97857226224176, 82.6321101796106, 3.1210...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-306.8130083691328, 91.20208756975964, 4.8379...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-619.6831061204579, 107.6126642956754, 29.545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-287.82387069919866, 101.51551026221725, 6.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[-262.7111259722113, 84.1841488652595, 3.69229...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[-274.68278526002223, 94.76874695508073, 3.583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-545.8997803053684, 94.28232769185743, 22.473...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[-297.1497912374246, 93.35873617744811, 0.1293...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[-237.82900386724705, 85.64256228760232, -1.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[-260.91999963896467, 94.25220735576018, -0.62...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[-554.9165546730685, 119.24717308751225, 20.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[-310.46651960120516, 111.65507593109344, 3.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[-276.63579049080806, 93.7466885068284, -3.646...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[-229.98037600613847, 92.73478061352138, -10.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[-556.8906512685712, 114.07348808278753, 21.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[-311.7218116037182, 109.37780397609065, -6.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[-277.0224960587589, 90.40572254893208, -5.277...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[-208.6244743268714, 104.62880822351998, -13.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[-467.8706059087861, 150.7026683972865, 6.9408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[-291.87263252106055, 80.72472791805563, 8.813...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[-267.6040666142941, 76.18215556194727, 6.5193...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>[-270.9050439311626, 83.24184411630284, 5.8253...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>[-576.5320475501278, 98.48191420451985, 22.043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>[-340.8692927597237, 91.63540528125624, 15.328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>[-323.62252105075265, 67.87576661297365, 9.816...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>[-267.993418835994, 86.63109180229297, 3.26337...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>[-573.5730912722669, 113.5164638684677, 27.415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>[-306.57257173240123, 109.67017197663414, 11.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>[-315.04532522832824, 94.32080705109271, 2.107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>[-261.098646883903, 98.36798141597211, -2.0268...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>[-537.8573499804709, 132.46346704682844, 15.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>[-367.1911807821997, 84.24596017670552, 17.285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>[-356.30702746431626, 72.58502467149373, 15.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>[-294.0649867089362, 67.826550207352, -0.71173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>[-584.3130229911702, 96.89391639589692, 29.197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>[-338.1462172562831, 109.37235471741884, 13.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>[-322.9661655691384, 94.319345194262, 15.35222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>[-269.2274618041228, 81.26010349150518, 1.2883...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>[-557.9648808568126, 119.10574634745295, 28.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>[-322.05221400877684, 87.30480587542426, 18.85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>[-322.7737657069129, 95.85282433566887, 18.896...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>[-262.3750893207745, 89.32145743747377, 0.9361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>[-585.7432275644761, 121.1574671660622, 38.472...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>[-305.9160006046394, 85.83617564014556, 11.930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>[-331.70553509120793, 87.75995056661017, 10.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>[-281.3305074541287, 79.5421034170356, 1.88390...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>[-562.0557902338431, 107.55413103322176, 26.85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>[-299.5749817381685, 93.88058068466718, 10.768...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>[-310.62781103470326, 81.78451824131443, 12.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>[-268.2092121173742, 85.08309831063501, 4.4081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>[-560.2377886223912, 117.40669764661966, 30.12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feature\n",
       "0    [-320.56489703094303, 110.93380247868102, 12.4...\n",
       "1    [-244.65867781061723, 104.24924778351834, 0.65...\n",
       "2    [-269.98304089788536, 100.68981219664313, 4.81...\n",
       "3    [-564.5403264861648, 104.18191308304459, 26.30...\n",
       "4    [-299.4085271173833, 120.05930557550765, -7.83...\n",
       "5    [-268.41515221876404, 102.6471846342612, -6.83...\n",
       "6    [-270.43346188219135, 102.25127566034016, -7.7...\n",
       "7    [-578.9710836117222, 153.1407478680532, 12.843...\n",
       "8    [-337.16074928048477, 96.86674029531615, 4.881...\n",
       "9    [-313.97857226224176, 82.6321101796106, 3.1210...\n",
       "10   [-306.8130083691328, 91.20208756975964, 4.8379...\n",
       "11   [-619.6831061204579, 107.6126642956754, 29.545...\n",
       "12   [-287.82387069919866, 101.51551026221725, 6.41...\n",
       "13   [-262.7111259722113, 84.1841488652595, 3.69229...\n",
       "14   [-274.68278526002223, 94.76874695508073, 3.583...\n",
       "15   [-545.8997803053684, 94.28232769185743, 22.473...\n",
       "16   [-297.1497912374246, 93.35873617744811, 0.1293...\n",
       "17   [-237.82900386724705, 85.64256228760232, -1.48...\n",
       "18   [-260.91999963896467, 94.25220735576018, -0.62...\n",
       "19   [-554.9165546730685, 119.24717308751225, 20.04...\n",
       "20   [-310.46651960120516, 111.65507593109344, 3.51...\n",
       "21   [-276.63579049080806, 93.7466885068284, -3.646...\n",
       "22   [-229.98037600613847, 92.73478061352138, -10.1...\n",
       "23   [-556.8906512685712, 114.07348808278753, 21.39...\n",
       "24   [-311.7218116037182, 109.37780397609065, -6.25...\n",
       "25   [-277.0224960587589, 90.40572254893208, -5.277...\n",
       "26   [-208.6244743268714, 104.62880822351998, -13.9...\n",
       "27   [-467.8706059087861, 150.7026683972865, 6.9408...\n",
       "28   [-291.87263252106055, 80.72472791805563, 8.813...\n",
       "29   [-267.6040666142941, 76.18215556194727, 6.5193...\n",
       "..                                                 ...\n",
       "450  [-270.9050439311626, 83.24184411630284, 5.8253...\n",
       "451  [-576.5320475501278, 98.48191420451985, 22.043...\n",
       "452  [-340.8692927597237, 91.63540528125624, 15.328...\n",
       "453  [-323.62252105075265, 67.87576661297365, 9.816...\n",
       "454  [-267.993418835994, 86.63109180229297, 3.26337...\n",
       "455  [-573.5730912722669, 113.5164638684677, 27.415...\n",
       "456  [-306.57257173240123, 109.67017197663414, 11.9...\n",
       "457  [-315.04532522832824, 94.32080705109271, 2.107...\n",
       "458  [-261.098646883903, 98.36798141597211, -2.0268...\n",
       "459  [-537.8573499804709, 132.46346704682844, 15.03...\n",
       "460  [-367.1911807821997, 84.24596017670552, 17.285...\n",
       "461  [-356.30702746431626, 72.58502467149373, 15.99...\n",
       "462  [-294.0649867089362, 67.826550207352, -0.71173...\n",
       "463  [-584.3130229911702, 96.89391639589692, 29.197...\n",
       "464  [-338.1462172562831, 109.37235471741884, 13.92...\n",
       "465  [-322.9661655691384, 94.319345194262, 15.35222...\n",
       "466  [-269.2274618041228, 81.26010349150518, 1.2883...\n",
       "467  [-557.9648808568126, 119.10574634745295, 28.72...\n",
       "468  [-322.05221400877684, 87.30480587542426, 18.85...\n",
       "469  [-322.7737657069129, 95.85282433566887, 18.896...\n",
       "470  [-262.3750893207745, 89.32145743747377, 0.9361...\n",
       "471  [-585.7432275644761, 121.1574671660622, 38.472...\n",
       "472  [-305.9160006046394, 85.83617564014556, 11.930...\n",
       "473  [-331.70553509120793, 87.75995056661017, 10.33...\n",
       "474  [-281.3305074541287, 79.5421034170356, 1.88390...\n",
       "475  [-562.0557902338431, 107.55413103322176, 26.85...\n",
       "476  [-299.5749817381685, 93.88058068466718, 10.768...\n",
       "477  [-310.62781103470326, 81.78451824131443, 12.50...\n",
       "478  [-268.2092121173742, 85.08309831063501, 4.4081...\n",
       "479  [-560.2377886223912, 117.40669764661966, 30.12...\n",
       "\n",
       "[480 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-320.564897</td>\n",
       "      <td>110.933802</td>\n",
       "      <td>12.457851</td>\n",
       "      <td>34.670754</td>\n",
       "      <td>11.628866</td>\n",
       "      <td>-2.938117</td>\n",
       "      <td>-24.859946</td>\n",
       "      <td>-2.633693</td>\n",
       "      <td>-0.919507</td>\n",
       "      <td>-11.532021</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452810</td>\n",
       "      <td>1.783171</td>\n",
       "      <td>3.263025</td>\n",
       "      <td>2.756852</td>\n",
       "      <td>3.496057</td>\n",
       "      <td>5.099579</td>\n",
       "      <td>4.885279</td>\n",
       "      <td>5.633801</td>\n",
       "      <td>4.365917</td>\n",
       "      <td>3.453820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-244.658678</td>\n",
       "      <td>104.249248</td>\n",
       "      <td>0.657434</td>\n",
       "      <td>41.458732</td>\n",
       "      <td>-1.098887</td>\n",
       "      <td>3.049909</td>\n",
       "      <td>-23.316795</td>\n",
       "      <td>-7.371824</td>\n",
       "      <td>-7.313963</td>\n",
       "      <td>-5.459172</td>\n",
       "      <td>...</td>\n",
       "      <td>2.513106</td>\n",
       "      <td>4.278307</td>\n",
       "      <td>4.096044</td>\n",
       "      <td>2.962424</td>\n",
       "      <td>3.240562</td>\n",
       "      <td>0.578126</td>\n",
       "      <td>1.794270</td>\n",
       "      <td>3.656604</td>\n",
       "      <td>4.363981</td>\n",
       "      <td>3.638848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-269.983041</td>\n",
       "      <td>100.689812</td>\n",
       "      <td>4.812852</td>\n",
       "      <td>44.206061</td>\n",
       "      <td>-9.372619</td>\n",
       "      <td>-17.481868</td>\n",
       "      <td>0.876082</td>\n",
       "      <td>2.226196</td>\n",
       "      <td>-16.333266</td>\n",
       "      <td>-3.812531</td>\n",
       "      <td>...</td>\n",
       "      <td>2.308230</td>\n",
       "      <td>4.117299</td>\n",
       "      <td>3.856427</td>\n",
       "      <td>4.716765</td>\n",
       "      <td>6.389915</td>\n",
       "      <td>5.546877</td>\n",
       "      <td>4.826904</td>\n",
       "      <td>4.839705</td>\n",
       "      <td>4.608056</td>\n",
       "      <td>4.928732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-564.540326</td>\n",
       "      <td>104.181913</td>\n",
       "      <td>26.302574</td>\n",
       "      <td>44.703341</td>\n",
       "      <td>17.196513</td>\n",
       "      <td>-4.453330</td>\n",
       "      <td>-15.700971</td>\n",
       "      <td>-2.773550</td>\n",
       "      <td>-5.163968</td>\n",
       "      <td>-11.310603</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.580128</td>\n",
       "      <td>-1.982804</td>\n",
       "      <td>-0.331088</td>\n",
       "      <td>-2.861281</td>\n",
       "      <td>-2.723364</td>\n",
       "      <td>0.419460</td>\n",
       "      <td>2.015126</td>\n",
       "      <td>1.980087</td>\n",
       "      <td>-0.398496</td>\n",
       "      <td>-0.039357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-299.408527</td>\n",
       "      <td>120.059306</td>\n",
       "      <td>-7.834544</td>\n",
       "      <td>18.676239</td>\n",
       "      <td>14.225895</td>\n",
       "      <td>-2.376180</td>\n",
       "      <td>-20.357823</td>\n",
       "      <td>3.748768</td>\n",
       "      <td>4.587472</td>\n",
       "      <td>-11.664485</td>\n",
       "      <td>...</td>\n",
       "      <td>1.049761</td>\n",
       "      <td>1.525852</td>\n",
       "      <td>1.987423</td>\n",
       "      <td>0.174960</td>\n",
       "      <td>-0.661590</td>\n",
       "      <td>-0.089371</td>\n",
       "      <td>-0.488558</td>\n",
       "      <td>1.521584</td>\n",
       "      <td>1.066419</td>\n",
       "      <td>-0.393785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-268.415152</td>\n",
       "      <td>102.647185</td>\n",
       "      <td>-6.831019</td>\n",
       "      <td>21.777451</td>\n",
       "      <td>5.504902</td>\n",
       "      <td>2.677995</td>\n",
       "      <td>-17.891163</td>\n",
       "      <td>-4.412988</td>\n",
       "      <td>-3.229257</td>\n",
       "      <td>0.431965</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.543827</td>\n",
       "      <td>0.943443</td>\n",
       "      <td>-0.501339</td>\n",
       "      <td>-0.080925</td>\n",
       "      <td>0.131035</td>\n",
       "      <td>-1.918740</td>\n",
       "      <td>1.268647</td>\n",
       "      <td>2.679410</td>\n",
       "      <td>2.754248</td>\n",
       "      <td>3.670862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-270.433462</td>\n",
       "      <td>102.251276</td>\n",
       "      <td>-7.766242</td>\n",
       "      <td>27.726690</td>\n",
       "      <td>-2.322103</td>\n",
       "      <td>-15.604451</td>\n",
       "      <td>0.235773</td>\n",
       "      <td>0.016892</td>\n",
       "      <td>-12.838433</td>\n",
       "      <td>-0.243834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540800</td>\n",
       "      <td>1.750614</td>\n",
       "      <td>2.308556</td>\n",
       "      <td>1.087831</td>\n",
       "      <td>0.177460</td>\n",
       "      <td>-1.091181</td>\n",
       "      <td>-0.377372</td>\n",
       "      <td>-0.434003</td>\n",
       "      <td>-0.327013</td>\n",
       "      <td>-0.177506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-578.971084</td>\n",
       "      <td>153.140748</td>\n",
       "      <td>12.843857</td>\n",
       "      <td>13.583781</td>\n",
       "      <td>5.480952</td>\n",
       "      <td>-4.754079</td>\n",
       "      <td>-7.061755</td>\n",
       "      <td>1.223524</td>\n",
       "      <td>-7.304688</td>\n",
       "      <td>-13.289818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.529214</td>\n",
       "      <td>-0.245226</td>\n",
       "      <td>-0.666285</td>\n",
       "      <td>-2.915523</td>\n",
       "      <td>-1.297646</td>\n",
       "      <td>-1.285307</td>\n",
       "      <td>-1.099492</td>\n",
       "      <td>0.359853</td>\n",
       "      <td>-2.147516</td>\n",
       "      <td>-1.808127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-337.160749</td>\n",
       "      <td>96.866740</td>\n",
       "      <td>4.881764</td>\n",
       "      <td>26.825063</td>\n",
       "      <td>10.724669</td>\n",
       "      <td>-2.182416</td>\n",
       "      <td>-13.945372</td>\n",
       "      <td>7.127122</td>\n",
       "      <td>-0.079204</td>\n",
       "      <td>-7.433390</td>\n",
       "      <td>...</td>\n",
       "      <td>2.997824</td>\n",
       "      <td>3.103378</td>\n",
       "      <td>4.924483</td>\n",
       "      <td>6.009026</td>\n",
       "      <td>6.636278</td>\n",
       "      <td>6.517982</td>\n",
       "      <td>6.425938</td>\n",
       "      <td>4.764662</td>\n",
       "      <td>3.565150</td>\n",
       "      <td>4.918953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-313.978572</td>\n",
       "      <td>82.632110</td>\n",
       "      <td>3.121088</td>\n",
       "      <td>25.119724</td>\n",
       "      <td>6.733781</td>\n",
       "      <td>2.579732</td>\n",
       "      <td>-13.853373</td>\n",
       "      <td>0.178914</td>\n",
       "      <td>-1.616934</td>\n",
       "      <td>1.959738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892974</td>\n",
       "      <td>0.141898</td>\n",
       "      <td>1.821391</td>\n",
       "      <td>2.529989</td>\n",
       "      <td>1.968246</td>\n",
       "      <td>2.439394</td>\n",
       "      <td>3.644267</td>\n",
       "      <td>3.000721</td>\n",
       "      <td>4.114735</td>\n",
       "      <td>5.142286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-306.813008</td>\n",
       "      <td>91.202088</td>\n",
       "      <td>4.837953</td>\n",
       "      <td>35.295787</td>\n",
       "      <td>-4.541257</td>\n",
       "      <td>-15.186219</td>\n",
       "      <td>-1.853829</td>\n",
       "      <td>2.134356</td>\n",
       "      <td>-8.612269</td>\n",
       "      <td>0.580285</td>\n",
       "      <td>...</td>\n",
       "      <td>2.296859</td>\n",
       "      <td>3.049797</td>\n",
       "      <td>2.827478</td>\n",
       "      <td>2.024559</td>\n",
       "      <td>1.230836</td>\n",
       "      <td>1.951512</td>\n",
       "      <td>3.221304</td>\n",
       "      <td>4.017343</td>\n",
       "      <td>4.348317</td>\n",
       "      <td>3.054402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-619.683106</td>\n",
       "      <td>107.612664</td>\n",
       "      <td>29.545496</td>\n",
       "      <td>32.781815</td>\n",
       "      <td>13.113059</td>\n",
       "      <td>-2.023275</td>\n",
       "      <td>-6.724471</td>\n",
       "      <td>3.051477</td>\n",
       "      <td>-1.109710</td>\n",
       "      <td>-7.053607</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.463808</td>\n",
       "      <td>0.568521</td>\n",
       "      <td>-0.458534</td>\n",
       "      <td>-4.041868</td>\n",
       "      <td>-0.373413</td>\n",
       "      <td>1.693426</td>\n",
       "      <td>3.119295</td>\n",
       "      <td>6.467952</td>\n",
       "      <td>6.222947</td>\n",
       "      <td>7.158575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-287.823871</td>\n",
       "      <td>101.515510</td>\n",
       "      <td>6.410148</td>\n",
       "      <td>15.656604</td>\n",
       "      <td>7.395868</td>\n",
       "      <td>-1.489299</td>\n",
       "      <td>-24.872378</td>\n",
       "      <td>-5.148656</td>\n",
       "      <td>-0.039547</td>\n",
       "      <td>-10.816283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094653</td>\n",
       "      <td>1.922031</td>\n",
       "      <td>2.069620</td>\n",
       "      <td>1.789086</td>\n",
       "      <td>1.402842</td>\n",
       "      <td>1.192773</td>\n",
       "      <td>2.013896</td>\n",
       "      <td>2.935015</td>\n",
       "      <td>3.895297</td>\n",
       "      <td>5.941611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-262.711126</td>\n",
       "      <td>84.184149</td>\n",
       "      <td>3.692296</td>\n",
       "      <td>30.717997</td>\n",
       "      <td>0.333233</td>\n",
       "      <td>2.032098</td>\n",
       "      <td>-20.818370</td>\n",
       "      <td>-8.069312</td>\n",
       "      <td>-6.483575</td>\n",
       "      <td>-4.030453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720971</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>-0.489348</td>\n",
       "      <td>0.585226</td>\n",
       "      <td>2.560084</td>\n",
       "      <td>2.873368</td>\n",
       "      <td>2.866207</td>\n",
       "      <td>2.956850</td>\n",
       "      <td>3.221912</td>\n",
       "      <td>3.025061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-274.682785</td>\n",
       "      <td>94.768747</td>\n",
       "      <td>3.583395</td>\n",
       "      <td>31.612113</td>\n",
       "      <td>-2.270698</td>\n",
       "      <td>-13.238559</td>\n",
       "      <td>-8.697503</td>\n",
       "      <td>-3.330329</td>\n",
       "      <td>-13.886461</td>\n",
       "      <td>-2.766569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133236</td>\n",
       "      <td>0.832539</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.718816</td>\n",
       "      <td>1.454612</td>\n",
       "      <td>3.247061</td>\n",
       "      <td>4.824512</td>\n",
       "      <td>5.183765</td>\n",
       "      <td>4.432016</td>\n",
       "      <td>2.757248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-545.899780</td>\n",
       "      <td>94.282328</td>\n",
       "      <td>22.473580</td>\n",
       "      <td>21.962141</td>\n",
       "      <td>11.071408</td>\n",
       "      <td>2.064249</td>\n",
       "      <td>-9.974123</td>\n",
       "      <td>-5.297741</td>\n",
       "      <td>-6.165273</td>\n",
       "      <td>-9.604840</td>\n",
       "      <td>...</td>\n",
       "      <td>1.021445</td>\n",
       "      <td>3.128254</td>\n",
       "      <td>2.563572</td>\n",
       "      <td>0.236307</td>\n",
       "      <td>0.642036</td>\n",
       "      <td>-1.301531</td>\n",
       "      <td>-0.757510</td>\n",
       "      <td>0.594631</td>\n",
       "      <td>0.517790</td>\n",
       "      <td>2.317307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-297.149791</td>\n",
       "      <td>93.358736</td>\n",
       "      <td>0.129330</td>\n",
       "      <td>22.744894</td>\n",
       "      <td>12.982417</td>\n",
       "      <td>-2.121561</td>\n",
       "      <td>-23.176872</td>\n",
       "      <td>-3.080107</td>\n",
       "      <td>-3.018409</td>\n",
       "      <td>-14.218085</td>\n",
       "      <td>...</td>\n",
       "      <td>1.784480</td>\n",
       "      <td>2.797313</td>\n",
       "      <td>0.787051</td>\n",
       "      <td>-0.474089</td>\n",
       "      <td>1.092980</td>\n",
       "      <td>0.932278</td>\n",
       "      <td>0.742255</td>\n",
       "      <td>1.795864</td>\n",
       "      <td>3.188131</td>\n",
       "      <td>4.286123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-237.829004</td>\n",
       "      <td>85.642562</td>\n",
       "      <td>-1.482641</td>\n",
       "      <td>30.883268</td>\n",
       "      <td>-4.640333</td>\n",
       "      <td>1.335876</td>\n",
       "      <td>-20.403958</td>\n",
       "      <td>-5.666015</td>\n",
       "      <td>-8.458400</td>\n",
       "      <td>-4.095452</td>\n",
       "      <td>...</td>\n",
       "      <td>1.637515</td>\n",
       "      <td>3.088781</td>\n",
       "      <td>3.316565</td>\n",
       "      <td>4.343492</td>\n",
       "      <td>5.712959</td>\n",
       "      <td>4.264993</td>\n",
       "      <td>6.487091</td>\n",
       "      <td>7.751737</td>\n",
       "      <td>8.683150</td>\n",
       "      <td>8.666596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-260.920000</td>\n",
       "      <td>94.252207</td>\n",
       "      <td>-0.628142</td>\n",
       "      <td>35.111116</td>\n",
       "      <td>-10.885650</td>\n",
       "      <td>-11.894777</td>\n",
       "      <td>-8.281734</td>\n",
       "      <td>-2.487652</td>\n",
       "      <td>-13.697984</td>\n",
       "      <td>-6.830959</td>\n",
       "      <td>...</td>\n",
       "      <td>1.896655</td>\n",
       "      <td>4.731171</td>\n",
       "      <td>5.223400</td>\n",
       "      <td>4.126560</td>\n",
       "      <td>3.545781</td>\n",
       "      <td>3.134574</td>\n",
       "      <td>4.163274</td>\n",
       "      <td>4.238909</td>\n",
       "      <td>3.606129</td>\n",
       "      <td>2.932312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-554.916555</td>\n",
       "      <td>119.247173</td>\n",
       "      <td>20.049515</td>\n",
       "      <td>24.732460</td>\n",
       "      <td>4.934111</td>\n",
       "      <td>-6.313914</td>\n",
       "      <td>-15.549304</td>\n",
       "      <td>-7.235226</td>\n",
       "      <td>-9.178871</td>\n",
       "      <td>-13.237397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.994061</td>\n",
       "      <td>0.273503</td>\n",
       "      <td>0.141774</td>\n",
       "      <td>-2.123241</td>\n",
       "      <td>-1.487538</td>\n",
       "      <td>-1.147595</td>\n",
       "      <td>-0.665070</td>\n",
       "      <td>1.203635</td>\n",
       "      <td>0.748611</td>\n",
       "      <td>1.120355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-310.466520</td>\n",
       "      <td>111.655076</td>\n",
       "      <td>3.510758</td>\n",
       "      <td>28.038363</td>\n",
       "      <td>2.558900</td>\n",
       "      <td>0.751742</td>\n",
       "      <td>-22.066307</td>\n",
       "      <td>-3.129726</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>-11.526986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164121</td>\n",
       "      <td>0.559290</td>\n",
       "      <td>0.553784</td>\n",
       "      <td>1.427426</td>\n",
       "      <td>3.409991</td>\n",
       "      <td>5.172947</td>\n",
       "      <td>5.295261</td>\n",
       "      <td>7.167189</td>\n",
       "      <td>7.946955</td>\n",
       "      <td>6.104829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-276.635790</td>\n",
       "      <td>93.746689</td>\n",
       "      <td>-3.646088</td>\n",
       "      <td>31.032646</td>\n",
       "      <td>6.120393</td>\n",
       "      <td>1.945582</td>\n",
       "      <td>-19.112421</td>\n",
       "      <td>-4.126155</td>\n",
       "      <td>-3.454874</td>\n",
       "      <td>-2.151538</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.823949</td>\n",
       "      <td>-0.154802</td>\n",
       "      <td>1.964497</td>\n",
       "      <td>1.255755</td>\n",
       "      <td>0.608359</td>\n",
       "      <td>0.679066</td>\n",
       "      <td>0.849191</td>\n",
       "      <td>1.283594</td>\n",
       "      <td>1.590320</td>\n",
       "      <td>1.617642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-229.980376</td>\n",
       "      <td>92.734781</td>\n",
       "      <td>-10.102935</td>\n",
       "      <td>38.225387</td>\n",
       "      <td>-12.808887</td>\n",
       "      <td>-8.081135</td>\n",
       "      <td>-9.241305</td>\n",
       "      <td>-0.922913</td>\n",
       "      <td>-11.749296</td>\n",
       "      <td>-4.356548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920867</td>\n",
       "      <td>0.249137</td>\n",
       "      <td>2.279387</td>\n",
       "      <td>2.188748</td>\n",
       "      <td>2.733104</td>\n",
       "      <td>2.431164</td>\n",
       "      <td>2.090510</td>\n",
       "      <td>3.369304</td>\n",
       "      <td>2.246630</td>\n",
       "      <td>2.007894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-556.890651</td>\n",
       "      <td>114.073488</td>\n",
       "      <td>21.399754</td>\n",
       "      <td>37.684455</td>\n",
       "      <td>1.765665</td>\n",
       "      <td>-5.789695</td>\n",
       "      <td>-11.279757</td>\n",
       "      <td>-0.880750</td>\n",
       "      <td>-7.797464</td>\n",
       "      <td>-12.325886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228329</td>\n",
       "      <td>0.142309</td>\n",
       "      <td>-0.065403</td>\n",
       "      <td>-2.161767</td>\n",
       "      <td>-0.434520</td>\n",
       "      <td>-0.591449</td>\n",
       "      <td>0.751506</td>\n",
       "      <td>1.570371</td>\n",
       "      <td>-1.204428</td>\n",
       "      <td>0.389953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-311.721812</td>\n",
       "      <td>109.377804</td>\n",
       "      <td>-6.253777</td>\n",
       "      <td>20.515531</td>\n",
       "      <td>1.536390</td>\n",
       "      <td>-6.694665</td>\n",
       "      <td>-16.409074</td>\n",
       "      <td>3.595946</td>\n",
       "      <td>-3.917058</td>\n",
       "      <td>-10.481376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.552881</td>\n",
       "      <td>2.468394</td>\n",
       "      <td>3.484781</td>\n",
       "      <td>2.921893</td>\n",
       "      <td>3.235744</td>\n",
       "      <td>3.604677</td>\n",
       "      <td>4.461789</td>\n",
       "      <td>6.496880</td>\n",
       "      <td>8.847790</td>\n",
       "      <td>8.812864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-277.022496</td>\n",
       "      <td>90.405723</td>\n",
       "      <td>-5.277691</td>\n",
       "      <td>18.908560</td>\n",
       "      <td>-1.914564</td>\n",
       "      <td>0.759638</td>\n",
       "      <td>-13.838499</td>\n",
       "      <td>-0.469484</td>\n",
       "      <td>-6.623128</td>\n",
       "      <td>2.865756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743524</td>\n",
       "      <td>1.607718</td>\n",
       "      <td>1.737711</td>\n",
       "      <td>2.482907</td>\n",
       "      <td>3.338550</td>\n",
       "      <td>2.707236</td>\n",
       "      <td>2.611088</td>\n",
       "      <td>0.121514</td>\n",
       "      <td>0.629194</td>\n",
       "      <td>1.456162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-208.624474</td>\n",
       "      <td>104.628808</td>\n",
       "      <td>-13.943393</td>\n",
       "      <td>26.271492</td>\n",
       "      <td>-15.843213</td>\n",
       "      <td>-11.005214</td>\n",
       "      <td>-13.288870</td>\n",
       "      <td>-2.621522</td>\n",
       "      <td>-10.667197</td>\n",
       "      <td>-0.191851</td>\n",
       "      <td>...</td>\n",
       "      <td>3.211881</td>\n",
       "      <td>3.033859</td>\n",
       "      <td>4.159673</td>\n",
       "      <td>4.727725</td>\n",
       "      <td>3.593283</td>\n",
       "      <td>3.313064</td>\n",
       "      <td>3.354987</td>\n",
       "      <td>2.968107</td>\n",
       "      <td>2.460999</td>\n",
       "      <td>1.700034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-467.870606</td>\n",
       "      <td>150.702668</td>\n",
       "      <td>6.940878</td>\n",
       "      <td>13.059629</td>\n",
       "      <td>-6.794840</td>\n",
       "      <td>-23.409382</td>\n",
       "      <td>-11.542217</td>\n",
       "      <td>2.467216</td>\n",
       "      <td>-15.035852</td>\n",
       "      <td>-23.422054</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.919832</td>\n",
       "      <td>-0.469279</td>\n",
       "      <td>-4.088092</td>\n",
       "      <td>-5.701839</td>\n",
       "      <td>-0.011955</td>\n",
       "      <td>-4.946802</td>\n",
       "      <td>-1.943001</td>\n",
       "      <td>-3.436878</td>\n",
       "      <td>-6.409079</td>\n",
       "      <td>-2.927387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-291.872633</td>\n",
       "      <td>80.724728</td>\n",
       "      <td>8.813734</td>\n",
       "      <td>24.354779</td>\n",
       "      <td>-3.727562</td>\n",
       "      <td>-2.716657</td>\n",
       "      <td>-20.333166</td>\n",
       "      <td>-4.286414</td>\n",
       "      <td>-1.203566</td>\n",
       "      <td>-7.991472</td>\n",
       "      <td>...</td>\n",
       "      <td>4.803417</td>\n",
       "      <td>8.918398</td>\n",
       "      <td>8.608139</td>\n",
       "      <td>7.215964</td>\n",
       "      <td>6.221586</td>\n",
       "      <td>5.591549</td>\n",
       "      <td>5.749485</td>\n",
       "      <td>7.318852</td>\n",
       "      <td>6.561183</td>\n",
       "      <td>4.343619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-267.604067</td>\n",
       "      <td>76.182156</td>\n",
       "      <td>6.519338</td>\n",
       "      <td>32.557985</td>\n",
       "      <td>-1.324882</td>\n",
       "      <td>3.437367</td>\n",
       "      <td>-17.131312</td>\n",
       "      <td>-6.799114</td>\n",
       "      <td>-7.417711</td>\n",
       "      <td>-6.034486</td>\n",
       "      <td>...</td>\n",
       "      <td>3.667866</td>\n",
       "      <td>5.165975</td>\n",
       "      <td>6.129603</td>\n",
       "      <td>3.540575</td>\n",
       "      <td>0.998083</td>\n",
       "      <td>0.595110</td>\n",
       "      <td>1.790990</td>\n",
       "      <td>2.636777</td>\n",
       "      <td>3.801948</td>\n",
       "      <td>3.991086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>-270.905044</td>\n",
       "      <td>83.241844</td>\n",
       "      <td>5.825305</td>\n",
       "      <td>34.028753</td>\n",
       "      <td>-20.226561</td>\n",
       "      <td>-4.650805</td>\n",
       "      <td>-12.991530</td>\n",
       "      <td>-2.309803</td>\n",
       "      <td>-14.578473</td>\n",
       "      <td>-4.914250</td>\n",
       "      <td>...</td>\n",
       "      <td>2.812163</td>\n",
       "      <td>3.093380</td>\n",
       "      <td>1.632940</td>\n",
       "      <td>-0.877966</td>\n",
       "      <td>2.241036</td>\n",
       "      <td>1.710399</td>\n",
       "      <td>1.639457</td>\n",
       "      <td>4.625621</td>\n",
       "      <td>2.235594</td>\n",
       "      <td>2.497927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-576.532048</td>\n",
       "      <td>98.481914</td>\n",
       "      <td>22.043391</td>\n",
       "      <td>35.167535</td>\n",
       "      <td>-0.444776</td>\n",
       "      <td>0.608610</td>\n",
       "      <td>-7.506805</td>\n",
       "      <td>-4.842706</td>\n",
       "      <td>-13.191851</td>\n",
       "      <td>-12.959278</td>\n",
       "      <td>...</td>\n",
       "      <td>4.426111</td>\n",
       "      <td>5.177279</td>\n",
       "      <td>2.554160</td>\n",
       "      <td>2.186716</td>\n",
       "      <td>5.343213</td>\n",
       "      <td>3.646216</td>\n",
       "      <td>3.993214</td>\n",
       "      <td>2.326687</td>\n",
       "      <td>0.506513</td>\n",
       "      <td>3.333642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>-340.869293</td>\n",
       "      <td>91.635405</td>\n",
       "      <td>15.328301</td>\n",
       "      <td>33.700820</td>\n",
       "      <td>-0.429162</td>\n",
       "      <td>6.658317</td>\n",
       "      <td>-25.491608</td>\n",
       "      <td>-3.136858</td>\n",
       "      <td>4.379834</td>\n",
       "      <td>-12.477610</td>\n",
       "      <td>...</td>\n",
       "      <td>7.124014</td>\n",
       "      <td>7.930197</td>\n",
       "      <td>8.842382</td>\n",
       "      <td>6.641419</td>\n",
       "      <td>6.830562</td>\n",
       "      <td>6.939276</td>\n",
       "      <td>5.250627</td>\n",
       "      <td>5.412664</td>\n",
       "      <td>3.379724</td>\n",
       "      <td>3.157793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>-323.622521</td>\n",
       "      <td>67.875767</td>\n",
       "      <td>9.816173</td>\n",
       "      <td>33.444895</td>\n",
       "      <td>-7.511998</td>\n",
       "      <td>2.373042</td>\n",
       "      <td>-22.135091</td>\n",
       "      <td>-2.645947</td>\n",
       "      <td>-5.675133</td>\n",
       "      <td>-2.786183</td>\n",
       "      <td>...</td>\n",
       "      <td>1.560307</td>\n",
       "      <td>2.373463</td>\n",
       "      <td>3.282973</td>\n",
       "      <td>2.033909</td>\n",
       "      <td>1.991121</td>\n",
       "      <td>1.484362</td>\n",
       "      <td>1.958998</td>\n",
       "      <td>2.029326</td>\n",
       "      <td>1.210597</td>\n",
       "      <td>1.815508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>-267.993419</td>\n",
       "      <td>86.631092</td>\n",
       "      <td>3.263370</td>\n",
       "      <td>28.449955</td>\n",
       "      <td>-24.136090</td>\n",
       "      <td>-11.551452</td>\n",
       "      <td>-13.266007</td>\n",
       "      <td>-3.861459</td>\n",
       "      <td>-14.582571</td>\n",
       "      <td>-2.435104</td>\n",
       "      <td>...</td>\n",
       "      <td>2.727813</td>\n",
       "      <td>2.064279</td>\n",
       "      <td>3.522736</td>\n",
       "      <td>2.007128</td>\n",
       "      <td>2.733028</td>\n",
       "      <td>1.805694</td>\n",
       "      <td>2.487521</td>\n",
       "      <td>3.761587</td>\n",
       "      <td>2.564815</td>\n",
       "      <td>3.633575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>-573.573091</td>\n",
       "      <td>113.516464</td>\n",
       "      <td>27.415844</td>\n",
       "      <td>35.419841</td>\n",
       "      <td>1.043905</td>\n",
       "      <td>-6.554022</td>\n",
       "      <td>-8.322166</td>\n",
       "      <td>0.526996</td>\n",
       "      <td>-10.460542</td>\n",
       "      <td>-15.149407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347566</td>\n",
       "      <td>0.154334</td>\n",
       "      <td>0.656173</td>\n",
       "      <td>-0.561989</td>\n",
       "      <td>1.486450</td>\n",
       "      <td>-0.652063</td>\n",
       "      <td>0.489430</td>\n",
       "      <td>2.628116</td>\n",
       "      <td>1.589769</td>\n",
       "      <td>2.397164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>-306.572572</td>\n",
       "      <td>109.670172</td>\n",
       "      <td>11.963575</td>\n",
       "      <td>16.871229</td>\n",
       "      <td>8.903087</td>\n",
       "      <td>1.114646</td>\n",
       "      <td>-19.945104</td>\n",
       "      <td>-3.327016</td>\n",
       "      <td>-1.510647</td>\n",
       "      <td>-9.728044</td>\n",
       "      <td>...</td>\n",
       "      <td>3.622234</td>\n",
       "      <td>2.925757</td>\n",
       "      <td>5.076261</td>\n",
       "      <td>4.986268</td>\n",
       "      <td>4.139367</td>\n",
       "      <td>5.599611</td>\n",
       "      <td>7.593524</td>\n",
       "      <td>7.631419</td>\n",
       "      <td>6.697954</td>\n",
       "      <td>5.786440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>-315.045325</td>\n",
       "      <td>94.320807</td>\n",
       "      <td>2.107157</td>\n",
       "      <td>22.853063</td>\n",
       "      <td>-4.755627</td>\n",
       "      <td>0.400240</td>\n",
       "      <td>-21.271273</td>\n",
       "      <td>-6.169301</td>\n",
       "      <td>-7.937066</td>\n",
       "      <td>-3.165314</td>\n",
       "      <td>...</td>\n",
       "      <td>3.231306</td>\n",
       "      <td>3.971601</td>\n",
       "      <td>5.411091</td>\n",
       "      <td>3.689788</td>\n",
       "      <td>2.697327</td>\n",
       "      <td>3.410430</td>\n",
       "      <td>3.242359</td>\n",
       "      <td>2.543476</td>\n",
       "      <td>2.200438</td>\n",
       "      <td>1.653810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>-261.098647</td>\n",
       "      <td>98.367981</td>\n",
       "      <td>-2.026808</td>\n",
       "      <td>19.736065</td>\n",
       "      <td>-13.907652</td>\n",
       "      <td>-9.889293</td>\n",
       "      <td>-10.083964</td>\n",
       "      <td>-5.183913</td>\n",
       "      <td>-14.426718</td>\n",
       "      <td>-7.976456</td>\n",
       "      <td>...</td>\n",
       "      <td>2.660886</td>\n",
       "      <td>3.668194</td>\n",
       "      <td>3.059879</td>\n",
       "      <td>2.167930</td>\n",
       "      <td>3.388354</td>\n",
       "      <td>3.547163</td>\n",
       "      <td>5.208120</td>\n",
       "      <td>5.214389</td>\n",
       "      <td>3.083698</td>\n",
       "      <td>3.613176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>-537.857350</td>\n",
       "      <td>132.463467</td>\n",
       "      <td>15.039651</td>\n",
       "      <td>17.587056</td>\n",
       "      <td>0.153911</td>\n",
       "      <td>-16.107528</td>\n",
       "      <td>-9.405851</td>\n",
       "      <td>1.305104</td>\n",
       "      <td>-11.788190</td>\n",
       "      <td>-16.191705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314444</td>\n",
       "      <td>0.032050</td>\n",
       "      <td>0.183975</td>\n",
       "      <td>1.286198</td>\n",
       "      <td>3.531481</td>\n",
       "      <td>-0.689179</td>\n",
       "      <td>0.978762</td>\n",
       "      <td>1.976808</td>\n",
       "      <td>0.923419</td>\n",
       "      <td>1.401621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>-367.191181</td>\n",
       "      <td>84.245960</td>\n",
       "      <td>17.285060</td>\n",
       "      <td>41.293951</td>\n",
       "      <td>4.594254</td>\n",
       "      <td>5.225729</td>\n",
       "      <td>-17.779283</td>\n",
       "      <td>-1.301197</td>\n",
       "      <td>0.770321</td>\n",
       "      <td>-8.781345</td>\n",
       "      <td>...</td>\n",
       "      <td>4.642564</td>\n",
       "      <td>6.850911</td>\n",
       "      <td>6.525017</td>\n",
       "      <td>6.046175</td>\n",
       "      <td>6.627548</td>\n",
       "      <td>6.348968</td>\n",
       "      <td>5.062342</td>\n",
       "      <td>6.036804</td>\n",
       "      <td>6.525787</td>\n",
       "      <td>4.515370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>-356.307027</td>\n",
       "      <td>72.585025</td>\n",
       "      <td>15.992023</td>\n",
       "      <td>44.839333</td>\n",
       "      <td>2.083604</td>\n",
       "      <td>6.769185</td>\n",
       "      <td>-20.210608</td>\n",
       "      <td>-2.029279</td>\n",
       "      <td>-2.718716</td>\n",
       "      <td>0.954320</td>\n",
       "      <td>...</td>\n",
       "      <td>5.493122</td>\n",
       "      <td>5.245116</td>\n",
       "      <td>5.753939</td>\n",
       "      <td>3.656642</td>\n",
       "      <td>1.958732</td>\n",
       "      <td>2.528291</td>\n",
       "      <td>2.533399</td>\n",
       "      <td>3.136919</td>\n",
       "      <td>2.225655</td>\n",
       "      <td>2.494422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>-294.064987</td>\n",
       "      <td>67.826550</td>\n",
       "      <td>-0.711737</td>\n",
       "      <td>32.634083</td>\n",
       "      <td>-7.998647</td>\n",
       "      <td>-0.993339</td>\n",
       "      <td>-10.638161</td>\n",
       "      <td>-0.815219</td>\n",
       "      <td>-11.688528</td>\n",
       "      <td>0.644370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385238</td>\n",
       "      <td>2.441582</td>\n",
       "      <td>3.419924</td>\n",
       "      <td>2.590114</td>\n",
       "      <td>2.308592</td>\n",
       "      <td>1.866217</td>\n",
       "      <td>3.443910</td>\n",
       "      <td>5.503410</td>\n",
       "      <td>2.807221</td>\n",
       "      <td>2.222786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>-584.313023</td>\n",
       "      <td>96.893916</td>\n",
       "      <td>29.197191</td>\n",
       "      <td>44.776808</td>\n",
       "      <td>7.547403</td>\n",
       "      <td>4.585640</td>\n",
       "      <td>-6.465312</td>\n",
       "      <td>0.270677</td>\n",
       "      <td>-4.520364</td>\n",
       "      <td>-10.090574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249142</td>\n",
       "      <td>2.276952</td>\n",
       "      <td>0.795975</td>\n",
       "      <td>3.669707</td>\n",
       "      <td>4.124699</td>\n",
       "      <td>2.248695</td>\n",
       "      <td>5.105586</td>\n",
       "      <td>3.808746</td>\n",
       "      <td>3.549122</td>\n",
       "      <td>4.208170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>-338.146217</td>\n",
       "      <td>109.372355</td>\n",
       "      <td>13.920223</td>\n",
       "      <td>33.369550</td>\n",
       "      <td>5.132312</td>\n",
       "      <td>2.439946</td>\n",
       "      <td>-28.102677</td>\n",
       "      <td>-6.727801</td>\n",
       "      <td>-0.976052</td>\n",
       "      <td>-15.288651</td>\n",
       "      <td>...</td>\n",
       "      <td>9.471755</td>\n",
       "      <td>9.140307</td>\n",
       "      <td>9.292207</td>\n",
       "      <td>7.426994</td>\n",
       "      <td>5.781572</td>\n",
       "      <td>6.442481</td>\n",
       "      <td>4.118801</td>\n",
       "      <td>3.803341</td>\n",
       "      <td>4.882173</td>\n",
       "      <td>3.320032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>-322.966166</td>\n",
       "      <td>94.319345</td>\n",
       "      <td>15.352224</td>\n",
       "      <td>41.629871</td>\n",
       "      <td>2.049926</td>\n",
       "      <td>1.462309</td>\n",
       "      <td>-21.611356</td>\n",
       "      <td>-7.455707</td>\n",
       "      <td>-8.713983</td>\n",
       "      <td>-2.991560</td>\n",
       "      <td>...</td>\n",
       "      <td>3.084132</td>\n",
       "      <td>3.332948</td>\n",
       "      <td>3.969742</td>\n",
       "      <td>3.727776</td>\n",
       "      <td>2.795976</td>\n",
       "      <td>2.424377</td>\n",
       "      <td>4.209958</td>\n",
       "      <td>6.077470</td>\n",
       "      <td>5.991613</td>\n",
       "      <td>4.875196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>-269.227462</td>\n",
       "      <td>81.260103</td>\n",
       "      <td>1.288338</td>\n",
       "      <td>27.528345</td>\n",
       "      <td>-17.977068</td>\n",
       "      <td>-12.434286</td>\n",
       "      <td>-13.867623</td>\n",
       "      <td>-10.106676</td>\n",
       "      <td>-18.582120</td>\n",
       "      <td>-5.513296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640435</td>\n",
       "      <td>2.405167</td>\n",
       "      <td>4.384703</td>\n",
       "      <td>1.077925</td>\n",
       "      <td>-0.344215</td>\n",
       "      <td>-0.384509</td>\n",
       "      <td>1.790997</td>\n",
       "      <td>4.362450</td>\n",
       "      <td>0.885165</td>\n",
       "      <td>0.831997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>-557.964881</td>\n",
       "      <td>119.105746</td>\n",
       "      <td>28.723866</td>\n",
       "      <td>36.506078</td>\n",
       "      <td>13.494842</td>\n",
       "      <td>-5.771920</td>\n",
       "      <td>-12.465300</td>\n",
       "      <td>-4.206241</td>\n",
       "      <td>-9.040893</td>\n",
       "      <td>-12.645042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096198</td>\n",
       "      <td>1.126412</td>\n",
       "      <td>-0.361065</td>\n",
       "      <td>2.047487</td>\n",
       "      <td>4.532744</td>\n",
       "      <td>2.755216</td>\n",
       "      <td>3.328837</td>\n",
       "      <td>3.454277</td>\n",
       "      <td>1.678651</td>\n",
       "      <td>1.096982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>-322.052214</td>\n",
       "      <td>87.304806</td>\n",
       "      <td>18.852072</td>\n",
       "      <td>22.347086</td>\n",
       "      <td>5.415433</td>\n",
       "      <td>2.634823</td>\n",
       "      <td>-15.122849</td>\n",
       "      <td>-4.381529</td>\n",
       "      <td>-2.904300</td>\n",
       "      <td>-12.093566</td>\n",
       "      <td>...</td>\n",
       "      <td>6.797799</td>\n",
       "      <td>8.086815</td>\n",
       "      <td>9.357588</td>\n",
       "      <td>7.789399</td>\n",
       "      <td>6.522356</td>\n",
       "      <td>6.153587</td>\n",
       "      <td>4.612971</td>\n",
       "      <td>5.000399</td>\n",
       "      <td>5.861700</td>\n",
       "      <td>4.160556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>-322.773766</td>\n",
       "      <td>95.852824</td>\n",
       "      <td>18.896094</td>\n",
       "      <td>29.532539</td>\n",
       "      <td>-0.784288</td>\n",
       "      <td>0.611706</td>\n",
       "      <td>-15.490798</td>\n",
       "      <td>-6.700054</td>\n",
       "      <td>-8.727936</td>\n",
       "      <td>-1.847062</td>\n",
       "      <td>...</td>\n",
       "      <td>3.421469</td>\n",
       "      <td>3.448301</td>\n",
       "      <td>4.427560</td>\n",
       "      <td>4.305747</td>\n",
       "      <td>3.357567</td>\n",
       "      <td>3.519138</td>\n",
       "      <td>3.159476</td>\n",
       "      <td>3.264066</td>\n",
       "      <td>3.892359</td>\n",
       "      <td>4.012164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>-262.375089</td>\n",
       "      <td>89.321457</td>\n",
       "      <td>0.936177</td>\n",
       "      <td>24.860885</td>\n",
       "      <td>-12.707221</td>\n",
       "      <td>-9.420169</td>\n",
       "      <td>-13.613567</td>\n",
       "      <td>-7.431204</td>\n",
       "      <td>-15.075917</td>\n",
       "      <td>-5.091093</td>\n",
       "      <td>...</td>\n",
       "      <td>2.972412</td>\n",
       "      <td>1.320135</td>\n",
       "      <td>1.714432</td>\n",
       "      <td>1.542031</td>\n",
       "      <td>2.730563</td>\n",
       "      <td>2.889894</td>\n",
       "      <td>1.042838</td>\n",
       "      <td>2.596208</td>\n",
       "      <td>4.835447</td>\n",
       "      <td>3.079378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>-585.743228</td>\n",
       "      <td>121.157467</td>\n",
       "      <td>38.472362</td>\n",
       "      <td>28.424604</td>\n",
       "      <td>9.901064</td>\n",
       "      <td>-9.169158</td>\n",
       "      <td>-9.050295</td>\n",
       "      <td>2.634156</td>\n",
       "      <td>-9.089717</td>\n",
       "      <td>-16.311628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.485874</td>\n",
       "      <td>-0.364697</td>\n",
       "      <td>-1.471591</td>\n",
       "      <td>-1.098680</td>\n",
       "      <td>0.787594</td>\n",
       "      <td>0.652533</td>\n",
       "      <td>2.190378</td>\n",
       "      <td>4.527128</td>\n",
       "      <td>4.739462</td>\n",
       "      <td>4.372875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>-305.916001</td>\n",
       "      <td>85.836176</td>\n",
       "      <td>11.930570</td>\n",
       "      <td>25.076284</td>\n",
       "      <td>5.713848</td>\n",
       "      <td>3.598567</td>\n",
       "      <td>-23.300195</td>\n",
       "      <td>-8.307825</td>\n",
       "      <td>0.219577</td>\n",
       "      <td>-10.783665</td>\n",
       "      <td>...</td>\n",
       "      <td>10.550657</td>\n",
       "      <td>9.945714</td>\n",
       "      <td>7.998956</td>\n",
       "      <td>5.587982</td>\n",
       "      <td>5.375407</td>\n",
       "      <td>7.034793</td>\n",
       "      <td>6.347784</td>\n",
       "      <td>5.571064</td>\n",
       "      <td>4.668942</td>\n",
       "      <td>2.050151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>-331.705535</td>\n",
       "      <td>87.759951</td>\n",
       "      <td>10.335712</td>\n",
       "      <td>43.407552</td>\n",
       "      <td>4.802627</td>\n",
       "      <td>4.496194</td>\n",
       "      <td>-20.245555</td>\n",
       "      <td>-9.257233</td>\n",
       "      <td>-8.499820</td>\n",
       "      <td>2.881831</td>\n",
       "      <td>...</td>\n",
       "      <td>2.755090</td>\n",
       "      <td>1.676381</td>\n",
       "      <td>2.831628</td>\n",
       "      <td>4.295623</td>\n",
       "      <td>5.495796</td>\n",
       "      <td>4.496833</td>\n",
       "      <td>5.516509</td>\n",
       "      <td>5.126643</td>\n",
       "      <td>4.459870</td>\n",
       "      <td>4.965587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>-281.330507</td>\n",
       "      <td>79.542103</td>\n",
       "      <td>1.883901</td>\n",
       "      <td>28.203205</td>\n",
       "      <td>-13.836293</td>\n",
       "      <td>-11.660917</td>\n",
       "      <td>-19.415583</td>\n",
       "      <td>-6.872575</td>\n",
       "      <td>-12.946230</td>\n",
       "      <td>-2.691450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256227</td>\n",
       "      <td>0.459824</td>\n",
       "      <td>1.052256</td>\n",
       "      <td>2.107690</td>\n",
       "      <td>1.915175</td>\n",
       "      <td>-0.777330</td>\n",
       "      <td>-0.549973</td>\n",
       "      <td>2.404471</td>\n",
       "      <td>2.242177</td>\n",
       "      <td>0.466355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>-562.055790</td>\n",
       "      <td>107.554131</td>\n",
       "      <td>26.853017</td>\n",
       "      <td>25.277784</td>\n",
       "      <td>5.072138</td>\n",
       "      <td>-0.991708</td>\n",
       "      <td>-12.561367</td>\n",
       "      <td>-4.152792</td>\n",
       "      <td>-8.706542</td>\n",
       "      <td>-13.637620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653458</td>\n",
       "      <td>-0.560693</td>\n",
       "      <td>0.263442</td>\n",
       "      <td>1.797453</td>\n",
       "      <td>1.149249</td>\n",
       "      <td>-0.706918</td>\n",
       "      <td>2.148012</td>\n",
       "      <td>2.364498</td>\n",
       "      <td>1.906818</td>\n",
       "      <td>2.230867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>-299.574982</td>\n",
       "      <td>93.880581</td>\n",
       "      <td>10.768436</td>\n",
       "      <td>20.881181</td>\n",
       "      <td>-3.954853</td>\n",
       "      <td>4.802007</td>\n",
       "      <td>-19.645370</td>\n",
       "      <td>-7.703498</td>\n",
       "      <td>-1.346626</td>\n",
       "      <td>-12.073581</td>\n",
       "      <td>...</td>\n",
       "      <td>10.486620</td>\n",
       "      <td>7.277603</td>\n",
       "      <td>5.678093</td>\n",
       "      <td>3.769067</td>\n",
       "      <td>4.604803</td>\n",
       "      <td>7.630280</td>\n",
       "      <td>6.978910</td>\n",
       "      <td>6.068219</td>\n",
       "      <td>3.587877</td>\n",
       "      <td>1.718973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>-310.627811</td>\n",
       "      <td>81.784518</td>\n",
       "      <td>12.504211</td>\n",
       "      <td>27.538303</td>\n",
       "      <td>0.193137</td>\n",
       "      <td>6.860135</td>\n",
       "      <td>-13.620145</td>\n",
       "      <td>-13.676087</td>\n",
       "      <td>-8.615488</td>\n",
       "      <td>1.435684</td>\n",
       "      <td>...</td>\n",
       "      <td>2.646777</td>\n",
       "      <td>4.147677</td>\n",
       "      <td>6.551423</td>\n",
       "      <td>7.165690</td>\n",
       "      <td>5.395996</td>\n",
       "      <td>2.185433</td>\n",
       "      <td>3.086167</td>\n",
       "      <td>3.127119</td>\n",
       "      <td>4.276848</td>\n",
       "      <td>5.810610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>-268.209212</td>\n",
       "      <td>85.083098</td>\n",
       "      <td>4.408130</td>\n",
       "      <td>18.682359</td>\n",
       "      <td>-26.025329</td>\n",
       "      <td>-7.332198</td>\n",
       "      <td>-13.394508</td>\n",
       "      <td>-7.121139</td>\n",
       "      <td>-14.417594</td>\n",
       "      <td>-2.936828</td>\n",
       "      <td>...</td>\n",
       "      <td>4.214722</td>\n",
       "      <td>3.311304</td>\n",
       "      <td>1.893023</td>\n",
       "      <td>0.605350</td>\n",
       "      <td>1.732259</td>\n",
       "      <td>1.291515</td>\n",
       "      <td>0.629140</td>\n",
       "      <td>1.236806</td>\n",
       "      <td>0.098758</td>\n",
       "      <td>1.097687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>-560.237789</td>\n",
       "      <td>117.406698</td>\n",
       "      <td>30.127662</td>\n",
       "      <td>29.382634</td>\n",
       "      <td>-8.456646</td>\n",
       "      <td>-9.427640</td>\n",
       "      <td>-10.459451</td>\n",
       "      <td>-0.303098</td>\n",
       "      <td>-9.703229</td>\n",
       "      <td>-14.502365</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.790963</td>\n",
       "      <td>0.514538</td>\n",
       "      <td>0.386544</td>\n",
       "      <td>0.825460</td>\n",
       "      <td>2.864297</td>\n",
       "      <td>0.514232</td>\n",
       "      <td>3.424520</td>\n",
       "      <td>4.295079</td>\n",
       "      <td>2.227084</td>\n",
       "      <td>2.408897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1          2          3          4          5   \\\n",
       "0   -320.564897  110.933802  12.457851  34.670754  11.628866  -2.938117   \n",
       "1   -244.658678  104.249248   0.657434  41.458732  -1.098887   3.049909   \n",
       "2   -269.983041  100.689812   4.812852  44.206061  -9.372619 -17.481868   \n",
       "3   -564.540326  104.181913  26.302574  44.703341  17.196513  -4.453330   \n",
       "4   -299.408527  120.059306  -7.834544  18.676239  14.225895  -2.376180   \n",
       "5   -268.415152  102.647185  -6.831019  21.777451   5.504902   2.677995   \n",
       "6   -270.433462  102.251276  -7.766242  27.726690  -2.322103 -15.604451   \n",
       "7   -578.971084  153.140748  12.843857  13.583781   5.480952  -4.754079   \n",
       "8   -337.160749   96.866740   4.881764  26.825063  10.724669  -2.182416   \n",
       "9   -313.978572   82.632110   3.121088  25.119724   6.733781   2.579732   \n",
       "10  -306.813008   91.202088   4.837953  35.295787  -4.541257 -15.186219   \n",
       "11  -619.683106  107.612664  29.545496  32.781815  13.113059  -2.023275   \n",
       "12  -287.823871  101.515510   6.410148  15.656604   7.395868  -1.489299   \n",
       "13  -262.711126   84.184149   3.692296  30.717997   0.333233   2.032098   \n",
       "14  -274.682785   94.768747   3.583395  31.612113  -2.270698 -13.238559   \n",
       "15  -545.899780   94.282328  22.473580  21.962141  11.071408   2.064249   \n",
       "16  -297.149791   93.358736   0.129330  22.744894  12.982417  -2.121561   \n",
       "17  -237.829004   85.642562  -1.482641  30.883268  -4.640333   1.335876   \n",
       "18  -260.920000   94.252207  -0.628142  35.111116 -10.885650 -11.894777   \n",
       "19  -554.916555  119.247173  20.049515  24.732460   4.934111  -6.313914   \n",
       "20  -310.466520  111.655076   3.510758  28.038363   2.558900   0.751742   \n",
       "21  -276.635790   93.746689  -3.646088  31.032646   6.120393   1.945582   \n",
       "22  -229.980376   92.734781 -10.102935  38.225387 -12.808887  -8.081135   \n",
       "23  -556.890651  114.073488  21.399754  37.684455   1.765665  -5.789695   \n",
       "24  -311.721812  109.377804  -6.253777  20.515531   1.536390  -6.694665   \n",
       "25  -277.022496   90.405723  -5.277691  18.908560  -1.914564   0.759638   \n",
       "26  -208.624474  104.628808 -13.943393  26.271492 -15.843213 -11.005214   \n",
       "27  -467.870606  150.702668   6.940878  13.059629  -6.794840 -23.409382   \n",
       "28  -291.872633   80.724728   8.813734  24.354779  -3.727562  -2.716657   \n",
       "29  -267.604067   76.182156   6.519338  32.557985  -1.324882   3.437367   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "450 -270.905044   83.241844   5.825305  34.028753 -20.226561  -4.650805   \n",
       "451 -576.532048   98.481914  22.043391  35.167535  -0.444776   0.608610   \n",
       "452 -340.869293   91.635405  15.328301  33.700820  -0.429162   6.658317   \n",
       "453 -323.622521   67.875767   9.816173  33.444895  -7.511998   2.373042   \n",
       "454 -267.993419   86.631092   3.263370  28.449955 -24.136090 -11.551452   \n",
       "455 -573.573091  113.516464  27.415844  35.419841   1.043905  -6.554022   \n",
       "456 -306.572572  109.670172  11.963575  16.871229   8.903087   1.114646   \n",
       "457 -315.045325   94.320807   2.107157  22.853063  -4.755627   0.400240   \n",
       "458 -261.098647   98.367981  -2.026808  19.736065 -13.907652  -9.889293   \n",
       "459 -537.857350  132.463467  15.039651  17.587056   0.153911 -16.107528   \n",
       "460 -367.191181   84.245960  17.285060  41.293951   4.594254   5.225729   \n",
       "461 -356.307027   72.585025  15.992023  44.839333   2.083604   6.769185   \n",
       "462 -294.064987   67.826550  -0.711737  32.634083  -7.998647  -0.993339   \n",
       "463 -584.313023   96.893916  29.197191  44.776808   7.547403   4.585640   \n",
       "464 -338.146217  109.372355  13.920223  33.369550   5.132312   2.439946   \n",
       "465 -322.966166   94.319345  15.352224  41.629871   2.049926   1.462309   \n",
       "466 -269.227462   81.260103   1.288338  27.528345 -17.977068 -12.434286   \n",
       "467 -557.964881  119.105746  28.723866  36.506078  13.494842  -5.771920   \n",
       "468 -322.052214   87.304806  18.852072  22.347086   5.415433   2.634823   \n",
       "469 -322.773766   95.852824  18.896094  29.532539  -0.784288   0.611706   \n",
       "470 -262.375089   89.321457   0.936177  24.860885 -12.707221  -9.420169   \n",
       "471 -585.743228  121.157467  38.472362  28.424604   9.901064  -9.169158   \n",
       "472 -305.916001   85.836176  11.930570  25.076284   5.713848   3.598567   \n",
       "473 -331.705535   87.759951  10.335712  43.407552   4.802627   4.496194   \n",
       "474 -281.330507   79.542103   1.883901  28.203205 -13.836293 -11.660917   \n",
       "475 -562.055790  107.554131  26.853017  25.277784   5.072138  -0.991708   \n",
       "476 -299.574982   93.880581  10.768436  20.881181  -3.954853   4.802007   \n",
       "477 -310.627811   81.784518  12.504211  27.538303   0.193137   6.860135   \n",
       "478 -268.209212   85.083098   4.408130  18.682359 -26.025329  -7.332198   \n",
       "479 -560.237789  117.406698  30.127662  29.382634  -8.456646  -9.427640   \n",
       "\n",
       "            6          7          8          9   ...         30        31  \\\n",
       "0   -24.859946  -2.633693  -0.919507 -11.532021  ...   1.452810  1.783171   \n",
       "1   -23.316795  -7.371824  -7.313963  -5.459172  ...   2.513106  4.278307   \n",
       "2     0.876082   2.226196 -16.333266  -3.812531  ...   2.308230  4.117299   \n",
       "3   -15.700971  -2.773550  -5.163968 -11.310603  ...  -2.580128 -1.982804   \n",
       "4   -20.357823   3.748768   4.587472 -11.664485  ...   1.049761  1.525852   \n",
       "5   -17.891163  -4.412988  -3.229257   0.431965  ...  -1.543827  0.943443   \n",
       "6     0.235773   0.016892 -12.838433  -0.243834  ...   0.540800  1.750614   \n",
       "7    -7.061755   1.223524  -7.304688 -13.289818  ...  -0.529214 -0.245226   \n",
       "8   -13.945372   7.127122  -0.079204  -7.433390  ...   2.997824  3.103378   \n",
       "9   -13.853373   0.178914  -1.616934   1.959738  ...   0.892974  0.141898   \n",
       "10   -1.853829   2.134356  -8.612269   0.580285  ...   2.296859  3.049797   \n",
       "11   -6.724471   3.051477  -1.109710  -7.053607  ...  -1.463808  0.568521   \n",
       "12  -24.872378  -5.148656  -0.039547 -10.816283  ...   0.094653  1.922031   \n",
       "13  -20.818370  -8.069312  -6.483575  -4.030453  ...  -0.720971  0.002464   \n",
       "14   -8.697503  -3.330329 -13.886461  -2.766569  ...  -0.133236  0.832539   \n",
       "15   -9.974123  -5.297741  -6.165273  -9.604840  ...   1.021445  3.128254   \n",
       "16  -23.176872  -3.080107  -3.018409 -14.218085  ...   1.784480  2.797313   \n",
       "17  -20.403958  -5.666015  -8.458400  -4.095452  ...   1.637515  3.088781   \n",
       "18   -8.281734  -2.487652 -13.697984  -6.830959  ...   1.896655  4.731171   \n",
       "19  -15.549304  -7.235226  -9.178871 -13.237397  ...  -0.994061  0.273503   \n",
       "20  -22.066307  -3.129726  -0.003739 -11.526986  ...  -0.164121  0.559290   \n",
       "21  -19.112421  -4.126155  -3.454874  -2.151538  ...  -1.823949 -0.154802   \n",
       "22   -9.241305  -0.922913 -11.749296  -4.356548  ...   0.920867  0.249137   \n",
       "23  -11.279757  -0.880750  -7.797464 -12.325886  ...  -0.228329  0.142309   \n",
       "24  -16.409074   3.595946  -3.917058 -10.481376  ...   1.552881  2.468394   \n",
       "25  -13.838499  -0.469484  -6.623128   2.865756  ...   0.743524  1.607718   \n",
       "26  -13.288870  -2.621522 -10.667197  -0.191851  ...   3.211881  3.033859   \n",
       "27  -11.542217   2.467216 -15.035852 -23.422054  ...  -1.919832 -0.469279   \n",
       "28  -20.333166  -4.286414  -1.203566  -7.991472  ...   4.803417  8.918398   \n",
       "29  -17.131312  -6.799114  -7.417711  -6.034486  ...   3.667866  5.165975   \n",
       "..         ...        ...        ...        ...  ...        ...       ...   \n",
       "450 -12.991530  -2.309803 -14.578473  -4.914250  ...   2.812163  3.093380   \n",
       "451  -7.506805  -4.842706 -13.191851 -12.959278  ...   4.426111  5.177279   \n",
       "452 -25.491608  -3.136858   4.379834 -12.477610  ...   7.124014  7.930197   \n",
       "453 -22.135091  -2.645947  -5.675133  -2.786183  ...   1.560307  2.373463   \n",
       "454 -13.266007  -3.861459 -14.582571  -2.435104  ...   2.727813  2.064279   \n",
       "455  -8.322166   0.526996 -10.460542 -15.149407  ...   0.347566  0.154334   \n",
       "456 -19.945104  -3.327016  -1.510647  -9.728044  ...   3.622234  2.925757   \n",
       "457 -21.271273  -6.169301  -7.937066  -3.165314  ...   3.231306  3.971601   \n",
       "458 -10.083964  -5.183913 -14.426718  -7.976456  ...   2.660886  3.668194   \n",
       "459  -9.405851   1.305104 -11.788190 -16.191705  ...   0.314444  0.032050   \n",
       "460 -17.779283  -1.301197   0.770321  -8.781345  ...   4.642564  6.850911   \n",
       "461 -20.210608  -2.029279  -2.718716   0.954320  ...   5.493122  5.245116   \n",
       "462 -10.638161  -0.815219 -11.688528   0.644370  ...   0.385238  2.441582   \n",
       "463  -6.465312   0.270677  -4.520364 -10.090574  ...   0.249142  2.276952   \n",
       "464 -28.102677  -6.727801  -0.976052 -15.288651  ...   9.471755  9.140307   \n",
       "465 -21.611356  -7.455707  -8.713983  -2.991560  ...   3.084132  3.332948   \n",
       "466 -13.867623 -10.106676 -18.582120  -5.513296  ...  -0.640435  2.405167   \n",
       "467 -12.465300  -4.206241  -9.040893 -12.645042  ...   0.096198  1.126412   \n",
       "468 -15.122849  -4.381529  -2.904300 -12.093566  ...   6.797799  8.086815   \n",
       "469 -15.490798  -6.700054  -8.727936  -1.847062  ...   3.421469  3.448301   \n",
       "470 -13.613567  -7.431204 -15.075917  -5.091093  ...   2.972412  1.320135   \n",
       "471  -9.050295   2.634156  -9.089717 -16.311628  ...  -0.485874 -0.364697   \n",
       "472 -23.300195  -8.307825   0.219577 -10.783665  ...  10.550657  9.945714   \n",
       "473 -20.245555  -9.257233  -8.499820   2.881831  ...   2.755090  1.676381   \n",
       "474 -19.415583  -6.872575 -12.946230  -2.691450  ...   0.256227  0.459824   \n",
       "475 -12.561367  -4.152792  -8.706542 -13.637620  ...  -0.653458 -0.560693   \n",
       "476 -19.645370  -7.703498  -1.346626 -12.073581  ...  10.486620  7.277603   \n",
       "477 -13.620145 -13.676087  -8.615488   1.435684  ...   2.646777  4.147677   \n",
       "478 -13.394508  -7.121139 -14.417594  -2.936828  ...   4.214722  3.311304   \n",
       "479 -10.459451  -0.303098  -9.703229 -14.502365  ...  -1.790963  0.514538   \n",
       "\n",
       "           32        33        34        35        36        37        38  \\\n",
       "0    3.263025  2.756852  3.496057  5.099579  4.885279  5.633801  4.365917   \n",
       "1    4.096044  2.962424  3.240562  0.578126  1.794270  3.656604  4.363981   \n",
       "2    3.856427  4.716765  6.389915  5.546877  4.826904  4.839705  4.608056   \n",
       "3   -0.331088 -2.861281 -2.723364  0.419460  2.015126  1.980087 -0.398496   \n",
       "4    1.987423  0.174960 -0.661590 -0.089371 -0.488558  1.521584  1.066419   \n",
       "5   -0.501339 -0.080925  0.131035 -1.918740  1.268647  2.679410  2.754248   \n",
       "6    2.308556  1.087831  0.177460 -1.091181 -0.377372 -0.434003 -0.327013   \n",
       "7   -0.666285 -2.915523 -1.297646 -1.285307 -1.099492  0.359853 -2.147516   \n",
       "8    4.924483  6.009026  6.636278  6.517982  6.425938  4.764662  3.565150   \n",
       "9    1.821391  2.529989  1.968246  2.439394  3.644267  3.000721  4.114735   \n",
       "10   2.827478  2.024559  1.230836  1.951512  3.221304  4.017343  4.348317   \n",
       "11  -0.458534 -4.041868 -0.373413  1.693426  3.119295  6.467952  6.222947   \n",
       "12   2.069620  1.789086  1.402842  1.192773  2.013896  2.935015  3.895297   \n",
       "13  -0.489348  0.585226  2.560084  2.873368  2.866207  2.956850  3.221912   \n",
       "14  -0.011741 -0.718816  1.454612  3.247061  4.824512  5.183765  4.432016   \n",
       "15   2.563572  0.236307  0.642036 -1.301531 -0.757510  0.594631  0.517790   \n",
       "16   0.787051 -0.474089  1.092980  0.932278  0.742255  1.795864  3.188131   \n",
       "17   3.316565  4.343492  5.712959  4.264993  6.487091  7.751737  8.683150   \n",
       "18   5.223400  4.126560  3.545781  3.134574  4.163274  4.238909  3.606129   \n",
       "19   0.141774 -2.123241 -1.487538 -1.147595 -0.665070  1.203635  0.748611   \n",
       "20   0.553784  1.427426  3.409991  5.172947  5.295261  7.167189  7.946955   \n",
       "21   1.964497  1.255755  0.608359  0.679066  0.849191  1.283594  1.590320   \n",
       "22   2.279387  2.188748  2.733104  2.431164  2.090510  3.369304  2.246630   \n",
       "23  -0.065403 -2.161767 -0.434520 -0.591449  0.751506  1.570371 -1.204428   \n",
       "24   3.484781  2.921893  3.235744  3.604677  4.461789  6.496880  8.847790   \n",
       "25   1.737711  2.482907  3.338550  2.707236  2.611088  0.121514  0.629194   \n",
       "26   4.159673  4.727725  3.593283  3.313064  3.354987  2.968107  2.460999   \n",
       "27  -4.088092 -5.701839 -0.011955 -4.946802 -1.943001 -3.436878 -6.409079   \n",
       "28   8.608139  7.215964  6.221586  5.591549  5.749485  7.318852  6.561183   \n",
       "29   6.129603  3.540575  0.998083  0.595110  1.790990  2.636777  3.801948   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "450  1.632940 -0.877966  2.241036  1.710399  1.639457  4.625621  2.235594   \n",
       "451  2.554160  2.186716  5.343213  3.646216  3.993214  2.326687  0.506513   \n",
       "452  8.842382  6.641419  6.830562  6.939276  5.250627  5.412664  3.379724   \n",
       "453  3.282973  2.033909  1.991121  1.484362  1.958998  2.029326  1.210597   \n",
       "454  3.522736  2.007128  2.733028  1.805694  2.487521  3.761587  2.564815   \n",
       "455  0.656173 -0.561989  1.486450 -0.652063  0.489430  2.628116  1.589769   \n",
       "456  5.076261  4.986268  4.139367  5.599611  7.593524  7.631419  6.697954   \n",
       "457  5.411091  3.689788  2.697327  3.410430  3.242359  2.543476  2.200438   \n",
       "458  3.059879  2.167930  3.388354  3.547163  5.208120  5.214389  3.083698   \n",
       "459  0.183975  1.286198  3.531481 -0.689179  0.978762  1.976808  0.923419   \n",
       "460  6.525017  6.046175  6.627548  6.348968  5.062342  6.036804  6.525787   \n",
       "461  5.753939  3.656642  1.958732  2.528291  2.533399  3.136919  2.225655   \n",
       "462  3.419924  2.590114  2.308592  1.866217  3.443910  5.503410  2.807221   \n",
       "463  0.795975  3.669707  4.124699  2.248695  5.105586  3.808746  3.549122   \n",
       "464  9.292207  7.426994  5.781572  6.442481  4.118801  3.803341  4.882173   \n",
       "465  3.969742  3.727776  2.795976  2.424377  4.209958  6.077470  5.991613   \n",
       "466  4.384703  1.077925 -0.344215 -0.384509  1.790997  4.362450  0.885165   \n",
       "467 -0.361065  2.047487  4.532744  2.755216  3.328837  3.454277  1.678651   \n",
       "468  9.357588  7.789399  6.522356  6.153587  4.612971  5.000399  5.861700   \n",
       "469  4.427560  4.305747  3.357567  3.519138  3.159476  3.264066  3.892359   \n",
       "470  1.714432  1.542031  2.730563  2.889894  1.042838  2.596208  4.835447   \n",
       "471 -1.471591 -1.098680  0.787594  0.652533  2.190378  4.527128  4.739462   \n",
       "472  7.998956  5.587982  5.375407  7.034793  6.347784  5.571064  4.668942   \n",
       "473  2.831628  4.295623  5.495796  4.496833  5.516509  5.126643  4.459870   \n",
       "474  1.052256  2.107690  1.915175 -0.777330 -0.549973  2.404471  2.242177   \n",
       "475  0.263442  1.797453  1.149249 -0.706918  2.148012  2.364498  1.906818   \n",
       "476  5.678093  3.769067  4.604803  7.630280  6.978910  6.068219  3.587877   \n",
       "477  6.551423  7.165690  5.395996  2.185433  3.086167  3.127119  4.276848   \n",
       "478  1.893023  0.605350  1.732259  1.291515  0.629140  1.236806  0.098758   \n",
       "479  0.386544  0.825460  2.864297  0.514232  3.424520  4.295079  2.227084   \n",
       "\n",
       "           39  \n",
       "0    3.453820  \n",
       "1    3.638848  \n",
       "2    4.928732  \n",
       "3   -0.039357  \n",
       "4   -0.393785  \n",
       "5    3.670862  \n",
       "6   -0.177506  \n",
       "7   -1.808127  \n",
       "8    4.918953  \n",
       "9    5.142286  \n",
       "10   3.054402  \n",
       "11   7.158575  \n",
       "12   5.941611  \n",
       "13   3.025061  \n",
       "14   2.757248  \n",
       "15   2.317307  \n",
       "16   4.286123  \n",
       "17   8.666596  \n",
       "18   2.932312  \n",
       "19   1.120355  \n",
       "20   6.104829  \n",
       "21   1.617642  \n",
       "22   2.007894  \n",
       "23   0.389953  \n",
       "24   8.812864  \n",
       "25   1.456162  \n",
       "26   1.700034  \n",
       "27  -2.927387  \n",
       "28   4.343619  \n",
       "29   3.991086  \n",
       "..        ...  \n",
       "450  2.497927  \n",
       "451  3.333642  \n",
       "452  3.157793  \n",
       "453  1.815508  \n",
       "454  3.633575  \n",
       "455  2.397164  \n",
       "456  5.786440  \n",
       "457  1.653810  \n",
       "458  3.613176  \n",
       "459  1.401621  \n",
       "460  4.515370  \n",
       "461  2.494422  \n",
       "462  2.222786  \n",
       "463  4.208170  \n",
       "464  3.320032  \n",
       "465  4.875196  \n",
       "466  0.831997  \n",
       "467  1.096982  \n",
       "468  4.160556  \n",
       "469  4.012164  \n",
       "470  3.079378  \n",
       "471  4.372875  \n",
       "472  2.050151  \n",
       "473  4.965587  \n",
       "474  0.466355  \n",
       "475  2.230867  \n",
       "476  1.718973  \n",
       "477  5.810610  \n",
       "478  1.097687  \n",
       "479  2.408897  \n",
       "\n",
       "[480 rows x 40 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(df['feature'].values.tolist())\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.concat([df3,labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-320.564897</td>\n",
       "      <td>110.933802</td>\n",
       "      <td>12.457851</td>\n",
       "      <td>34.670754</td>\n",
       "      <td>11.628866</td>\n",
       "      <td>-2.938117</td>\n",
       "      <td>-24.859946</td>\n",
       "      <td>-2.633693</td>\n",
       "      <td>-0.919507</td>\n",
       "      <td>-11.532021</td>\n",
       "      <td>...</td>\n",
       "      <td>1.783171</td>\n",
       "      <td>3.263025</td>\n",
       "      <td>2.756852</td>\n",
       "      <td>3.496057</td>\n",
       "      <td>5.099579</td>\n",
       "      <td>4.885279</td>\n",
       "      <td>5.633801</td>\n",
       "      <td>4.365917</td>\n",
       "      <td>3.453820</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-244.658678</td>\n",
       "      <td>104.249248</td>\n",
       "      <td>0.657434</td>\n",
       "      <td>41.458732</td>\n",
       "      <td>-1.098887</td>\n",
       "      <td>3.049909</td>\n",
       "      <td>-23.316795</td>\n",
       "      <td>-7.371824</td>\n",
       "      <td>-7.313963</td>\n",
       "      <td>-5.459172</td>\n",
       "      <td>...</td>\n",
       "      <td>4.278307</td>\n",
       "      <td>4.096044</td>\n",
       "      <td>2.962424</td>\n",
       "      <td>3.240562</td>\n",
       "      <td>0.578126</td>\n",
       "      <td>1.794270</td>\n",
       "      <td>3.656604</td>\n",
       "      <td>4.363981</td>\n",
       "      <td>3.638848</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-269.983041</td>\n",
       "      <td>100.689812</td>\n",
       "      <td>4.812852</td>\n",
       "      <td>44.206061</td>\n",
       "      <td>-9.372619</td>\n",
       "      <td>-17.481868</td>\n",
       "      <td>0.876082</td>\n",
       "      <td>2.226196</td>\n",
       "      <td>-16.333266</td>\n",
       "      <td>-3.812531</td>\n",
       "      <td>...</td>\n",
       "      <td>4.117299</td>\n",
       "      <td>3.856427</td>\n",
       "      <td>4.716765</td>\n",
       "      <td>6.389915</td>\n",
       "      <td>5.546877</td>\n",
       "      <td>4.826904</td>\n",
       "      <td>4.839705</td>\n",
       "      <td>4.608056</td>\n",
       "      <td>4.928732</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-564.540326</td>\n",
       "      <td>104.181913</td>\n",
       "      <td>26.302574</td>\n",
       "      <td>44.703341</td>\n",
       "      <td>17.196513</td>\n",
       "      <td>-4.453330</td>\n",
       "      <td>-15.700971</td>\n",
       "      <td>-2.773550</td>\n",
       "      <td>-5.163968</td>\n",
       "      <td>-11.310603</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.982804</td>\n",
       "      <td>-0.331088</td>\n",
       "      <td>-2.861281</td>\n",
       "      <td>-2.723364</td>\n",
       "      <td>0.419460</td>\n",
       "      <td>2.015126</td>\n",
       "      <td>1.980087</td>\n",
       "      <td>-0.398496</td>\n",
       "      <td>-0.039357</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-299.408527</td>\n",
       "      <td>120.059306</td>\n",
       "      <td>-7.834544</td>\n",
       "      <td>18.676239</td>\n",
       "      <td>14.225895</td>\n",
       "      <td>-2.376180</td>\n",
       "      <td>-20.357823</td>\n",
       "      <td>3.748768</td>\n",
       "      <td>4.587472</td>\n",
       "      <td>-11.664485</td>\n",
       "      <td>...</td>\n",
       "      <td>1.525852</td>\n",
       "      <td>1.987423</td>\n",
       "      <td>0.174960</td>\n",
       "      <td>-0.661590</td>\n",
       "      <td>-0.089371</td>\n",
       "      <td>-0.488558</td>\n",
       "      <td>1.521584</td>\n",
       "      <td>1.066419</td>\n",
       "      <td>-0.393785</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1          2          3          4          5  \\\n",
       "0 -320.564897  110.933802  12.457851  34.670754  11.628866  -2.938117   \n",
       "1 -244.658678  104.249248   0.657434  41.458732  -1.098887   3.049909   \n",
       "2 -269.983041  100.689812   4.812852  44.206061  -9.372619 -17.481868   \n",
       "3 -564.540326  104.181913  26.302574  44.703341  17.196513  -4.453330   \n",
       "4 -299.408527  120.059306  -7.834544  18.676239  14.225895  -2.376180   \n",
       "\n",
       "           6         7          8          9  ...        31        32  \\\n",
       "0 -24.859946 -2.633693  -0.919507 -11.532021  ...  1.783171  3.263025   \n",
       "1 -23.316795 -7.371824  -7.313963  -5.459172  ...  4.278307  4.096044   \n",
       "2   0.876082  2.226196 -16.333266  -3.812531  ...  4.117299  3.856427   \n",
       "3 -15.700971 -2.773550  -5.163968 -11.310603  ... -1.982804 -0.331088   \n",
       "4 -20.357823  3.748768   4.587472 -11.664485  ...  1.525852  1.987423   \n",
       "\n",
       "         33        34        35        36        37        38        39  \\\n",
       "0  2.756852  3.496057  5.099579  4.885279  5.633801  4.365917  3.453820   \n",
       "1  2.962424  3.240562  0.578126  1.794270  3.656604  4.363981  3.638848   \n",
       "2  4.716765  6.389915  5.546877  4.826904  4.839705  4.608056  4.928732   \n",
       "3 -2.861281 -2.723364  0.419460  2.015126  1.980087 -0.398496 -0.039357   \n",
       "4  0.174960 -0.661590 -0.089371 -0.488558  1.521584  1.066419 -0.393785   \n",
       "\n",
       "   emotion  \n",
       "0    angry  \n",
       "1    angry  \n",
       "2    angry  \n",
       "3    angry  \n",
       "4    angry  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnewdf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-287.823871</td>\n",
       "      <td>101.515510</td>\n",
       "      <td>6.410148</td>\n",
       "      <td>15.656604</td>\n",
       "      <td>7.395868</td>\n",
       "      <td>-1.489299</td>\n",
       "      <td>-24.872378</td>\n",
       "      <td>-5.148656</td>\n",
       "      <td>-0.039547</td>\n",
       "      <td>-10.816283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.922031</td>\n",
       "      <td>2.069620</td>\n",
       "      <td>1.789086</td>\n",
       "      <td>1.402842</td>\n",
       "      <td>1.192773</td>\n",
       "      <td>2.013896</td>\n",
       "      <td>2.935015</td>\n",
       "      <td>3.895297</td>\n",
       "      <td>5.941611</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>-432.127466</td>\n",
       "      <td>130.331011</td>\n",
       "      <td>15.421203</td>\n",
       "      <td>32.910652</td>\n",
       "      <td>23.467361</td>\n",
       "      <td>-1.484577</td>\n",
       "      <td>-19.036167</td>\n",
       "      <td>0.314333</td>\n",
       "      <td>5.954609</td>\n",
       "      <td>-6.524187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764855</td>\n",
       "      <td>2.257194</td>\n",
       "      <td>1.738118</td>\n",
       "      <td>1.038085</td>\n",
       "      <td>1.238373</td>\n",
       "      <td>1.734420</td>\n",
       "      <td>2.330078</td>\n",
       "      <td>1.231918</td>\n",
       "      <td>1.440224</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-340.495581</td>\n",
       "      <td>96.439813</td>\n",
       "      <td>21.219168</td>\n",
       "      <td>42.652258</td>\n",
       "      <td>-1.219512</td>\n",
       "      <td>12.036752</td>\n",
       "      <td>-25.907954</td>\n",
       "      <td>-3.376129</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>-12.693077</td>\n",
       "      <td>...</td>\n",
       "      <td>4.214099</td>\n",
       "      <td>7.637096</td>\n",
       "      <td>11.883751</td>\n",
       "      <td>15.016872</td>\n",
       "      <td>15.636499</td>\n",
       "      <td>12.301138</td>\n",
       "      <td>8.042070</td>\n",
       "      <td>5.284950</td>\n",
       "      <td>3.425573</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-465.225705</td>\n",
       "      <td>151.346358</td>\n",
       "      <td>28.000421</td>\n",
       "      <td>38.127225</td>\n",
       "      <td>9.868115</td>\n",
       "      <td>0.870507</td>\n",
       "      <td>-9.655647</td>\n",
       "      <td>-6.929020</td>\n",
       "      <td>5.113030</td>\n",
       "      <td>4.176812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538939</td>\n",
       "      <td>-0.411754</td>\n",
       "      <td>1.952185</td>\n",
       "      <td>2.514050</td>\n",
       "      <td>0.700188</td>\n",
       "      <td>0.558373</td>\n",
       "      <td>-0.027693</td>\n",
       "      <td>1.218584</td>\n",
       "      <td>1.688338</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>-422.190425</td>\n",
       "      <td>128.785296</td>\n",
       "      <td>25.661881</td>\n",
       "      <td>26.935536</td>\n",
       "      <td>17.211634</td>\n",
       "      <td>3.511938</td>\n",
       "      <td>-14.742881</td>\n",
       "      <td>0.687592</td>\n",
       "      <td>1.321263</td>\n",
       "      <td>-5.509755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684991</td>\n",
       "      <td>0.407341</td>\n",
       "      <td>1.436117</td>\n",
       "      <td>0.907008</td>\n",
       "      <td>-0.735813</td>\n",
       "      <td>-0.340283</td>\n",
       "      <td>1.214350</td>\n",
       "      <td>2.179666</td>\n",
       "      <td>1.231693</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-405.978889</td>\n",
       "      <td>107.061765</td>\n",
       "      <td>31.556338</td>\n",
       "      <td>40.077664</td>\n",
       "      <td>2.951004</td>\n",
       "      <td>-13.124174</td>\n",
       "      <td>5.861604</td>\n",
       "      <td>2.698900</td>\n",
       "      <td>-4.866779</td>\n",
       "      <td>1.311889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253118</td>\n",
       "      <td>-0.994997</td>\n",
       "      <td>0.461636</td>\n",
       "      <td>0.465271</td>\n",
       "      <td>-0.341487</td>\n",
       "      <td>0.240919</td>\n",
       "      <td>-0.200263</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>0.810546</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-432.696310</td>\n",
       "      <td>130.647264</td>\n",
       "      <td>22.789083</td>\n",
       "      <td>44.904304</td>\n",
       "      <td>23.801889</td>\n",
       "      <td>-1.714131</td>\n",
       "      <td>-17.877608</td>\n",
       "      <td>3.932217</td>\n",
       "      <td>0.856776</td>\n",
       "      <td>-9.977901</td>\n",
       "      <td>...</td>\n",
       "      <td>1.204498</td>\n",
       "      <td>0.662170</td>\n",
       "      <td>1.290700</td>\n",
       "      <td>1.350119</td>\n",
       "      <td>0.512094</td>\n",
       "      <td>-0.365574</td>\n",
       "      <td>0.171132</td>\n",
       "      <td>0.139680</td>\n",
       "      <td>-0.069024</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>-306.572572</td>\n",
       "      <td>109.670172</td>\n",
       "      <td>11.963575</td>\n",
       "      <td>16.871229</td>\n",
       "      <td>8.903087</td>\n",
       "      <td>1.114646</td>\n",
       "      <td>-19.945104</td>\n",
       "      <td>-3.327016</td>\n",
       "      <td>-1.510647</td>\n",
       "      <td>-9.728044</td>\n",
       "      <td>...</td>\n",
       "      <td>2.925757</td>\n",
       "      <td>5.076261</td>\n",
       "      <td>4.986268</td>\n",
       "      <td>4.139367</td>\n",
       "      <td>5.599611</td>\n",
       "      <td>7.593524</td>\n",
       "      <td>7.631419</td>\n",
       "      <td>6.697954</td>\n",
       "      <td>5.786440</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-362.253273</td>\n",
       "      <td>104.006509</td>\n",
       "      <td>14.625180</td>\n",
       "      <td>33.239899</td>\n",
       "      <td>-2.979909</td>\n",
       "      <td>2.600910</td>\n",
       "      <td>-13.862579</td>\n",
       "      <td>-9.817516</td>\n",
       "      <td>-6.566922</td>\n",
       "      <td>3.962269</td>\n",
       "      <td>...</td>\n",
       "      <td>5.546566</td>\n",
       "      <td>5.094293</td>\n",
       "      <td>5.683984</td>\n",
       "      <td>5.993845</td>\n",
       "      <td>4.896129</td>\n",
       "      <td>5.367832</td>\n",
       "      <td>5.546755</td>\n",
       "      <td>4.691688</td>\n",
       "      <td>3.431571</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-300.130159</td>\n",
       "      <td>122.647049</td>\n",
       "      <td>3.019568</td>\n",
       "      <td>28.961545</td>\n",
       "      <td>1.925842</td>\n",
       "      <td>-4.731266</td>\n",
       "      <td>-29.251653</td>\n",
       "      <td>-4.576898</td>\n",
       "      <td>-2.315240</td>\n",
       "      <td>-14.437467</td>\n",
       "      <td>...</td>\n",
       "      <td>1.045617</td>\n",
       "      <td>1.390836</td>\n",
       "      <td>2.190548</td>\n",
       "      <td>4.104951</td>\n",
       "      <td>5.339343</td>\n",
       "      <td>6.885227</td>\n",
       "      <td>5.573310</td>\n",
       "      <td>6.737365</td>\n",
       "      <td>6.787633</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1          2          3          4          5  \\\n",
       "12  -287.823871  101.515510   6.410148  15.656604   7.395868  -1.489299   \n",
       "260 -432.127466  130.331011  15.421203  32.910652  23.467361  -1.484577   \n",
       "148 -340.495581   96.439813  21.219168  42.652258  -1.219512  12.036752   \n",
       "337 -465.225705  151.346358  28.000421  38.127225   9.868115   0.870507   \n",
       "288 -422.190425  128.785296  25.661881  26.935536  17.211634   3.511938   \n",
       "250 -405.978889  107.061765  31.556338  40.077664   2.951004 -13.124174   \n",
       "280 -432.696310  130.647264  22.789083  44.904304  23.801889  -1.714131   \n",
       "456 -306.572572  109.670172  11.963575  16.871229   8.903087   1.114646   \n",
       "161 -362.253273  104.006509  14.625180  33.239899  -2.979909   2.600910   \n",
       "36  -300.130159  122.647049   3.019568  28.961545   1.925842  -4.731266   \n",
       "\n",
       "             6         7         8          9  ...        31        32  \\\n",
       "12  -24.872378 -5.148656 -0.039547 -10.816283  ...  1.922031  2.069620   \n",
       "260 -19.036167  0.314333  5.954609  -6.524187  ...  0.764855  2.257194   \n",
       "148 -25.907954 -3.376129  0.781092 -12.693077  ...  4.214099  7.637096   \n",
       "337  -9.655647 -6.929020  5.113030   4.176812  ...  0.538939 -0.411754   \n",
       "288 -14.742881  0.687592  1.321263  -5.509755  ...  0.684991  0.407341   \n",
       "250   5.861604  2.698900 -4.866779   1.311889  ...  0.253118 -0.994997   \n",
       "280 -17.877608  3.932217  0.856776  -9.977901  ...  1.204498  0.662170   \n",
       "456 -19.945104 -3.327016 -1.510647  -9.728044  ...  2.925757  5.076261   \n",
       "161 -13.862579 -9.817516 -6.566922   3.962269  ...  5.546566  5.094293   \n",
       "36  -29.251653 -4.576898 -2.315240 -14.437467  ...  1.045617  1.390836   \n",
       "\n",
       "            33         34         35         36        37        38        39  \\\n",
       "12    1.789086   1.402842   1.192773   2.013896  2.935015  3.895297  5.941611   \n",
       "260   1.738118   1.038085   1.238373   1.734420  2.330078  1.231918  1.440224   \n",
       "148  11.883751  15.016872  15.636499  12.301138  8.042070  5.284950  3.425573   \n",
       "337   1.952185   2.514050   0.700188   0.558373 -0.027693  1.218584  1.688338   \n",
       "288   1.436117   0.907008  -0.735813  -0.340283  1.214350  2.179666  1.231693   \n",
       "250   0.461636   0.465271  -0.341487   0.240919 -0.200263 -0.106715  0.810546   \n",
       "280   1.290700   1.350119   0.512094  -0.365574  0.171132  0.139680 -0.069024   \n",
       "456   4.986268   4.139367   5.599611   7.593524  7.631419  6.697954  5.786440   \n",
       "161   5.683984   5.993845   4.896129   5.367832  5.546755  4.691688  3.431571   \n",
       "36    2.190548   4.104951   5.339343   6.885227  5.573310  6.737365  6.787633   \n",
       "\n",
       "       emotion  \n",
       "12       angry  \n",
       "260    neutral  \n",
       "148    fearful  \n",
       "337    neutral  \n",
       "288    neutral  \n",
       "250    neutral  \n",
       "280    neutral  \n",
       "456  surprised  \n",
       "161    fearful  \n",
       "36       angry  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "rnewdf = shuffle(newdf)\n",
    "rnewdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf=rnewdf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = np.random.rand(len(rnewdf)) < 0.8\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfeatures = train.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-287.823871</td>\n",
       "      <td>101.515510</td>\n",
       "      <td>6.410148</td>\n",
       "      <td>15.656604</td>\n",
       "      <td>7.395868</td>\n",
       "      <td>-1.489299</td>\n",
       "      <td>-24.872378</td>\n",
       "      <td>-5.148656</td>\n",
       "      <td>-0.039547</td>\n",
       "      <td>-10.816283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094653</td>\n",
       "      <td>1.922031</td>\n",
       "      <td>2.069620</td>\n",
       "      <td>1.789086</td>\n",
       "      <td>1.402842</td>\n",
       "      <td>1.192773</td>\n",
       "      <td>2.013896</td>\n",
       "      <td>2.935015</td>\n",
       "      <td>3.895297</td>\n",
       "      <td>5.941611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>-432.127466</td>\n",
       "      <td>130.331011</td>\n",
       "      <td>15.421203</td>\n",
       "      <td>32.910652</td>\n",
       "      <td>23.467361</td>\n",
       "      <td>-1.484577</td>\n",
       "      <td>-19.036167</td>\n",
       "      <td>0.314333</td>\n",
       "      <td>5.954609</td>\n",
       "      <td>-6.524187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475086</td>\n",
       "      <td>0.764855</td>\n",
       "      <td>2.257194</td>\n",
       "      <td>1.738118</td>\n",
       "      <td>1.038085</td>\n",
       "      <td>1.238373</td>\n",
       "      <td>1.734420</td>\n",
       "      <td>2.330078</td>\n",
       "      <td>1.231918</td>\n",
       "      <td>1.440224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-340.495581</td>\n",
       "      <td>96.439813</td>\n",
       "      <td>21.219168</td>\n",
       "      <td>42.652258</td>\n",
       "      <td>-1.219512</td>\n",
       "      <td>12.036752</td>\n",
       "      <td>-25.907954</td>\n",
       "      <td>-3.376129</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>-12.693077</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.245740</td>\n",
       "      <td>4.214099</td>\n",
       "      <td>7.637096</td>\n",
       "      <td>11.883751</td>\n",
       "      <td>15.016872</td>\n",
       "      <td>15.636499</td>\n",
       "      <td>12.301138</td>\n",
       "      <td>8.042070</td>\n",
       "      <td>5.284950</td>\n",
       "      <td>3.425573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-465.225705</td>\n",
       "      <td>151.346358</td>\n",
       "      <td>28.000421</td>\n",
       "      <td>38.127225</td>\n",
       "      <td>9.868115</td>\n",
       "      <td>0.870507</td>\n",
       "      <td>-9.655647</td>\n",
       "      <td>-6.929020</td>\n",
       "      <td>5.113030</td>\n",
       "      <td>4.176812</td>\n",
       "      <td>...</td>\n",
       "      <td>1.406707</td>\n",
       "      <td>0.538939</td>\n",
       "      <td>-0.411754</td>\n",
       "      <td>1.952185</td>\n",
       "      <td>2.514050</td>\n",
       "      <td>0.700188</td>\n",
       "      <td>0.558373</td>\n",
       "      <td>-0.027693</td>\n",
       "      <td>1.218584</td>\n",
       "      <td>1.688338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>-422.190425</td>\n",
       "      <td>128.785296</td>\n",
       "      <td>25.661881</td>\n",
       "      <td>26.935536</td>\n",
       "      <td>17.211634</td>\n",
       "      <td>3.511938</td>\n",
       "      <td>-14.742881</td>\n",
       "      <td>0.687592</td>\n",
       "      <td>1.321263</td>\n",
       "      <td>-5.509755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231847</td>\n",
       "      <td>0.684991</td>\n",
       "      <td>0.407341</td>\n",
       "      <td>1.436117</td>\n",
       "      <td>0.907008</td>\n",
       "      <td>-0.735813</td>\n",
       "      <td>-0.340283</td>\n",
       "      <td>1.214350</td>\n",
       "      <td>2.179666</td>\n",
       "      <td>1.231693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-405.978889</td>\n",
       "      <td>107.061765</td>\n",
       "      <td>31.556338</td>\n",
       "      <td>40.077664</td>\n",
       "      <td>2.951004</td>\n",
       "      <td>-13.124174</td>\n",
       "      <td>5.861604</td>\n",
       "      <td>2.698900</td>\n",
       "      <td>-4.866779</td>\n",
       "      <td>1.311889</td>\n",
       "      <td>...</td>\n",
       "      <td>1.026799</td>\n",
       "      <td>0.253118</td>\n",
       "      <td>-0.994997</td>\n",
       "      <td>0.461636</td>\n",
       "      <td>0.465271</td>\n",
       "      <td>-0.341487</td>\n",
       "      <td>0.240919</td>\n",
       "      <td>-0.200263</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>0.810546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-432.696310</td>\n",
       "      <td>130.647264</td>\n",
       "      <td>22.789083</td>\n",
       "      <td>44.904304</td>\n",
       "      <td>23.801889</td>\n",
       "      <td>-1.714131</td>\n",
       "      <td>-17.877608</td>\n",
       "      <td>3.932217</td>\n",
       "      <td>0.856776</td>\n",
       "      <td>-9.977901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093268</td>\n",
       "      <td>1.204498</td>\n",
       "      <td>0.662170</td>\n",
       "      <td>1.290700</td>\n",
       "      <td>1.350119</td>\n",
       "      <td>0.512094</td>\n",
       "      <td>-0.365574</td>\n",
       "      <td>0.171132</td>\n",
       "      <td>0.139680</td>\n",
       "      <td>-0.069024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>-306.572572</td>\n",
       "      <td>109.670172</td>\n",
       "      <td>11.963575</td>\n",
       "      <td>16.871229</td>\n",
       "      <td>8.903087</td>\n",
       "      <td>1.114646</td>\n",
       "      <td>-19.945104</td>\n",
       "      <td>-3.327016</td>\n",
       "      <td>-1.510647</td>\n",
       "      <td>-9.728044</td>\n",
       "      <td>...</td>\n",
       "      <td>3.622234</td>\n",
       "      <td>2.925757</td>\n",
       "      <td>5.076261</td>\n",
       "      <td>4.986268</td>\n",
       "      <td>4.139367</td>\n",
       "      <td>5.599611</td>\n",
       "      <td>7.593524</td>\n",
       "      <td>7.631419</td>\n",
       "      <td>6.697954</td>\n",
       "      <td>5.786440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-362.253273</td>\n",
       "      <td>104.006509</td>\n",
       "      <td>14.625180</td>\n",
       "      <td>33.239899</td>\n",
       "      <td>-2.979909</td>\n",
       "      <td>2.600910</td>\n",
       "      <td>-13.862579</td>\n",
       "      <td>-9.817516</td>\n",
       "      <td>-6.566922</td>\n",
       "      <td>3.962269</td>\n",
       "      <td>...</td>\n",
       "      <td>4.743016</td>\n",
       "      <td>5.546566</td>\n",
       "      <td>5.094293</td>\n",
       "      <td>5.683984</td>\n",
       "      <td>5.993845</td>\n",
       "      <td>4.896129</td>\n",
       "      <td>5.367832</td>\n",
       "      <td>5.546755</td>\n",
       "      <td>4.691688</td>\n",
       "      <td>3.431571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-300.130159</td>\n",
       "      <td>122.647049</td>\n",
       "      <td>3.019568</td>\n",
       "      <td>28.961545</td>\n",
       "      <td>1.925842</td>\n",
       "      <td>-4.731266</td>\n",
       "      <td>-29.251653</td>\n",
       "      <td>-4.576898</td>\n",
       "      <td>-2.315240</td>\n",
       "      <td>-14.437467</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.296631</td>\n",
       "      <td>1.045617</td>\n",
       "      <td>1.390836</td>\n",
       "      <td>2.190548</td>\n",
       "      <td>4.104951</td>\n",
       "      <td>5.339343</td>\n",
       "      <td>6.885227</td>\n",
       "      <td>5.573310</td>\n",
       "      <td>6.737365</td>\n",
       "      <td>6.787633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>-434.851371</td>\n",
       "      <td>98.543921</td>\n",
       "      <td>25.464044</td>\n",
       "      <td>31.634010</td>\n",
       "      <td>17.479671</td>\n",
       "      <td>0.170478</td>\n",
       "      <td>-12.976320</td>\n",
       "      <td>3.972902</td>\n",
       "      <td>5.519806</td>\n",
       "      <td>-7.376347</td>\n",
       "      <td>...</td>\n",
       "      <td>1.304375</td>\n",
       "      <td>2.459639</td>\n",
       "      <td>7.031638</td>\n",
       "      <td>10.685749</td>\n",
       "      <td>13.381920</td>\n",
       "      <td>15.544302</td>\n",
       "      <td>14.403574</td>\n",
       "      <td>10.910903</td>\n",
       "      <td>5.343784</td>\n",
       "      <td>2.570242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-603.482656</td>\n",
       "      <td>139.774472</td>\n",
       "      <td>35.270295</td>\n",
       "      <td>33.156113</td>\n",
       "      <td>5.109076</td>\n",
       "      <td>-5.873011</td>\n",
       "      <td>-11.603914</td>\n",
       "      <td>-2.241049</td>\n",
       "      <td>-8.431053</td>\n",
       "      <td>-12.230952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140043</td>\n",
       "      <td>-1.359306</td>\n",
       "      <td>-0.877896</td>\n",
       "      <td>1.434194</td>\n",
       "      <td>-0.242057</td>\n",
       "      <td>-2.660174</td>\n",
       "      <td>0.283196</td>\n",
       "      <td>1.534021</td>\n",
       "      <td>-0.873214</td>\n",
       "      <td>-1.603326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-276.635790</td>\n",
       "      <td>93.746689</td>\n",
       "      <td>-3.646088</td>\n",
       "      <td>31.032646</td>\n",
       "      <td>6.120393</td>\n",
       "      <td>1.945582</td>\n",
       "      <td>-19.112421</td>\n",
       "      <td>-4.126155</td>\n",
       "      <td>-3.454874</td>\n",
       "      <td>-2.151538</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.823949</td>\n",
       "      <td>-0.154802</td>\n",
       "      <td>1.964497</td>\n",
       "      <td>1.255755</td>\n",
       "      <td>0.608359</td>\n",
       "      <td>0.679066</td>\n",
       "      <td>0.849191</td>\n",
       "      <td>1.283594</td>\n",
       "      <td>1.590320</td>\n",
       "      <td>1.617642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>-430.131915</td>\n",
       "      <td>97.279675</td>\n",
       "      <td>32.496212</td>\n",
       "      <td>53.664850</td>\n",
       "      <td>6.007011</td>\n",
       "      <td>4.054683</td>\n",
       "      <td>-9.289378</td>\n",
       "      <td>-5.950959</td>\n",
       "      <td>-1.032873</td>\n",
       "      <td>0.885925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312108</td>\n",
       "      <td>0.683822</td>\n",
       "      <td>2.695188</td>\n",
       "      <td>4.416217</td>\n",
       "      <td>5.010666</td>\n",
       "      <td>4.190008</td>\n",
       "      <td>4.481039</td>\n",
       "      <td>5.206698</td>\n",
       "      <td>4.853494</td>\n",
       "      <td>4.402532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>-554.978541</td>\n",
       "      <td>104.136938</td>\n",
       "      <td>20.310271</td>\n",
       "      <td>42.173790</td>\n",
       "      <td>4.162060</td>\n",
       "      <td>-10.504581</td>\n",
       "      <td>-16.668871</td>\n",
       "      <td>0.468744</td>\n",
       "      <td>-9.847779</td>\n",
       "      <td>-13.191914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358069</td>\n",
       "      <td>1.241784</td>\n",
       "      <td>5.565015</td>\n",
       "      <td>4.851893</td>\n",
       "      <td>6.418690</td>\n",
       "      <td>7.039807</td>\n",
       "      <td>6.523548</td>\n",
       "      <td>6.526476</td>\n",
       "      <td>4.778089</td>\n",
       "      <td>4.733151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-372.162483</td>\n",
       "      <td>74.524255</td>\n",
       "      <td>21.258143</td>\n",
       "      <td>31.796736</td>\n",
       "      <td>-3.313249</td>\n",
       "      <td>3.594831</td>\n",
       "      <td>-12.761745</td>\n",
       "      <td>-7.420061</td>\n",
       "      <td>-6.527652</td>\n",
       "      <td>-0.068557</td>\n",
       "      <td>...</td>\n",
       "      <td>5.934588</td>\n",
       "      <td>5.416731</td>\n",
       "      <td>4.644275</td>\n",
       "      <td>3.695900</td>\n",
       "      <td>2.996713</td>\n",
       "      <td>2.943676</td>\n",
       "      <td>3.729929</td>\n",
       "      <td>4.140914</td>\n",
       "      <td>2.323401</td>\n",
       "      <td>2.297245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-363.945005</td>\n",
       "      <td>132.844093</td>\n",
       "      <td>18.439736</td>\n",
       "      <td>41.831050</td>\n",
       "      <td>-1.238363</td>\n",
       "      <td>-10.838084</td>\n",
       "      <td>-2.721811</td>\n",
       "      <td>-5.487784</td>\n",
       "      <td>-14.612774</td>\n",
       "      <td>-2.332597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184617</td>\n",
       "      <td>0.511796</td>\n",
       "      <td>0.028943</td>\n",
       "      <td>-0.172511</td>\n",
       "      <td>0.542554</td>\n",
       "      <td>0.723893</td>\n",
       "      <td>0.219070</td>\n",
       "      <td>0.134097</td>\n",
       "      <td>0.170139</td>\n",
       "      <td>0.447085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-313.978572</td>\n",
       "      <td>82.632110</td>\n",
       "      <td>3.121088</td>\n",
       "      <td>25.119724</td>\n",
       "      <td>6.733781</td>\n",
       "      <td>2.579732</td>\n",
       "      <td>-13.853373</td>\n",
       "      <td>0.178914</td>\n",
       "      <td>-1.616934</td>\n",
       "      <td>1.959738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892974</td>\n",
       "      <td>0.141898</td>\n",
       "      <td>1.821391</td>\n",
       "      <td>2.529989</td>\n",
       "      <td>1.968246</td>\n",
       "      <td>2.439394</td>\n",
       "      <td>3.644267</td>\n",
       "      <td>3.000721</td>\n",
       "      <td>4.114735</td>\n",
       "      <td>5.142286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-323.640484</td>\n",
       "      <td>102.057851</td>\n",
       "      <td>11.414539</td>\n",
       "      <td>27.203663</td>\n",
       "      <td>9.512438</td>\n",
       "      <td>3.446159</td>\n",
       "      <td>-24.401392</td>\n",
       "      <td>1.727612</td>\n",
       "      <td>0.480743</td>\n",
       "      <td>-14.468013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043533</td>\n",
       "      <td>2.885248</td>\n",
       "      <td>1.025534</td>\n",
       "      <td>-0.121056</td>\n",
       "      <td>1.210861</td>\n",
       "      <td>3.269635</td>\n",
       "      <td>3.549279</td>\n",
       "      <td>7.939622</td>\n",
       "      <td>10.756551</td>\n",
       "      <td>10.050595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-364.242769</td>\n",
       "      <td>128.513973</td>\n",
       "      <td>16.392617</td>\n",
       "      <td>25.728719</td>\n",
       "      <td>14.533887</td>\n",
       "      <td>2.682050</td>\n",
       "      <td>-19.095919</td>\n",
       "      <td>-1.081341</td>\n",
       "      <td>-1.801339</td>\n",
       "      <td>-16.871039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.494622</td>\n",
       "      <td>0.313001</td>\n",
       "      <td>0.552062</td>\n",
       "      <td>-1.445480</td>\n",
       "      <td>-1.226161</td>\n",
       "      <td>1.729511</td>\n",
       "      <td>3.378181</td>\n",
       "      <td>5.310474</td>\n",
       "      <td>8.002821</td>\n",
       "      <td>8.380767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>-406.815580</td>\n",
       "      <td>106.710433</td>\n",
       "      <td>38.339610</td>\n",
       "      <td>42.492754</td>\n",
       "      <td>6.015100</td>\n",
       "      <td>9.122415</td>\n",
       "      <td>-9.922833</td>\n",
       "      <td>-10.160527</td>\n",
       "      <td>-7.804421</td>\n",
       "      <td>4.860304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135046</td>\n",
       "      <td>-0.216605</td>\n",
       "      <td>0.442285</td>\n",
       "      <td>2.677046</td>\n",
       "      <td>3.935339</td>\n",
       "      <td>4.211635</td>\n",
       "      <td>6.919534</td>\n",
       "      <td>9.008892</td>\n",
       "      <td>8.672603</td>\n",
       "      <td>9.387525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-228.524283</td>\n",
       "      <td>104.885862</td>\n",
       "      <td>-5.776232</td>\n",
       "      <td>41.991320</td>\n",
       "      <td>-5.163069</td>\n",
       "      <td>-14.241785</td>\n",
       "      <td>-14.590222</td>\n",
       "      <td>-4.090602</td>\n",
       "      <td>-17.707419</td>\n",
       "      <td>-5.517556</td>\n",
       "      <td>...</td>\n",
       "      <td>1.642368</td>\n",
       "      <td>2.337504</td>\n",
       "      <td>4.073754</td>\n",
       "      <td>1.221485</td>\n",
       "      <td>1.994306</td>\n",
       "      <td>2.067558</td>\n",
       "      <td>2.249683</td>\n",
       "      <td>4.469474</td>\n",
       "      <td>3.492391</td>\n",
       "      <td>2.744447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-301.265046</td>\n",
       "      <td>93.101924</td>\n",
       "      <td>8.343871</td>\n",
       "      <td>23.903461</td>\n",
       "      <td>5.642780</td>\n",
       "      <td>3.585409</td>\n",
       "      <td>-7.081349</td>\n",
       "      <td>-4.429382</td>\n",
       "      <td>-8.290206</td>\n",
       "      <td>-3.702344</td>\n",
       "      <td>...</td>\n",
       "      <td>1.238613</td>\n",
       "      <td>2.370341</td>\n",
       "      <td>2.882989</td>\n",
       "      <td>1.881962</td>\n",
       "      <td>2.258587</td>\n",
       "      <td>2.833024</td>\n",
       "      <td>2.439725</td>\n",
       "      <td>2.751248</td>\n",
       "      <td>4.530745</td>\n",
       "      <td>5.222333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-576.532048</td>\n",
       "      <td>98.481914</td>\n",
       "      <td>22.043391</td>\n",
       "      <td>35.167535</td>\n",
       "      <td>-0.444776</td>\n",
       "      <td>0.608610</td>\n",
       "      <td>-7.506805</td>\n",
       "      <td>-4.842706</td>\n",
       "      <td>-13.191851</td>\n",
       "      <td>-12.959278</td>\n",
       "      <td>...</td>\n",
       "      <td>4.426111</td>\n",
       "      <td>5.177279</td>\n",
       "      <td>2.554160</td>\n",
       "      <td>2.186716</td>\n",
       "      <td>5.343213</td>\n",
       "      <td>3.646216</td>\n",
       "      <td>3.993214</td>\n",
       "      <td>2.326687</td>\n",
       "      <td>0.506513</td>\n",
       "      <td>3.333642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-382.896532</td>\n",
       "      <td>143.836625</td>\n",
       "      <td>18.894789</td>\n",
       "      <td>46.446644</td>\n",
       "      <td>0.208779</td>\n",
       "      <td>-18.305492</td>\n",
       "      <td>3.421248</td>\n",
       "      <td>1.049910</td>\n",
       "      <td>-8.883140</td>\n",
       "      <td>0.807907</td>\n",
       "      <td>...</td>\n",
       "      <td>1.137249</td>\n",
       "      <td>2.297980</td>\n",
       "      <td>2.212605</td>\n",
       "      <td>0.884639</td>\n",
       "      <td>-0.239720</td>\n",
       "      <td>0.917674</td>\n",
       "      <td>3.352121</td>\n",
       "      <td>4.327776</td>\n",
       "      <td>4.452914</td>\n",
       "      <td>2.091570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-250.120819</td>\n",
       "      <td>95.843478</td>\n",
       "      <td>-9.177524</td>\n",
       "      <td>30.220906</td>\n",
       "      <td>-17.715860</td>\n",
       "      <td>-12.656891</td>\n",
       "      <td>-9.108992</td>\n",
       "      <td>-2.146361</td>\n",
       "      <td>-12.959524</td>\n",
       "      <td>-2.016111</td>\n",
       "      <td>...</td>\n",
       "      <td>3.188646</td>\n",
       "      <td>3.218551</td>\n",
       "      <td>2.460108</td>\n",
       "      <td>1.244071</td>\n",
       "      <td>3.105667</td>\n",
       "      <td>2.021699</td>\n",
       "      <td>3.606981</td>\n",
       "      <td>4.024233</td>\n",
       "      <td>2.494627</td>\n",
       "      <td>2.720836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>-621.978720</td>\n",
       "      <td>128.415491</td>\n",
       "      <td>34.011600</td>\n",
       "      <td>35.791722</td>\n",
       "      <td>15.782161</td>\n",
       "      <td>-2.823287</td>\n",
       "      <td>-8.815575</td>\n",
       "      <td>3.864244</td>\n",
       "      <td>-3.055049</td>\n",
       "      <td>-9.098061</td>\n",
       "      <td>...</td>\n",
       "      <td>2.231181</td>\n",
       "      <td>0.341566</td>\n",
       "      <td>-0.129298</td>\n",
       "      <td>0.363795</td>\n",
       "      <td>0.466652</td>\n",
       "      <td>-0.227194</td>\n",
       "      <td>1.567995</td>\n",
       "      <td>0.900737</td>\n",
       "      <td>-1.163473</td>\n",
       "      <td>0.728602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>-360.320776</td>\n",
       "      <td>134.733076</td>\n",
       "      <td>7.438498</td>\n",
       "      <td>39.600563</td>\n",
       "      <td>-0.211756</td>\n",
       "      <td>-20.311009</td>\n",
       "      <td>7.464531</td>\n",
       "      <td>1.244229</td>\n",
       "      <td>-10.944938</td>\n",
       "      <td>1.566006</td>\n",
       "      <td>...</td>\n",
       "      <td>2.284521</td>\n",
       "      <td>2.008376</td>\n",
       "      <td>0.598170</td>\n",
       "      <td>0.175363</td>\n",
       "      <td>0.380484</td>\n",
       "      <td>0.732959</td>\n",
       "      <td>1.616396</td>\n",
       "      <td>2.283424</td>\n",
       "      <td>2.273788</td>\n",
       "      <td>1.790770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-618.632607</td>\n",
       "      <td>126.814947</td>\n",
       "      <td>27.376553</td>\n",
       "      <td>44.930481</td>\n",
       "      <td>9.987193</td>\n",
       "      <td>1.061669</td>\n",
       "      <td>1.167161</td>\n",
       "      <td>3.224571</td>\n",
       "      <td>-5.404695</td>\n",
       "      <td>-9.356676</td>\n",
       "      <td>...</td>\n",
       "      <td>1.651552</td>\n",
       "      <td>2.132630</td>\n",
       "      <td>0.751663</td>\n",
       "      <td>-0.968554</td>\n",
       "      <td>0.145046</td>\n",
       "      <td>-0.253114</td>\n",
       "      <td>1.210670</td>\n",
       "      <td>3.194715</td>\n",
       "      <td>-1.874546</td>\n",
       "      <td>-2.026386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-229.980376</td>\n",
       "      <td>92.734781</td>\n",
       "      <td>-10.102935</td>\n",
       "      <td>38.225387</td>\n",
       "      <td>-12.808887</td>\n",
       "      <td>-8.081135</td>\n",
       "      <td>-9.241305</td>\n",
       "      <td>-0.922913</td>\n",
       "      <td>-11.749296</td>\n",
       "      <td>-4.356548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920867</td>\n",
       "      <td>0.249137</td>\n",
       "      <td>2.279387</td>\n",
       "      <td>2.188748</td>\n",
       "      <td>2.733104</td>\n",
       "      <td>2.431164</td>\n",
       "      <td>2.090510</td>\n",
       "      <td>3.369304</td>\n",
       "      <td>2.246630</td>\n",
       "      <td>2.007894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-451.659432</td>\n",
       "      <td>102.003742</td>\n",
       "      <td>29.902955</td>\n",
       "      <td>41.905496</td>\n",
       "      <td>-1.878806</td>\n",
       "      <td>6.404506</td>\n",
       "      <td>-10.052050</td>\n",
       "      <td>-5.085905</td>\n",
       "      <td>4.141112</td>\n",
       "      <td>4.651836</td>\n",
       "      <td>...</td>\n",
       "      <td>1.718879</td>\n",
       "      <td>1.882781</td>\n",
       "      <td>1.708072</td>\n",
       "      <td>1.198320</td>\n",
       "      <td>2.215826</td>\n",
       "      <td>2.800559</td>\n",
       "      <td>2.886817</td>\n",
       "      <td>3.867586</td>\n",
       "      <td>3.235160</td>\n",
       "      <td>4.495156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>-615.820944</td>\n",
       "      <td>138.075746</td>\n",
       "      <td>28.458369</td>\n",
       "      <td>29.954639</td>\n",
       "      <td>6.336812</td>\n",
       "      <td>-7.033151</td>\n",
       "      <td>-5.712378</td>\n",
       "      <td>4.939312</td>\n",
       "      <td>-12.768874</td>\n",
       "      <td>-14.474800</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.143227</td>\n",
       "      <td>1.568735</td>\n",
       "      <td>1.288424</td>\n",
       "      <td>-0.988612</td>\n",
       "      <td>-1.843756</td>\n",
       "      <td>-1.796114</td>\n",
       "      <td>1.200146</td>\n",
       "      <td>0.327601</td>\n",
       "      <td>-3.404551</td>\n",
       "      <td>-2.832622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-564.540326</td>\n",
       "      <td>104.181913</td>\n",
       "      <td>26.302574</td>\n",
       "      <td>44.703341</td>\n",
       "      <td>17.196513</td>\n",
       "      <td>-4.453330</td>\n",
       "      <td>-15.700971</td>\n",
       "      <td>-2.773550</td>\n",
       "      <td>-5.163968</td>\n",
       "      <td>-11.310603</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.580128</td>\n",
       "      <td>-1.982804</td>\n",
       "      <td>-0.331088</td>\n",
       "      <td>-2.861281</td>\n",
       "      <td>-2.723364</td>\n",
       "      <td>0.419460</td>\n",
       "      <td>2.015126</td>\n",
       "      <td>1.980087</td>\n",
       "      <td>-0.398496</td>\n",
       "      <td>-0.039357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>-360.809779</td>\n",
       "      <td>113.284110</td>\n",
       "      <td>15.287115</td>\n",
       "      <td>42.154347</td>\n",
       "      <td>-8.036496</td>\n",
       "      <td>-12.458731</td>\n",
       "      <td>0.343810</td>\n",
       "      <td>2.427382</td>\n",
       "      <td>-8.502563</td>\n",
       "      <td>1.338325</td>\n",
       "      <td>...</td>\n",
       "      <td>1.564645</td>\n",
       "      <td>1.180753</td>\n",
       "      <td>2.646671</td>\n",
       "      <td>2.562342</td>\n",
       "      <td>2.029351</td>\n",
       "      <td>1.301214</td>\n",
       "      <td>2.026145</td>\n",
       "      <td>4.375845</td>\n",
       "      <td>4.780044</td>\n",
       "      <td>3.547263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-412.200250</td>\n",
       "      <td>119.983382</td>\n",
       "      <td>40.456164</td>\n",
       "      <td>42.918788</td>\n",
       "      <td>7.759223</td>\n",
       "      <td>-8.827861</td>\n",
       "      <td>0.302530</td>\n",
       "      <td>-0.876979</td>\n",
       "      <td>-9.754246</td>\n",
       "      <td>1.815627</td>\n",
       "      <td>...</td>\n",
       "      <td>2.216655</td>\n",
       "      <td>3.416843</td>\n",
       "      <td>2.306034</td>\n",
       "      <td>1.992271</td>\n",
       "      <td>2.432954</td>\n",
       "      <td>1.527816</td>\n",
       "      <td>1.284672</td>\n",
       "      <td>0.879847</td>\n",
       "      <td>1.154534</td>\n",
       "      <td>0.759829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>-401.880261</td>\n",
       "      <td>129.446839</td>\n",
       "      <td>35.187346</td>\n",
       "      <td>41.844689</td>\n",
       "      <td>-2.079105</td>\n",
       "      <td>-8.869166</td>\n",
       "      <td>6.147035</td>\n",
       "      <td>0.027061</td>\n",
       "      <td>-11.670313</td>\n",
       "      <td>-0.428516</td>\n",
       "      <td>...</td>\n",
       "      <td>3.392816</td>\n",
       "      <td>3.341651</td>\n",
       "      <td>1.174717</td>\n",
       "      <td>1.227031</td>\n",
       "      <td>1.056021</td>\n",
       "      <td>0.537438</td>\n",
       "      <td>0.450876</td>\n",
       "      <td>-0.222660</td>\n",
       "      <td>1.172093</td>\n",
       "      <td>0.972544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>-327.104932</td>\n",
       "      <td>79.301763</td>\n",
       "      <td>7.942151</td>\n",
       "      <td>29.259399</td>\n",
       "      <td>-8.706316</td>\n",
       "      <td>-8.208314</td>\n",
       "      <td>-4.251045</td>\n",
       "      <td>0.597293</td>\n",
       "      <td>-6.918529</td>\n",
       "      <td>-1.235340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384934</td>\n",
       "      <td>1.026097</td>\n",
       "      <td>2.588998</td>\n",
       "      <td>2.699226</td>\n",
       "      <td>1.447225</td>\n",
       "      <td>0.253246</td>\n",
       "      <td>1.453918</td>\n",
       "      <td>2.504979</td>\n",
       "      <td>2.104876</td>\n",
       "      <td>1.271855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-348.962771</td>\n",
       "      <td>99.436237</td>\n",
       "      <td>15.986567</td>\n",
       "      <td>45.182565</td>\n",
       "      <td>1.513263</td>\n",
       "      <td>1.273786</td>\n",
       "      <td>-23.431848</td>\n",
       "      <td>-14.130073</td>\n",
       "      <td>-7.768824</td>\n",
       "      <td>0.927446</td>\n",
       "      <td>...</td>\n",
       "      <td>9.633837</td>\n",
       "      <td>7.363714</td>\n",
       "      <td>6.801923</td>\n",
       "      <td>7.122531</td>\n",
       "      <td>4.459290</td>\n",
       "      <td>2.609737</td>\n",
       "      <td>2.826959</td>\n",
       "      <td>3.389008</td>\n",
       "      <td>2.765094</td>\n",
       "      <td>3.615255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-414.906462</td>\n",
       "      <td>122.865282</td>\n",
       "      <td>33.993675</td>\n",
       "      <td>55.732142</td>\n",
       "      <td>15.695612</td>\n",
       "      <td>-0.341726</td>\n",
       "      <td>-24.717426</td>\n",
       "      <td>-5.705747</td>\n",
       "      <td>2.717990</td>\n",
       "      <td>-2.816059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169357</td>\n",
       "      <td>0.741317</td>\n",
       "      <td>-0.332308</td>\n",
       "      <td>0.449911</td>\n",
       "      <td>0.845619</td>\n",
       "      <td>0.116425</td>\n",
       "      <td>1.158065</td>\n",
       "      <td>2.381865</td>\n",
       "      <td>1.937507</td>\n",
       "      <td>2.386734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-335.045334</td>\n",
       "      <td>115.213070</td>\n",
       "      <td>14.902544</td>\n",
       "      <td>29.936056</td>\n",
       "      <td>26.858322</td>\n",
       "      <td>-1.246389</td>\n",
       "      <td>-24.746914</td>\n",
       "      <td>-3.276896</td>\n",
       "      <td>1.782275</td>\n",
       "      <td>-9.783207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.649823</td>\n",
       "      <td>0.497959</td>\n",
       "      <td>1.968609</td>\n",
       "      <td>1.951153</td>\n",
       "      <td>0.974884</td>\n",
       "      <td>0.591810</td>\n",
       "      <td>2.367409</td>\n",
       "      <td>4.864021</td>\n",
       "      <td>7.062141</td>\n",
       "      <td>8.062965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-442.376328</td>\n",
       "      <td>108.209211</td>\n",
       "      <td>13.920570</td>\n",
       "      <td>33.964150</td>\n",
       "      <td>-4.300990</td>\n",
       "      <td>6.558071</td>\n",
       "      <td>-14.493118</td>\n",
       "      <td>-3.506007</td>\n",
       "      <td>4.074500</td>\n",
       "      <td>9.947217</td>\n",
       "      <td>...</td>\n",
       "      <td>2.309879</td>\n",
       "      <td>2.637121</td>\n",
       "      <td>5.963342</td>\n",
       "      <td>3.102167</td>\n",
       "      <td>3.136553</td>\n",
       "      <td>4.544684</td>\n",
       "      <td>4.318352</td>\n",
       "      <td>3.409357</td>\n",
       "      <td>3.593279</td>\n",
       "      <td>3.990837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>-449.896765</td>\n",
       "      <td>110.615643</td>\n",
       "      <td>38.923263</td>\n",
       "      <td>39.071117</td>\n",
       "      <td>11.406802</td>\n",
       "      <td>-0.129699</td>\n",
       "      <td>-13.487579</td>\n",
       "      <td>2.969503</td>\n",
       "      <td>5.324938</td>\n",
       "      <td>-4.175093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.829099</td>\n",
       "      <td>0.160902</td>\n",
       "      <td>0.531549</td>\n",
       "      <td>1.310473</td>\n",
       "      <td>1.356206</td>\n",
       "      <td>0.217443</td>\n",
       "      <td>2.057493</td>\n",
       "      <td>2.218633</td>\n",
       "      <td>2.019491</td>\n",
       "      <td>4.059384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>-571.964636</td>\n",
       "      <td>120.924964</td>\n",
       "      <td>12.184644</td>\n",
       "      <td>38.451703</td>\n",
       "      <td>12.888660</td>\n",
       "      <td>-1.571916</td>\n",
       "      <td>-16.119903</td>\n",
       "      <td>-5.374135</td>\n",
       "      <td>-9.205994</td>\n",
       "      <td>-15.640402</td>\n",
       "      <td>...</td>\n",
       "      <td>1.506510</td>\n",
       "      <td>2.181098</td>\n",
       "      <td>-0.020008</td>\n",
       "      <td>0.174914</td>\n",
       "      <td>1.905475</td>\n",
       "      <td>-0.366554</td>\n",
       "      <td>2.614419</td>\n",
       "      <td>3.634988</td>\n",
       "      <td>1.905689</td>\n",
       "      <td>3.461926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>-296.716022</td>\n",
       "      <td>80.503846</td>\n",
       "      <td>-1.804558</td>\n",
       "      <td>25.722287</td>\n",
       "      <td>-11.859665</td>\n",
       "      <td>-6.640318</td>\n",
       "      <td>-6.788085</td>\n",
       "      <td>-1.806376</td>\n",
       "      <td>-8.041108</td>\n",
       "      <td>-0.613035</td>\n",
       "      <td>...</td>\n",
       "      <td>4.786008</td>\n",
       "      <td>3.298865</td>\n",
       "      <td>3.248292</td>\n",
       "      <td>1.469338</td>\n",
       "      <td>1.942831</td>\n",
       "      <td>3.576282</td>\n",
       "      <td>1.584157</td>\n",
       "      <td>1.607352</td>\n",
       "      <td>1.998821</td>\n",
       "      <td>2.675377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-356.277005</td>\n",
       "      <td>107.314982</td>\n",
       "      <td>26.716779</td>\n",
       "      <td>41.239015</td>\n",
       "      <td>-5.655700</td>\n",
       "      <td>-2.430470</td>\n",
       "      <td>1.966906</td>\n",
       "      <td>-1.379982</td>\n",
       "      <td>-10.738918</td>\n",
       "      <td>-2.128725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908686</td>\n",
       "      <td>2.708944</td>\n",
       "      <td>1.517132</td>\n",
       "      <td>1.785931</td>\n",
       "      <td>2.981266</td>\n",
       "      <td>1.518840</td>\n",
       "      <td>1.453033</td>\n",
       "      <td>1.966187</td>\n",
       "      <td>2.162614</td>\n",
       "      <td>2.396414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-562.578613</td>\n",
       "      <td>104.115564</td>\n",
       "      <td>23.074322</td>\n",
       "      <td>33.477178</td>\n",
       "      <td>10.957926</td>\n",
       "      <td>1.295070</td>\n",
       "      <td>-9.973155</td>\n",
       "      <td>-6.239166</td>\n",
       "      <td>-11.178637</td>\n",
       "      <td>-13.318111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059648</td>\n",
       "      <td>-0.426545</td>\n",
       "      <td>1.435029</td>\n",
       "      <td>2.294525</td>\n",
       "      <td>1.277858</td>\n",
       "      <td>-1.131861</td>\n",
       "      <td>1.802468</td>\n",
       "      <td>4.437437</td>\n",
       "      <td>2.567069</td>\n",
       "      <td>2.111247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-240.821107</td>\n",
       "      <td>87.376801</td>\n",
       "      <td>-3.440582</td>\n",
       "      <td>22.200195</td>\n",
       "      <td>-16.390295</td>\n",
       "      <td>-3.571389</td>\n",
       "      <td>-17.686169</td>\n",
       "      <td>-15.280418</td>\n",
       "      <td>-13.796058</td>\n",
       "      <td>-2.879346</td>\n",
       "      <td>...</td>\n",
       "      <td>5.879108</td>\n",
       "      <td>4.037976</td>\n",
       "      <td>3.712013</td>\n",
       "      <td>3.269332</td>\n",
       "      <td>2.483173</td>\n",
       "      <td>2.681557</td>\n",
       "      <td>1.576796</td>\n",
       "      <td>3.074815</td>\n",
       "      <td>3.111052</td>\n",
       "      <td>0.492740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-316.408834</td>\n",
       "      <td>105.347958</td>\n",
       "      <td>21.716192</td>\n",
       "      <td>43.489467</td>\n",
       "      <td>3.989892</td>\n",
       "      <td>-4.474727</td>\n",
       "      <td>-21.663240</td>\n",
       "      <td>-1.987640</td>\n",
       "      <td>-6.056660</td>\n",
       "      <td>-1.838507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889446</td>\n",
       "      <td>3.595333</td>\n",
       "      <td>5.008366</td>\n",
       "      <td>4.674027</td>\n",
       "      <td>4.232653</td>\n",
       "      <td>4.111045</td>\n",
       "      <td>3.903578</td>\n",
       "      <td>4.511707</td>\n",
       "      <td>4.754718</td>\n",
       "      <td>3.825773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-363.087063</td>\n",
       "      <td>77.744523</td>\n",
       "      <td>20.823881</td>\n",
       "      <td>37.965253</td>\n",
       "      <td>-7.821355</td>\n",
       "      <td>5.113374</td>\n",
       "      <td>-21.827561</td>\n",
       "      <td>-10.262245</td>\n",
       "      <td>-6.993255</td>\n",
       "      <td>0.242945</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479265</td>\n",
       "      <td>2.803738</td>\n",
       "      <td>3.537723</td>\n",
       "      <td>3.529042</td>\n",
       "      <td>2.132112</td>\n",
       "      <td>2.144042</td>\n",
       "      <td>1.879729</td>\n",
       "      <td>2.174715</td>\n",
       "      <td>1.775709</td>\n",
       "      <td>1.456835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>-680.202352</td>\n",
       "      <td>124.771186</td>\n",
       "      <td>24.726650</td>\n",
       "      <td>35.910451</td>\n",
       "      <td>15.533346</td>\n",
       "      <td>3.332256</td>\n",
       "      <td>-6.431071</td>\n",
       "      <td>6.098152</td>\n",
       "      <td>-0.643167</td>\n",
       "      <td>-4.468894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533046</td>\n",
       "      <td>-1.293357</td>\n",
       "      <td>-1.826354</td>\n",
       "      <td>-2.582217</td>\n",
       "      <td>-0.321365</td>\n",
       "      <td>-0.150544</td>\n",
       "      <td>0.305770</td>\n",
       "      <td>-0.047913</td>\n",
       "      <td>-1.527759</td>\n",
       "      <td>0.069459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>-538.277004</td>\n",
       "      <td>147.344007</td>\n",
       "      <td>19.870350</td>\n",
       "      <td>18.315887</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>-10.965101</td>\n",
       "      <td>-14.581704</td>\n",
       "      <td>-3.533224</td>\n",
       "      <td>-9.768176</td>\n",
       "      <td>-14.369276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217283</td>\n",
       "      <td>-1.487998</td>\n",
       "      <td>1.160371</td>\n",
       "      <td>0.669748</td>\n",
       "      <td>3.622553</td>\n",
       "      <td>4.290413</td>\n",
       "      <td>2.267128</td>\n",
       "      <td>2.581942</td>\n",
       "      <td>-1.219281</td>\n",
       "      <td>-1.583040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-441.939383</td>\n",
       "      <td>121.073342</td>\n",
       "      <td>42.228624</td>\n",
       "      <td>44.316016</td>\n",
       "      <td>0.565406</td>\n",
       "      <td>6.006791</td>\n",
       "      <td>-4.745008</td>\n",
       "      <td>-3.385309</td>\n",
       "      <td>-1.493476</td>\n",
       "      <td>3.116250</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.050425</td>\n",
       "      <td>0.961721</td>\n",
       "      <td>-0.667593</td>\n",
       "      <td>0.806910</td>\n",
       "      <td>1.532966</td>\n",
       "      <td>-1.231958</td>\n",
       "      <td>1.757688</td>\n",
       "      <td>1.522121</td>\n",
       "      <td>0.489499</td>\n",
       "      <td>1.825178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-226.829176</td>\n",
       "      <td>93.709303</td>\n",
       "      <td>0.471723</td>\n",
       "      <td>42.447517</td>\n",
       "      <td>-8.432659</td>\n",
       "      <td>-4.233105</td>\n",
       "      <td>-15.760228</td>\n",
       "      <td>-3.213731</td>\n",
       "      <td>-12.499037</td>\n",
       "      <td>-3.621449</td>\n",
       "      <td>...</td>\n",
       "      <td>1.171142</td>\n",
       "      <td>2.443039</td>\n",
       "      <td>2.943492</td>\n",
       "      <td>2.063990</td>\n",
       "      <td>2.611041</td>\n",
       "      <td>1.508550</td>\n",
       "      <td>1.366474</td>\n",
       "      <td>2.892521</td>\n",
       "      <td>1.041060</td>\n",
       "      <td>0.339918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>-562.055790</td>\n",
       "      <td>107.554131</td>\n",
       "      <td>26.853017</td>\n",
       "      <td>25.277784</td>\n",
       "      <td>5.072138</td>\n",
       "      <td>-0.991708</td>\n",
       "      <td>-12.561367</td>\n",
       "      <td>-4.152792</td>\n",
       "      <td>-8.706542</td>\n",
       "      <td>-13.637620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653458</td>\n",
       "      <td>-0.560693</td>\n",
       "      <td>0.263442</td>\n",
       "      <td>1.797453</td>\n",
       "      <td>1.149249</td>\n",
       "      <td>-0.706918</td>\n",
       "      <td>2.148012</td>\n",
       "      <td>2.364498</td>\n",
       "      <td>1.906818</td>\n",
       "      <td>2.230867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>-436.370819</td>\n",
       "      <td>135.433312</td>\n",
       "      <td>19.837799</td>\n",
       "      <td>38.866741</td>\n",
       "      <td>9.593291</td>\n",
       "      <td>-1.529023</td>\n",
       "      <td>-18.785781</td>\n",
       "      <td>-3.340150</td>\n",
       "      <td>2.919727</td>\n",
       "      <td>2.778586</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.077948</td>\n",
       "      <td>0.289998</td>\n",
       "      <td>0.100389</td>\n",
       "      <td>1.427070</td>\n",
       "      <td>1.698957</td>\n",
       "      <td>0.558742</td>\n",
       "      <td>1.796393</td>\n",
       "      <td>3.256265</td>\n",
       "      <td>3.834511</td>\n",
       "      <td>2.645109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-319.901998</td>\n",
       "      <td>78.768449</td>\n",
       "      <td>17.341875</td>\n",
       "      <td>43.145510</td>\n",
       "      <td>15.078900</td>\n",
       "      <td>1.285913</td>\n",
       "      <td>-15.494866</td>\n",
       "      <td>-6.915486</td>\n",
       "      <td>-6.775249</td>\n",
       "      <td>-7.266575</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164263</td>\n",
       "      <td>0.236306</td>\n",
       "      <td>2.347420</td>\n",
       "      <td>3.265172</td>\n",
       "      <td>2.424406</td>\n",
       "      <td>1.083118</td>\n",
       "      <td>1.794233</td>\n",
       "      <td>2.718746</td>\n",
       "      <td>2.170102</td>\n",
       "      <td>2.408735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-549.593547</td>\n",
       "      <td>96.194970</td>\n",
       "      <td>26.251380</td>\n",
       "      <td>35.855242</td>\n",
       "      <td>11.222940</td>\n",
       "      <td>-1.259802</td>\n",
       "      <td>-14.315946</td>\n",
       "      <td>-6.897882</td>\n",
       "      <td>-5.457868</td>\n",
       "      <td>-12.388130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345621</td>\n",
       "      <td>0.934451</td>\n",
       "      <td>2.078736</td>\n",
       "      <td>2.417572</td>\n",
       "      <td>1.947629</td>\n",
       "      <td>0.097649</td>\n",
       "      <td>2.305652</td>\n",
       "      <td>2.851927</td>\n",
       "      <td>2.151014</td>\n",
       "      <td>2.977748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>-450.102935</td>\n",
       "      <td>134.773577</td>\n",
       "      <td>36.648986</td>\n",
       "      <td>52.442089</td>\n",
       "      <td>15.246445</td>\n",
       "      <td>2.710231</td>\n",
       "      <td>-18.517984</td>\n",
       "      <td>-3.401544</td>\n",
       "      <td>2.314736</td>\n",
       "      <td>-3.260462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>2.334119</td>\n",
       "      <td>-1.998438</td>\n",
       "      <td>1.814853</td>\n",
       "      <td>1.121548</td>\n",
       "      <td>-1.448660</td>\n",
       "      <td>2.104702</td>\n",
       "      <td>1.184363</td>\n",
       "      <td>1.309205</td>\n",
       "      <td>0.993657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>-455.124380</td>\n",
       "      <td>99.359560</td>\n",
       "      <td>36.538788</td>\n",
       "      <td>35.767154</td>\n",
       "      <td>12.141202</td>\n",
       "      <td>1.231861</td>\n",
       "      <td>-7.421506</td>\n",
       "      <td>-3.392504</td>\n",
       "      <td>0.131567</td>\n",
       "      <td>0.576603</td>\n",
       "      <td>...</td>\n",
       "      <td>2.998948</td>\n",
       "      <td>4.015828</td>\n",
       "      <td>5.615757</td>\n",
       "      <td>6.720202</td>\n",
       "      <td>5.859033</td>\n",
       "      <td>4.839969</td>\n",
       "      <td>2.976057</td>\n",
       "      <td>2.541430</td>\n",
       "      <td>3.290174</td>\n",
       "      <td>5.419835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>-396.615148</td>\n",
       "      <td>95.302145</td>\n",
       "      <td>21.180622</td>\n",
       "      <td>36.349787</td>\n",
       "      <td>19.660689</td>\n",
       "      <td>2.719008</td>\n",
       "      <td>-15.584608</td>\n",
       "      <td>-3.168175</td>\n",
       "      <td>-3.618893</td>\n",
       "      <td>-9.905001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151456</td>\n",
       "      <td>0.709250</td>\n",
       "      <td>1.657197</td>\n",
       "      <td>4.079550</td>\n",
       "      <td>9.983696</td>\n",
       "      <td>15.611817</td>\n",
       "      <td>17.373626</td>\n",
       "      <td>14.530228</td>\n",
       "      <td>9.388773</td>\n",
       "      <td>6.697734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1          2          3          4          5   \\\n",
       "12  -287.823871  101.515510   6.410148  15.656604   7.395868  -1.489299   \n",
       "260 -432.127466  130.331011  15.421203  32.910652  23.467361  -1.484577   \n",
       "148 -340.495581   96.439813  21.219168  42.652258  -1.219512  12.036752   \n",
       "337 -465.225705  151.346358  28.000421  38.127225   9.868115   0.870507   \n",
       "288 -422.190425  128.785296  25.661881  26.935536  17.211634   3.511938   \n",
       "250 -405.978889  107.061765  31.556338  40.077664   2.951004 -13.124174   \n",
       "280 -432.696310  130.647264  22.789083  44.904304  23.801889  -1.714131   \n",
       "456 -306.572572  109.670172  11.963575  16.871229   8.903087   1.114646   \n",
       "161 -362.253273  104.006509  14.625180  33.239899  -2.979909   2.600910   \n",
       "36  -300.130159  122.647049   3.019568  28.961545   1.925842  -4.731266   \n",
       "368 -434.851371   98.543921  25.464044  31.634010  17.479671   0.170478   \n",
       "119 -603.482656  139.774472  35.270295  33.156113   5.109076  -5.873011   \n",
       "21  -276.635790   93.746689  -3.646088  31.032646   6.120393   1.945582   \n",
       "397 -430.131915   97.279675  32.496212  53.664850   6.007011   4.054683   \n",
       "423 -554.978541  104.136938  20.310271  42.173790   4.162060 -10.504581   \n",
       "169 -372.162483   74.524255  21.258143  31.796736  -3.313249   3.594831   \n",
       "350 -363.945005  132.844093  18.439736  41.831050  -1.238363 -10.838084   \n",
       "9   -313.978572   82.632110   3.121088  25.119724   6.733781   2.579732   \n",
       "168 -323.640484  102.057851  11.414539  27.203663   9.512438   3.446159   \n",
       "112 -364.242769  128.513973  16.392617  25.728719  14.533887   2.682050   \n",
       "401 -406.815580  106.710433  38.339610  42.492754   6.015100   9.122415   \n",
       "58  -228.524283  104.885862  -5.776232  41.991320  -5.163069 -14.241785   \n",
       "118 -301.265046   93.101924   8.343871  23.903461   5.642780   3.585409   \n",
       "451 -576.532048   98.481914  22.043391  35.167535  -0.444776   0.608610   \n",
       "338 -382.896532  143.836625  18.894789  46.446644   0.208779 -18.305492   \n",
       "446 -250.120819   95.843478  -9.177524  30.220906 -17.715860 -12.656891   \n",
       "103 -621.978720  128.415491  34.011600  35.791722  15.782161  -2.823287   \n",
       "306 -360.320776  134.733076   7.438498  39.600563  -0.211756 -20.311009   \n",
       "355 -618.632607  126.814947  27.376553  44.930481   9.987193   1.061669   \n",
       "22  -229.980376   92.734781 -10.102935  38.225387 -12.808887  -8.081135   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "105 -451.659432  102.003742  29.902955  41.905496  -1.878806   6.404506   \n",
       "291 -615.820944  138.075746  28.458369  29.954639   6.336812  -7.033151   \n",
       "3   -564.540326  104.181913  26.302574  44.703341  17.196513  -4.453330   \n",
       "262 -360.809779  113.284110  15.287115  42.154347  -8.036496 -12.458731   \n",
       "406 -412.200250  119.983382  40.456164  42.918788   7.759223  -8.827861   \n",
       "402 -401.880261  129.446839  35.187346  41.844689  -2.079105  -8.869166   \n",
       "430 -327.104932   79.301763   7.942151  29.259399  -8.706316  -8.208314   \n",
       "165 -348.962771   99.436237  15.986567  45.182565   1.513263   1.273786   \n",
       "241 -414.906462  122.865282  33.993675  55.732142  15.695612  -0.341726   \n",
       "40  -335.045334  115.213070  14.902544  29.936056  26.858322  -1.246389   \n",
       "69  -442.376328  108.209211  13.920570  33.964150  -4.300990   6.558071   \n",
       "285 -449.896765  110.615643  38.923263  39.071117  11.406802  -0.129699   \n",
       "227 -571.964636  120.924964  12.184644  38.451703  12.888660  -1.571916   \n",
       "130 -296.716022   80.503846  -1.804558  25.722287 -11.859665  -6.640318   \n",
       "342 -356.277005  107.314982  26.716779  41.239015  -5.655700  -2.430470   \n",
       "199 -562.578613  104.115564  23.074322  33.477178  10.957926   1.295070   \n",
       "166 -240.821107   87.376801  -3.440582  22.200195 -16.390295  -3.571389   \n",
       "181 -316.408834  105.347958  21.716192  43.489467   3.989892  -4.474727   \n",
       "133 -363.087063   77.744523  20.823881  37.965253  -7.821355   5.113374   \n",
       "371 -680.202352  124.771186  24.726650  35.910451  15.533346   3.332256   \n",
       "435 -538.277004  147.344007  19.870350  18.315887   0.818333 -10.965101   \n",
       "353 -441.939383  121.073342  42.228624  44.316016   0.565406   6.006791   \n",
       "34  -226.829176   93.709303   0.471723  42.447517  -8.432659  -4.233105   \n",
       "475 -562.055790  107.554131  26.853017  25.277784   5.072138  -0.991708   \n",
       "261 -436.370819  135.433312  19.837799  38.866741   9.593291  -1.529023   \n",
       "197 -319.901998   78.768449  17.341875  43.145510  15.078900   1.285913   \n",
       "239 -549.593547   96.194970  26.251380  35.855242  11.222940  -1.259802   \n",
       "277 -450.102935  134.773577  36.648986  52.442089  15.246445   2.710231   \n",
       "385 -455.124380   99.359560  36.538788  35.767154  12.141202   1.231861   \n",
       "384 -396.615148   95.302145  21.180622  36.349787  19.660689   2.719008   \n",
       "\n",
       "            6          7          8          9   ...        30        31  \\\n",
       "12  -24.872378  -5.148656  -0.039547 -10.816283  ...  0.094653  1.922031   \n",
       "260 -19.036167   0.314333   5.954609  -6.524187  ...  0.475086  0.764855   \n",
       "148 -25.907954  -3.376129   0.781092 -12.693077  ... -2.245740  4.214099   \n",
       "337  -9.655647  -6.929020   5.113030   4.176812  ...  1.406707  0.538939   \n",
       "288 -14.742881   0.687592   1.321263  -5.509755  ...  0.231847  0.684991   \n",
       "250   5.861604   2.698900  -4.866779   1.311889  ...  1.026799  0.253118   \n",
       "280 -17.877608   3.932217   0.856776  -9.977901  ...  0.093268  1.204498   \n",
       "456 -19.945104  -3.327016  -1.510647  -9.728044  ...  3.622234  2.925757   \n",
       "161 -13.862579  -9.817516  -6.566922   3.962269  ...  4.743016  5.546566   \n",
       "36  -29.251653  -4.576898  -2.315240 -14.437467  ... -1.296631  1.045617   \n",
       "368 -12.976320   3.972902   5.519806  -7.376347  ...  1.304375  2.459639   \n",
       "119 -11.603914  -2.241049  -8.431053 -12.230952  ...  0.140043 -1.359306   \n",
       "21  -19.112421  -4.126155  -3.454874  -2.151538  ... -1.823949 -0.154802   \n",
       "397  -9.289378  -5.950959  -1.032873   0.885925  ... -0.312108  0.683822   \n",
       "423 -16.668871   0.468744  -9.847779 -13.191914  ...  0.358069  1.241784   \n",
       "169 -12.761745  -7.420061  -6.527652  -0.068557  ...  5.934588  5.416731   \n",
       "350  -2.721811  -5.487784 -14.612774  -2.332597  ...  0.184617  0.511796   \n",
       "9   -13.853373   0.178914  -1.616934   1.959738  ...  0.892974  0.141898   \n",
       "168 -24.401392   1.727612   0.480743 -14.468013  ...  0.043533  2.885248   \n",
       "112 -19.095919  -1.081341  -1.801339 -16.871039  ... -0.494622  0.313001   \n",
       "401  -9.922833 -10.160527  -7.804421   4.860304  ...  0.135046 -0.216605   \n",
       "58  -14.590222  -4.090602 -17.707419  -5.517556  ...  1.642368  2.337504   \n",
       "118  -7.081349  -4.429382  -8.290206  -3.702344  ...  1.238613  2.370341   \n",
       "451  -7.506805  -4.842706 -13.191851 -12.959278  ...  4.426111  5.177279   \n",
       "338   3.421248   1.049910  -8.883140   0.807907  ...  1.137249  2.297980   \n",
       "446  -9.108992  -2.146361 -12.959524  -2.016111  ...  3.188646  3.218551   \n",
       "103  -8.815575   3.864244  -3.055049  -9.098061  ...  2.231181  0.341566   \n",
       "306   7.464531   1.244229 -10.944938   1.566006  ...  2.284521  2.008376   \n",
       "355   1.167161   3.224571  -5.404695  -9.356676  ...  1.651552  2.132630   \n",
       "22   -9.241305  -0.922913 -11.749296  -4.356548  ...  0.920867  0.249137   \n",
       "..         ...        ...        ...        ...  ...       ...       ...   \n",
       "105 -10.052050  -5.085905   4.141112   4.651836  ...  1.718879  1.882781   \n",
       "291  -5.712378   4.939312 -12.768874 -14.474800  ... -1.143227  1.568735   \n",
       "3   -15.700971  -2.773550  -5.163968 -11.310603  ... -2.580128 -1.982804   \n",
       "262   0.343810   2.427382  -8.502563   1.338325  ...  1.564645  1.180753   \n",
       "406   0.302530  -0.876979  -9.754246   1.815627  ...  2.216655  3.416843   \n",
       "402   6.147035   0.027061 -11.670313  -0.428516  ...  3.392816  3.341651   \n",
       "430  -4.251045   0.597293  -6.918529  -1.235340  ...  0.384934  1.026097   \n",
       "165 -23.431848 -14.130073  -7.768824   0.927446  ...  9.633837  7.363714   \n",
       "241 -24.717426  -5.705747   2.717990  -2.816059  ... -0.169357  0.741317   \n",
       "40  -24.746914  -3.276896   1.782275  -9.783207  ... -0.649823  0.497959   \n",
       "69  -14.493118  -3.506007   4.074500   9.947217  ...  2.309879  2.637121   \n",
       "285 -13.487579   2.969503   5.324938  -4.175093  ... -0.829099  0.160902   \n",
       "227 -16.119903  -5.374135  -9.205994 -15.640402  ...  1.506510  2.181098   \n",
       "130  -6.788085  -1.806376  -8.041108  -0.613035  ...  4.786008  3.298865   \n",
       "342   1.966906  -1.379982 -10.738918  -2.128725  ...  0.908686  2.708944   \n",
       "199  -9.973155  -6.239166 -11.178637 -13.318111  ...  0.059648 -0.426545   \n",
       "166 -17.686169 -15.280418 -13.796058  -2.879346  ...  5.879108  4.037976   \n",
       "181 -21.663240  -1.987640  -6.056660  -1.838507  ...  0.889446  3.595333   \n",
       "133 -21.827561 -10.262245  -6.993255   0.242945  ...  2.479265  2.803738   \n",
       "371  -6.431071   6.098152  -0.643167  -4.468894  ...  0.533046 -1.293357   \n",
       "435 -14.581704  -3.533224  -9.768176 -14.369276  ... -0.217283 -1.487998   \n",
       "353  -4.745008  -3.385309  -1.493476   3.116250  ... -1.050425  0.961721   \n",
       "34  -15.760228  -3.213731 -12.499037  -3.621449  ...  1.171142  2.443039   \n",
       "475 -12.561367  -4.152792  -8.706542 -13.637620  ... -0.653458 -0.560693   \n",
       "261 -18.785781  -3.340150   2.919727   2.778586  ... -2.077948  0.289998   \n",
       "197 -15.494866  -6.915486  -6.775249  -7.266575  ... -1.164263  0.236306   \n",
       "239 -14.315946  -6.897882  -5.457868 -12.388130  ...  0.345621  0.934451   \n",
       "277 -18.517984  -3.401544   2.314736  -3.260462  ...  0.967500  2.334119   \n",
       "385  -7.421506  -3.392504   0.131567   0.576603  ...  2.998948  4.015828   \n",
       "384 -15.584608  -3.168175  -3.618893  -9.905001  ... -0.151456  0.709250   \n",
       "\n",
       "           32         33         34         35         36         37  \\\n",
       "12   2.069620   1.789086   1.402842   1.192773   2.013896   2.935015   \n",
       "260  2.257194   1.738118   1.038085   1.238373   1.734420   2.330078   \n",
       "148  7.637096  11.883751  15.016872  15.636499  12.301138   8.042070   \n",
       "337 -0.411754   1.952185   2.514050   0.700188   0.558373  -0.027693   \n",
       "288  0.407341   1.436117   0.907008  -0.735813  -0.340283   1.214350   \n",
       "250 -0.994997   0.461636   0.465271  -0.341487   0.240919  -0.200263   \n",
       "280  0.662170   1.290700   1.350119   0.512094  -0.365574   0.171132   \n",
       "456  5.076261   4.986268   4.139367   5.599611   7.593524   7.631419   \n",
       "161  5.094293   5.683984   5.993845   4.896129   5.367832   5.546755   \n",
       "36   1.390836   2.190548   4.104951   5.339343   6.885227   5.573310   \n",
       "368  7.031638  10.685749  13.381920  15.544302  14.403574  10.910903   \n",
       "119 -0.877896   1.434194  -0.242057  -2.660174   0.283196   1.534021   \n",
       "21   1.964497   1.255755   0.608359   0.679066   0.849191   1.283594   \n",
       "397  2.695188   4.416217   5.010666   4.190008   4.481039   5.206698   \n",
       "423  5.565015   4.851893   6.418690   7.039807   6.523548   6.526476   \n",
       "169  4.644275   3.695900   2.996713   2.943676   3.729929   4.140914   \n",
       "350  0.028943  -0.172511   0.542554   0.723893   0.219070   0.134097   \n",
       "9    1.821391   2.529989   1.968246   2.439394   3.644267   3.000721   \n",
       "168  1.025534  -0.121056   1.210861   3.269635   3.549279   7.939622   \n",
       "112  0.552062  -1.445480  -1.226161   1.729511   3.378181   5.310474   \n",
       "401  0.442285   2.677046   3.935339   4.211635   6.919534   9.008892   \n",
       "58   4.073754   1.221485   1.994306   2.067558   2.249683   4.469474   \n",
       "118  2.882989   1.881962   2.258587   2.833024   2.439725   2.751248   \n",
       "451  2.554160   2.186716   5.343213   3.646216   3.993214   2.326687   \n",
       "338  2.212605   0.884639  -0.239720   0.917674   3.352121   4.327776   \n",
       "446  2.460108   1.244071   3.105667   2.021699   3.606981   4.024233   \n",
       "103 -0.129298   0.363795   0.466652  -0.227194   1.567995   0.900737   \n",
       "306  0.598170   0.175363   0.380484   0.732959   1.616396   2.283424   \n",
       "355  0.751663  -0.968554   0.145046  -0.253114   1.210670   3.194715   \n",
       "22   2.279387   2.188748   2.733104   2.431164   2.090510   3.369304   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "105  1.708072   1.198320   2.215826   2.800559   2.886817   3.867586   \n",
       "291  1.288424  -0.988612  -1.843756  -1.796114   1.200146   0.327601   \n",
       "3   -0.331088  -2.861281  -2.723364   0.419460   2.015126   1.980087   \n",
       "262  2.646671   2.562342   2.029351   1.301214   2.026145   4.375845   \n",
       "406  2.306034   1.992271   2.432954   1.527816   1.284672   0.879847   \n",
       "402  1.174717   1.227031   1.056021   0.537438   0.450876  -0.222660   \n",
       "430  2.588998   2.699226   1.447225   0.253246   1.453918   2.504979   \n",
       "165  6.801923   7.122531   4.459290   2.609737   2.826959   3.389008   \n",
       "241 -0.332308   0.449911   0.845619   0.116425   1.158065   2.381865   \n",
       "40   1.968609   1.951153   0.974884   0.591810   2.367409   4.864021   \n",
       "69   5.963342   3.102167   3.136553   4.544684   4.318352   3.409357   \n",
       "285  0.531549   1.310473   1.356206   0.217443   2.057493   2.218633   \n",
       "227 -0.020008   0.174914   1.905475  -0.366554   2.614419   3.634988   \n",
       "130  3.248292   1.469338   1.942831   3.576282   1.584157   1.607352   \n",
       "342  1.517132   1.785931   2.981266   1.518840   1.453033   1.966187   \n",
       "199  1.435029   2.294525   1.277858  -1.131861   1.802468   4.437437   \n",
       "166  3.712013   3.269332   2.483173   2.681557   1.576796   3.074815   \n",
       "181  5.008366   4.674027   4.232653   4.111045   3.903578   4.511707   \n",
       "133  3.537723   3.529042   2.132112   2.144042   1.879729   2.174715   \n",
       "371 -1.826354  -2.582217  -0.321365  -0.150544   0.305770  -0.047913   \n",
       "435  1.160371   0.669748   3.622553   4.290413   2.267128   2.581942   \n",
       "353 -0.667593   0.806910   1.532966  -1.231958   1.757688   1.522121   \n",
       "34   2.943492   2.063990   2.611041   1.508550   1.366474   2.892521   \n",
       "475  0.263442   1.797453   1.149249  -0.706918   2.148012   2.364498   \n",
       "261  0.100389   1.427070   1.698957   0.558742   1.796393   3.256265   \n",
       "197  2.347420   3.265172   2.424406   1.083118   1.794233   2.718746   \n",
       "239  2.078736   2.417572   1.947629   0.097649   2.305652   2.851927   \n",
       "277 -1.998438   1.814853   1.121548  -1.448660   2.104702   1.184363   \n",
       "385  5.615757   6.720202   5.859033   4.839969   2.976057   2.541430   \n",
       "384  1.657197   4.079550   9.983696  15.611817  17.373626  14.530228   \n",
       "\n",
       "            38         39  \n",
       "12    3.895297   5.941611  \n",
       "260   1.231918   1.440224  \n",
       "148   5.284950   3.425573  \n",
       "337   1.218584   1.688338  \n",
       "288   2.179666   1.231693  \n",
       "250  -0.106715   0.810546  \n",
       "280   0.139680  -0.069024  \n",
       "456   6.697954   5.786440  \n",
       "161   4.691688   3.431571  \n",
       "36    6.737365   6.787633  \n",
       "368   5.343784   2.570242  \n",
       "119  -0.873214  -1.603326  \n",
       "21    1.590320   1.617642  \n",
       "397   4.853494   4.402532  \n",
       "423   4.778089   4.733151  \n",
       "169   2.323401   2.297245  \n",
       "350   0.170139   0.447085  \n",
       "9     4.114735   5.142286  \n",
       "168  10.756551  10.050595  \n",
       "112   8.002821   8.380767  \n",
       "401   8.672603   9.387525  \n",
       "58    3.492391   2.744447  \n",
       "118   4.530745   5.222333  \n",
       "451   0.506513   3.333642  \n",
       "338   4.452914   2.091570  \n",
       "446   2.494627   2.720836  \n",
       "103  -1.163473   0.728602  \n",
       "306   2.273788   1.790770  \n",
       "355  -1.874546  -2.026386  \n",
       "22    2.246630   2.007894  \n",
       "..         ...        ...  \n",
       "105   3.235160   4.495156  \n",
       "291  -3.404551  -2.832622  \n",
       "3    -0.398496  -0.039357  \n",
       "262   4.780044   3.547263  \n",
       "406   1.154534   0.759829  \n",
       "402   1.172093   0.972544  \n",
       "430   2.104876   1.271855  \n",
       "165   2.765094   3.615255  \n",
       "241   1.937507   2.386734  \n",
       "40    7.062141   8.062965  \n",
       "69    3.593279   3.990837  \n",
       "285   2.019491   4.059384  \n",
       "227   1.905689   3.461926  \n",
       "130   1.998821   2.675377  \n",
       "342   2.162614   2.396414  \n",
       "199   2.567069   2.111247  \n",
       "166   3.111052   0.492740  \n",
       "181   4.754718   3.825773  \n",
       "133   1.775709   1.456835  \n",
       "371  -1.527759   0.069459  \n",
       "435  -1.219281  -1.583040  \n",
       "353   0.489499   1.825178  \n",
       "34    1.041060   0.339918  \n",
       "475   1.906818   2.230867  \n",
       "261   3.834511   2.645109  \n",
       "197   2.170102   2.408735  \n",
       "239   2.151014   2.977748  \n",
       "277   1.309205   0.993657  \n",
       "385   3.290174   5.419835  \n",
       "384   9.388773   6.697734  \n",
       "\n",
       "[387 rows x 40 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabel = train.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = test.iloc[:, :-1]\n",
    "testlabel = test.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testlabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>disgusted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>disgusted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>disgusted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>disgusted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>disgusted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>disgusted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion\n",
       "12       angry\n",
       "260    neutral\n",
       "148    fearful\n",
       "337    neutral\n",
       "288    neutral\n",
       "250    neutral\n",
       "280    neutral\n",
       "456  surprised\n",
       "161    fearful\n",
       "36       angry\n",
       "368        sad\n",
       "119  disgusted\n",
       "21       angry\n",
       "397        sad\n",
       "423  surprised\n",
       "169    fearful\n",
       "350    neutral\n",
       "9        angry\n",
       "168    fearful\n",
       "112  disgusted\n",
       "401        sad\n",
       "58       angry\n",
       "118  disgusted\n",
       "451  surprised\n",
       "338    neutral\n",
       "446  surprised\n",
       "103  disgusted\n",
       "306    neutral\n",
       "355    neutral\n",
       "22       angry\n",
       "..         ...\n",
       "105  disgusted\n",
       "291    neutral\n",
       "3        angry\n",
       "262    neutral\n",
       "406        sad\n",
       "402        sad\n",
       "430  surprised\n",
       "165    fearful\n",
       "241    neutral\n",
       "40       angry\n",
       "69   disgusted\n",
       "285    neutral\n",
       "227      happy\n",
       "130    fearful\n",
       "342    neutral\n",
       "199      happy\n",
       "166    fearful\n",
       "181      happy\n",
       "133    fearful\n",
       "371        sad\n",
       "435  surprised\n",
       "353    neutral\n",
       "34       angry\n",
       "475  surprised\n",
       "261    neutral\n",
       "197      happy\n",
       "239      happy\n",
       "277    neutral\n",
       "385        sad\n",
       "384        sad\n",
       "\n",
       "[387 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-287.8238707 ,  101.51551026,    6.41014822, ...,    2.93501496,\n",
       "           3.8952973 ,    5.94161147],\n",
       "       [-432.12746605,  130.331011  ,   15.42120293, ...,    2.33007829,\n",
       "           1.23191773,    1.44022361],\n",
       "       [-340.49558067,   96.43981326,   21.21916801, ...,    8.04207037,\n",
       "           5.28495043,    3.42557283],\n",
       "       ...,\n",
       "       [-450.10293482,  134.773577  ,   36.6489865 , ...,    1.1843626 ,\n",
       "           1.30920473,    0.99365732],\n",
       "       [-455.12437988,   99.35955961,   36.53878765, ...,    2.54142979,\n",
       "           3.29017421,    5.41983481],\n",
       "       [-396.61514783,   95.30214462,   21.180622  , ...,   14.53022755,\n",
       "           9.3887727 ,    6.69773368]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 40)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for cnn\n",
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(40,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 40, 256)           1536      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 40, 128)           163968    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 5, 128)            82048     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5, 128)            82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 4487      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 334,087\n",
      "Trainable params: 334,087\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ioann\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 387 samples, validate on 93 samples\n",
      "Epoch 1/700\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 4.3586 - accuracy: 0.1421 - val_loss: 2.3254 - val_accuracy: 0.1720\n",
      "Epoch 2/700\n",
      "387/387 [==============================] - 0s 655us/step - loss: 2.2697 - accuracy: 0.1886 - val_loss: 1.9028 - val_accuracy: 0.3011\n",
      "Epoch 3/700\n",
      "387/387 [==============================] - 0s 704us/step - loss: 1.9561 - accuracy: 0.2532 - val_loss: 1.8042 - val_accuracy: 0.2796\n",
      "Epoch 4/700\n",
      "387/387 [==============================] - 0s 679us/step - loss: 1.9000 - accuracy: 0.2351 - val_loss: 1.7841 - val_accuracy: 0.2796\n",
      "Epoch 5/700\n",
      "387/387 [==============================] - 0s 662us/step - loss: 1.8889 - accuracy: 0.2558 - val_loss: 1.7890 - val_accuracy: 0.3656\n",
      "Epoch 6/700\n",
      "387/387 [==============================] - 0s 701us/step - loss: 1.8163 - accuracy: 0.3049 - val_loss: 1.7598 - val_accuracy: 0.3226\n",
      "Epoch 7/700\n",
      "387/387 [==============================] - 0s 691us/step - loss: 1.8417 - accuracy: 0.2739 - val_loss: 1.7831 - val_accuracy: 0.3656\n",
      "Epoch 8/700\n",
      "387/387 [==============================] - 0s 678us/step - loss: 1.7812 - accuracy: 0.3333 - val_loss: 1.7276 - val_accuracy: 0.3656\n",
      "Epoch 9/700\n",
      "387/387 [==============================] - 0s 682us/step - loss: 1.7161 - accuracy: 0.3411 - val_loss: 1.7207 - val_accuracy: 0.2688\n",
      "Epoch 10/700\n",
      "387/387 [==============================] - 0s 698us/step - loss: 1.7351 - accuracy: 0.3437 - val_loss: 1.6843 - val_accuracy: 0.3978\n",
      "Epoch 11/700\n",
      "387/387 [==============================] - 0s 644us/step - loss: 1.7063 - accuracy: 0.3463 - val_loss: 1.6466 - val_accuracy: 0.3441\n",
      "Epoch 12/700\n",
      "387/387 [==============================] - 0s 626us/step - loss: 1.6937 - accuracy: 0.3695 - val_loss: 1.6885 - val_accuracy: 0.3226\n",
      "Epoch 13/700\n",
      "387/387 [==============================] - 0s 626us/step - loss: 1.6607 - accuracy: 0.3695 - val_loss: 1.6630 - val_accuracy: 0.3011\n",
      "Epoch 14/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 1.6303 - accuracy: 0.3850 - val_loss: 1.6302 - val_accuracy: 0.3226\n",
      "Epoch 15/700\n",
      "387/387 [==============================] - 0s 655us/step - loss: 1.6231 - accuracy: 0.3876 - val_loss: 1.6221 - val_accuracy: 0.3656\n",
      "Epoch 16/700\n",
      "387/387 [==============================] - 0s 629us/step - loss: 1.6039 - accuracy: 0.4005 - val_loss: 1.6160 - val_accuracy: 0.3656\n",
      "Epoch 17/700\n",
      "387/387 [==============================] - 0s 630us/step - loss: 1.6077 - accuracy: 0.4031 - val_loss: 1.5961 - val_accuracy: 0.3978\n",
      "Epoch 18/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 1.5607 - accuracy: 0.3953 - val_loss: 1.5921 - val_accuracy: 0.3978\n",
      "Epoch 19/700\n",
      "387/387 [==============================] - 0s 664us/step - loss: 1.5495 - accuracy: 0.4367 - val_loss: 1.5907 - val_accuracy: 0.3978\n",
      "Epoch 20/700\n",
      "387/387 [==============================] - 0s 631us/step - loss: 1.5403 - accuracy: 0.4160 - val_loss: 1.5604 - val_accuracy: 0.3763\n",
      "Epoch 21/700\n",
      "387/387 [==============================] - 0s 621us/step - loss: 1.5120 - accuracy: 0.4315 - val_loss: 1.5481 - val_accuracy: 0.3763\n",
      "Epoch 22/700\n",
      "387/387 [==============================] - 0s 611us/step - loss: 1.4962 - accuracy: 0.4419 - val_loss: 1.4938 - val_accuracy: 0.4086\n",
      "Epoch 23/700\n",
      "387/387 [==============================] - 0s 647us/step - loss: 1.4899 - accuracy: 0.4522 - val_loss: 1.5778 - val_accuracy: 0.3871\n",
      "Epoch 24/700\n",
      "387/387 [==============================] - 0s 637us/step - loss: 1.4775 - accuracy: 0.4599 - val_loss: 1.5072 - val_accuracy: 0.4086\n",
      "Epoch 25/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 1.4629 - accuracy: 0.4238 - val_loss: 1.4730 - val_accuracy: 0.4409\n",
      "Epoch 26/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 1.4517 - accuracy: 0.4264 - val_loss: 1.4675 - val_accuracy: 0.3871\n",
      "Epoch 27/700\n",
      "387/387 [==============================] - 0s 621us/step - loss: 1.4158 - accuracy: 0.4703 - val_loss: 1.5012 - val_accuracy: 0.4194\n",
      "Epoch 28/700\n",
      "387/387 [==============================] - 0s 621us/step - loss: 1.3950 - accuracy: 0.4755 - val_loss: 1.5263 - val_accuracy: 0.3763\n",
      "Epoch 29/700\n",
      "387/387 [==============================] - 0s 602us/step - loss: 1.4165 - accuracy: 0.4625 - val_loss: 1.4355 - val_accuracy: 0.4301\n",
      "Epoch 30/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 1.3689 - accuracy: 0.5116 - val_loss: 1.4147 - val_accuracy: 0.4194\n",
      "Epoch 31/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 1.3531 - accuracy: 0.4806 - val_loss: 1.4256 - val_accuracy: 0.4301\n",
      "Epoch 32/700\n",
      "387/387 [==============================] - 0s 629us/step - loss: 1.3430 - accuracy: 0.5065 - val_loss: 1.4257 - val_accuracy: 0.4301\n",
      "Epoch 33/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 1.3320 - accuracy: 0.5013 - val_loss: 1.4186 - val_accuracy: 0.4516\n",
      "Epoch 34/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 1.3346 - accuracy: 0.4935 - val_loss: 1.3654 - val_accuracy: 0.4839\n",
      "Epoch 35/700\n",
      "387/387 [==============================] - 0s 608us/step - loss: 1.3146 - accuracy: 0.4935 - val_loss: 1.3760 - val_accuracy: 0.4409\n",
      "Epoch 36/700\n",
      "387/387 [==============================] - 0s 638us/step - loss: 1.3051 - accuracy: 0.4832 - val_loss: 1.3536 - val_accuracy: 0.4516\n",
      "Epoch 37/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 1.2771 - accuracy: 0.5090 - val_loss: 1.3647 - val_accuracy: 0.4409\n",
      "Epoch 38/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 1.2657 - accuracy: 0.5065 - val_loss: 1.3391 - val_accuracy: 0.4086\n",
      "Epoch 39/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 1.2569 - accuracy: 0.5323 - val_loss: 1.3201 - val_accuracy: 0.3871\n",
      "Epoch 40/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 1.2377 - accuracy: 0.5349 - val_loss: 1.4450 - val_accuracy: 0.3441\n",
      "Epoch 41/700\n",
      "387/387 [==============================] - 0s 629us/step - loss: 1.2333 - accuracy: 0.5504 - val_loss: 1.3529 - val_accuracy: 0.4086\n",
      "Epoch 42/700\n",
      "387/387 [==============================] - 0s 610us/step - loss: 1.2241 - accuracy: 0.5245 - val_loss: 1.3058 - val_accuracy: 0.3871\n",
      "Epoch 43/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 1.2028 - accuracy: 0.5426 - val_loss: 1.3048 - val_accuracy: 0.4516\n",
      "Epoch 44/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 1.1891 - accuracy: 0.5607 - val_loss: 1.3227 - val_accuracy: 0.4624\n",
      "Epoch 45/700\n",
      "387/387 [==============================] - 0s 637us/step - loss: 1.2020 - accuracy: 0.5659 - val_loss: 1.3117 - val_accuracy: 0.4624\n",
      "Epoch 46/700\n",
      "387/387 [==============================] - 0s 626us/step - loss: 1.1964 - accuracy: 0.5426 - val_loss: 1.3167 - val_accuracy: 0.4516\n",
      "Epoch 47/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 1.1871 - accuracy: 0.5452 - val_loss: 1.2575 - val_accuracy: 0.3871\n",
      "Epoch 48/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 1.1823 - accuracy: 0.5685 - val_loss: 1.3317 - val_accuracy: 0.4409\n",
      "Epoch 49/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 1.1864 - accuracy: 0.5530 - val_loss: 1.3177 - val_accuracy: 0.4624\n",
      "Epoch 50/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 1.1366 - accuracy: 0.5581 - val_loss: 1.2540 - val_accuracy: 0.4731\n",
      "Epoch 51/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 1.1267 - accuracy: 0.5452 - val_loss: 1.2470 - val_accuracy: 0.4409\n",
      "Epoch 52/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 1.1429 - accuracy: 0.5607 - val_loss: 1.2680 - val_accuracy: 0.4624\n",
      "Epoch 53/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 1.1367 - accuracy: 0.5633 - val_loss: 1.3341 - val_accuracy: 0.4409\n",
      "Epoch 54/700\n",
      "387/387 [==============================] - 0s 629us/step - loss: 1.1295 - accuracy: 0.5633 - val_loss: 1.2571 - val_accuracy: 0.4946\n",
      "Epoch 55/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 0s 600us/step - loss: 1.1284 - accuracy: 0.5762 - val_loss: 1.2741 - val_accuracy: 0.4731\n",
      "Epoch 56/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 1.1003 - accuracy: 0.5556 - val_loss: 1.2396 - val_accuracy: 0.5054\n",
      "Epoch 57/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 1.1000 - accuracy: 0.5840 - val_loss: 1.2501 - val_accuracy: 0.5161\n",
      "Epoch 58/700\n",
      "387/387 [==============================] - 0s 619us/step - loss: 1.0893 - accuracy: 0.5814 - val_loss: 1.2436 - val_accuracy: 0.4516\n",
      "Epoch 59/700\n",
      "387/387 [==============================] - 0s 613us/step - loss: 1.1018 - accuracy: 0.5607 - val_loss: 1.2689 - val_accuracy: 0.4946\n",
      "Epoch 60/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 1.0878 - accuracy: 0.5866 - val_loss: 1.2164 - val_accuracy: 0.5269\n",
      "Epoch 61/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 1.0708 - accuracy: 0.5866 - val_loss: 1.2365 - val_accuracy: 0.5269\n",
      "Epoch 62/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 1.0907 - accuracy: 0.5556 - val_loss: 1.2006 - val_accuracy: 0.4731\n",
      "Epoch 63/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 1.0873 - accuracy: 0.5788 - val_loss: 1.2099 - val_accuracy: 0.5054\n",
      "Epoch 64/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 1.0605 - accuracy: 0.5891 - val_loss: 1.2533 - val_accuracy: 0.4946\n",
      "Epoch 65/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 1.0441 - accuracy: 0.6150 - val_loss: 1.2523 - val_accuracy: 0.4946\n",
      "Epoch 66/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 1.0550 - accuracy: 0.5762 - val_loss: 1.2038 - val_accuracy: 0.4946\n",
      "Epoch 67/700\n",
      "387/387 [==============================] - 0s 624us/step - loss: 1.0404 - accuracy: 0.6150 - val_loss: 1.2700 - val_accuracy: 0.4516\n",
      "Epoch 68/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 1.0545 - accuracy: 0.6021 - val_loss: 1.2085 - val_accuracy: 0.4946\n",
      "Epoch 69/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 1.0381 - accuracy: 0.6202 - val_loss: 1.1759 - val_accuracy: 0.4731\n",
      "Epoch 70/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 1.0184 - accuracy: 0.6047 - val_loss: 1.1943 - val_accuracy: 0.4946\n",
      "Epoch 71/700\n",
      "387/387 [==============================] - 0s 629us/step - loss: 1.0456 - accuracy: 0.6098 - val_loss: 1.1688 - val_accuracy: 0.5161\n",
      "Epoch 72/700\n",
      "387/387 [==============================] - 0s 670us/step - loss: 0.9995 - accuracy: 0.6072 - val_loss: 1.2097 - val_accuracy: 0.5269\n",
      "Epoch 73/700\n",
      "387/387 [==============================] - 0s 655us/step - loss: 1.0159 - accuracy: 0.5891 - val_loss: 1.2078 - val_accuracy: 0.4624\n",
      "Epoch 74/700\n",
      "387/387 [==============================] - 0s 644us/step - loss: 1.0026 - accuracy: 0.6253 - val_loss: 1.1748 - val_accuracy: 0.4839\n",
      "Epoch 75/700\n",
      "387/387 [==============================] - 0s 644us/step - loss: 0.9976 - accuracy: 0.6434 - val_loss: 1.1670 - val_accuracy: 0.4946\n",
      "Epoch 76/700\n",
      "387/387 [==============================] - 0s 670us/step - loss: 1.0034 - accuracy: 0.6253 - val_loss: 1.1923 - val_accuracy: 0.5054\n",
      "Epoch 77/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 0.9976 - accuracy: 0.6227 - val_loss: 1.1537 - val_accuracy: 0.4946\n",
      "Epoch 78/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.9858 - accuracy: 0.6434 - val_loss: 1.1551 - val_accuracy: 0.5484\n",
      "Epoch 79/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.9644 - accuracy: 0.6460 - val_loss: 1.2061 - val_accuracy: 0.5484\n",
      "Epoch 80/700\n",
      "387/387 [==============================] - 0s 626us/step - loss: 0.9958 - accuracy: 0.6357 - val_loss: 1.1510 - val_accuracy: 0.5484\n",
      "Epoch 81/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.6382 - val_loss: 1.1195 - val_accuracy: 0.5161\n",
      "Epoch 82/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.9814 - accuracy: 0.6305 - val_loss: 1.1433 - val_accuracy: 0.5914\n",
      "Epoch 83/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.9857 - accuracy: 0.6331 - val_loss: 1.1629 - val_accuracy: 0.5269\n",
      "Epoch 84/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.9398 - accuracy: 0.6537 - val_loss: 1.1185 - val_accuracy: 0.4731\n",
      "Epoch 85/700\n",
      "387/387 [==============================] - 0s 626us/step - loss: 0.9688 - accuracy: 0.6202 - val_loss: 1.1241 - val_accuracy: 0.5376\n",
      "Epoch 86/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.9620 - accuracy: 0.6202 - val_loss: 1.1279 - val_accuracy: 0.5591\n",
      "Epoch 87/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.9668 - accuracy: 0.6150 - val_loss: 1.1537 - val_accuracy: 0.5054\n",
      "Epoch 88/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.9622 - accuracy: 0.6486 - val_loss: 1.1560 - val_accuracy: 0.5591\n",
      "Epoch 89/700\n",
      "387/387 [==============================] - 0s 629us/step - loss: 0.9488 - accuracy: 0.6331 - val_loss: 1.1185 - val_accuracy: 0.5699\n",
      "Epoch 90/700\n",
      "387/387 [==============================] - 0s 604us/step - loss: 0.9318 - accuracy: 0.6382 - val_loss: 1.1404 - val_accuracy: 0.4946\n",
      "Epoch 91/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.9321 - accuracy: 0.6357 - val_loss: 1.1781 - val_accuracy: 0.5161\n",
      "Epoch 92/700\n",
      "387/387 [==============================] - 0s 584us/step - loss: 0.9525 - accuracy: 0.6305 - val_loss: 1.1557 - val_accuracy: 0.5161\n",
      "Epoch 93/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.9285 - accuracy: 0.6357 - val_loss: 1.0981 - val_accuracy: 0.5054\n",
      "Epoch 94/700\n",
      "387/387 [==============================] - 0s 639us/step - loss: 0.9386 - accuracy: 0.6486 - val_loss: 1.1818 - val_accuracy: 0.4839\n",
      "Epoch 95/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.9218 - accuracy: 0.6563 - val_loss: 1.1012 - val_accuracy: 0.5591\n",
      "Epoch 96/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.9314 - accuracy: 0.6667 - val_loss: 1.1314 - val_accuracy: 0.5484\n",
      "Epoch 97/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.8990 - accuracy: 0.6357 - val_loss: 1.0950 - val_accuracy: 0.5376\n",
      "Epoch 98/700\n",
      "387/387 [==============================] - 0s 639us/step - loss: 0.9192 - accuracy: 0.6563 - val_loss: 1.1056 - val_accuracy: 0.5484\n",
      "Epoch 99/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.9208 - accuracy: 0.6537 - val_loss: 1.1349 - val_accuracy: 0.5269\n",
      "Epoch 100/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.9017 - accuracy: 0.6563 - val_loss: 1.1634 - val_accuracy: 0.4731\n",
      "Epoch 101/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.8925 - accuracy: 0.6408 - val_loss: 1.0829 - val_accuracy: 0.5699\n",
      "Epoch 102/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.8999 - accuracy: 0.6718 - val_loss: 1.1430 - val_accuracy: 0.5591\n",
      "Epoch 103/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.9051 - accuracy: 0.6641 - val_loss: 1.0581 - val_accuracy: 0.5699\n",
      "Epoch 104/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.8937 - accuracy: 0.6796 - val_loss: 1.1268 - val_accuracy: 0.5806\n",
      "Epoch 105/700\n",
      "387/387 [==============================] - 0s 597us/step - loss: 0.9141 - accuracy: 0.6434 - val_loss: 1.1140 - val_accuracy: 0.5591\n",
      "Epoch 106/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.8942 - accuracy: 0.6641 - val_loss: 1.0794 - val_accuracy: 0.5699\n",
      "Epoch 107/700\n",
      "387/387 [==============================] - 0s 637us/step - loss: 0.8898 - accuracy: 0.6641 - val_loss: 1.0875 - val_accuracy: 0.5484\n",
      "Epoch 108/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.8835 - accuracy: 0.6589 - val_loss: 1.0592 - val_accuracy: 0.5161\n",
      "Epoch 109/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.8942 - accuracy: 0.6693 - val_loss: 1.1301 - val_accuracy: 0.5161\n",
      "Epoch 110/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.8844 - accuracy: 0.6641 - val_loss: 1.1768 - val_accuracy: 0.4839\n",
      "Epoch 111/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 0s 637us/step - loss: 0.8807 - accuracy: 0.6537 - val_loss: 1.1009 - val_accuracy: 0.5269\n",
      "Epoch 112/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.8692 - accuracy: 0.6667 - val_loss: 1.0858 - val_accuracy: 0.5161\n",
      "Epoch 113/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.8600 - accuracy: 0.6744 - val_loss: 1.0883 - val_accuracy: 0.5484\n",
      "Epoch 114/700\n",
      "387/387 [==============================] - 0s 584us/step - loss: 0.8613 - accuracy: 0.6718 - val_loss: 1.0964 - val_accuracy: 0.5484\n",
      "Epoch 115/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.8679 - accuracy: 0.6796 - val_loss: 1.0642 - val_accuracy: 0.5591\n",
      "Epoch 116/700\n",
      "387/387 [==============================] - 0s 631us/step - loss: 0.8608 - accuracy: 0.6615 - val_loss: 1.0449 - val_accuracy: 0.6022\n",
      "Epoch 117/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 0.8622 - accuracy: 0.6796 - val_loss: 1.0509 - val_accuracy: 0.5699\n",
      "Epoch 118/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.8582 - accuracy: 0.6796 - val_loss: 1.0711 - val_accuracy: 0.5806\n",
      "Epoch 119/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.8428 - accuracy: 0.6718 - val_loss: 1.1157 - val_accuracy: 0.5806\n",
      "Epoch 120/700\n",
      "387/387 [==============================] - 0s 608us/step - loss: 0.8631 - accuracy: 0.6873 - val_loss: 1.0967 - val_accuracy: 0.5699\n",
      "Epoch 121/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.8443 - accuracy: 0.6899 - val_loss: 1.0579 - val_accuracy: 0.5269\n",
      "Epoch 122/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.8660 - accuracy: 0.6925 - val_loss: 1.0674 - val_accuracy: 0.5591\n",
      "Epoch 123/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.8381 - accuracy: 0.6796 - val_loss: 1.1462 - val_accuracy: 0.4731\n",
      "Epoch 124/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.8735 - accuracy: 0.6615 - val_loss: 1.0705 - val_accuracy: 0.5484\n",
      "Epoch 125/700\n",
      "387/387 [==============================] - 0s 626us/step - loss: 0.8294 - accuracy: 0.6796 - val_loss: 1.1149 - val_accuracy: 0.5376\n",
      "Epoch 126/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.8526 - accuracy: 0.6796 - val_loss: 1.0608 - val_accuracy: 0.5806\n",
      "Epoch 127/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.8388 - accuracy: 0.6848 - val_loss: 1.0784 - val_accuracy: 0.5806\n",
      "Epoch 128/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.8293 - accuracy: 0.6899 - val_loss: 1.0644 - val_accuracy: 0.5269\n",
      "Epoch 129/700\n",
      "387/387 [==============================] - 0s 626us/step - loss: 0.8280 - accuracy: 0.6899 - val_loss: 1.0359 - val_accuracy: 0.5699\n",
      "Epoch 130/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.8386 - accuracy: 0.6796 - val_loss: 1.0594 - val_accuracy: 0.5806\n",
      "Epoch 131/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.8318 - accuracy: 0.6693 - val_loss: 1.0743 - val_accuracy: 0.5269\n",
      "Epoch 132/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.8325 - accuracy: 0.6899 - val_loss: 1.0811 - val_accuracy: 0.5484\n",
      "Epoch 133/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.8240 - accuracy: 0.6848 - val_loss: 1.0429 - val_accuracy: 0.5699\n",
      "Epoch 134/700\n",
      "387/387 [==============================] - 0s 642us/step - loss: 0.8153 - accuracy: 0.7183 - val_loss: 1.0491 - val_accuracy: 0.5269\n",
      "Epoch 135/700\n",
      "387/387 [==============================] - 0s 596us/step - loss: 0.8125 - accuracy: 0.6925 - val_loss: 1.0779 - val_accuracy: 0.5806\n",
      "Epoch 136/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.8165 - accuracy: 0.7003 - val_loss: 1.0471 - val_accuracy: 0.5699\n",
      "Epoch 137/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.8215 - accuracy: 0.6848 - val_loss: 1.0546 - val_accuracy: 0.5699\n",
      "Epoch 138/700\n",
      "387/387 [==============================] - 0s 611us/step - loss: 0.8217 - accuracy: 0.7106 - val_loss: 1.0279 - val_accuracy: 0.5806\n",
      "Epoch 139/700\n",
      "387/387 [==============================] - 0s 642us/step - loss: 0.8151 - accuracy: 0.7080 - val_loss: 1.0300 - val_accuracy: 0.6022\n",
      "Epoch 140/700\n",
      "387/387 [==============================] - 0s 649us/step - loss: 0.7947 - accuracy: 0.7106 - val_loss: 1.0107 - val_accuracy: 0.5161\n",
      "Epoch 141/700\n",
      "387/387 [==============================] - 0s 649us/step - loss: 0.8039 - accuracy: 0.6873 - val_loss: 1.0116 - val_accuracy: 0.5914\n",
      "Epoch 142/700\n",
      "387/387 [==============================] - 0s 686us/step - loss: 0.8018 - accuracy: 0.7003 - val_loss: 1.0313 - val_accuracy: 0.5591\n",
      "Epoch 143/700\n",
      "387/387 [==============================] - 0s 665us/step - loss: 0.7961 - accuracy: 0.7158 - val_loss: 1.0223 - val_accuracy: 0.5484\n",
      "Epoch 144/700\n",
      "387/387 [==============================] - 0s 652us/step - loss: 0.7988 - accuracy: 0.7106 - val_loss: 1.0351 - val_accuracy: 0.6022\n",
      "Epoch 145/700\n",
      "387/387 [==============================] - 0s 612us/step - loss: 0.8021 - accuracy: 0.6796 - val_loss: 1.0244 - val_accuracy: 0.5806\n",
      "Epoch 146/700\n",
      "387/387 [==============================] - 0s 634us/step - loss: 0.8028 - accuracy: 0.6899 - val_loss: 1.0077 - val_accuracy: 0.5806\n",
      "Epoch 147/700\n",
      "387/387 [==============================] - 0s 621us/step - loss: 0.8047 - accuracy: 0.7054 - val_loss: 1.0619 - val_accuracy: 0.5591\n",
      "Epoch 148/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.7869 - accuracy: 0.7028 - val_loss: 1.0202 - val_accuracy: 0.5914\n",
      "Epoch 149/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.7846 - accuracy: 0.7235 - val_loss: 1.0389 - val_accuracy: 0.5914\n",
      "Epoch 150/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.7930 - accuracy: 0.7054 - val_loss: 0.9957 - val_accuracy: 0.5806\n",
      "Epoch 151/700\n",
      "387/387 [==============================] - 0s 639us/step - loss: 0.7817 - accuracy: 0.7235 - val_loss: 1.0084 - val_accuracy: 0.5376\n",
      "Epoch 152/700\n",
      "387/387 [==============================] - 0s 608us/step - loss: 0.7823 - accuracy: 0.6977 - val_loss: 1.0331 - val_accuracy: 0.5591\n",
      "Epoch 153/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.7719 - accuracy: 0.7028 - val_loss: 0.9857 - val_accuracy: 0.5699\n",
      "Epoch 154/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.7754 - accuracy: 0.7313 - val_loss: 1.0742 - val_accuracy: 0.5269\n",
      "Epoch 155/700\n",
      "387/387 [==============================] - 0s 639us/step - loss: 0.7850 - accuracy: 0.7054 - val_loss: 1.0242 - val_accuracy: 0.5376\n",
      "Epoch 156/700\n",
      "387/387 [==============================] - 0s 621us/step - loss: 0.7941 - accuracy: 0.7003 - val_loss: 1.0157 - val_accuracy: 0.5376\n",
      "Epoch 157/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.7658 - accuracy: 0.7183 - val_loss: 1.0344 - val_accuracy: 0.5484\n",
      "Epoch 158/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.7585 - accuracy: 0.7390 - val_loss: 1.0063 - val_accuracy: 0.5806\n",
      "Epoch 159/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.7701 - accuracy: 0.7106 - val_loss: 1.0937 - val_accuracy: 0.5269\n",
      "Epoch 160/700\n",
      "387/387 [==============================] - 0s 634us/step - loss: 0.7712 - accuracy: 0.7183 - val_loss: 1.0214 - val_accuracy: 0.5591\n",
      "Epoch 161/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.7681 - accuracy: 0.7158 - val_loss: 0.9992 - val_accuracy: 0.5484\n",
      "Epoch 162/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.7544 - accuracy: 0.7080 - val_loss: 0.9960 - val_accuracy: 0.5806\n",
      "Epoch 163/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.7650 - accuracy: 0.7261 - val_loss: 1.0313 - val_accuracy: 0.5699\n",
      "Epoch 164/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.7520 - accuracy: 0.7339 - val_loss: 1.0002 - val_accuracy: 0.5591\n",
      "Epoch 165/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.7544 - accuracy: 0.7287 - val_loss: 1.0040 - val_accuracy: 0.5914\n",
      "Epoch 166/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.7646 - accuracy: 0.7158 - val_loss: 1.0696 - val_accuracy: 0.5591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.7702 - accuracy: 0.7235 - val_loss: 1.0122 - val_accuracy: 0.5914\n",
      "Epoch 168/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.7516 - accuracy: 0.7287 - val_loss: 1.0652 - val_accuracy: 0.5161\n",
      "Epoch 169/700\n",
      "387/387 [==============================] - 0s 629us/step - loss: 0.7572 - accuracy: 0.7106 - val_loss: 1.0214 - val_accuracy: 0.5376\n",
      "Epoch 170/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.7538 - accuracy: 0.7494 - val_loss: 1.0217 - val_accuracy: 0.5914\n",
      "Epoch 171/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.7522 - accuracy: 0.7261 - val_loss: 0.9864 - val_accuracy: 0.5806\n",
      "Epoch 172/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.7396 - accuracy: 0.7313 - val_loss: 1.0401 - val_accuracy: 0.5269\n",
      "Epoch 173/700\n",
      "387/387 [==============================] - 0s 613us/step - loss: 0.7430 - accuracy: 0.7261 - val_loss: 0.9858 - val_accuracy: 0.5484\n",
      "Epoch 174/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.7450 - accuracy: 0.7183 - val_loss: 1.1015 - val_accuracy: 0.5376\n",
      "Epoch 175/700\n",
      "387/387 [==============================] - 0s 578us/step - loss: 0.7491 - accuracy: 0.7287 - val_loss: 1.0143 - val_accuracy: 0.5269\n",
      "Epoch 176/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.7540 - accuracy: 0.7519 - val_loss: 1.0514 - val_accuracy: 0.5269\n",
      "Epoch 177/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.7302 - accuracy: 0.7209 - val_loss: 1.0307 - val_accuracy: 0.5806\n",
      "Epoch 178/700\n",
      "387/387 [==============================] - 0s 613us/step - loss: 0.7388 - accuracy: 0.7287 - val_loss: 1.0329 - val_accuracy: 0.5699\n",
      "Epoch 179/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.7338 - accuracy: 0.7287 - val_loss: 0.9949 - val_accuracy: 0.5484\n",
      "Epoch 180/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.7372 - accuracy: 0.7390 - val_loss: 1.0219 - val_accuracy: 0.5699\n",
      "Epoch 181/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.7419 - accuracy: 0.7235 - val_loss: 0.9664 - val_accuracy: 0.5806\n",
      "Epoch 182/700\n",
      "387/387 [==============================] - 0s 611us/step - loss: 0.7349 - accuracy: 0.7339 - val_loss: 0.9798 - val_accuracy: 0.5484\n",
      "Epoch 183/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.7313 - accuracy: 0.7339 - val_loss: 1.0123 - val_accuracy: 0.5914\n",
      "Epoch 184/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.7254 - accuracy: 0.7339 - val_loss: 1.1063 - val_accuracy: 0.5269\n",
      "Epoch 185/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.7167 - accuracy: 0.7287 - val_loss: 0.9798 - val_accuracy: 0.5699\n",
      "Epoch 186/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.7097 - accuracy: 0.7494 - val_loss: 0.9488 - val_accuracy: 0.5914\n",
      "Epoch 187/700\n",
      "387/387 [==============================] - 0s 637us/step - loss: 0.7218 - accuracy: 0.7442 - val_loss: 0.9503 - val_accuracy: 0.5699\n",
      "Epoch 188/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.7063 - accuracy: 0.7545 - val_loss: 1.0093 - val_accuracy: 0.5591\n",
      "Epoch 189/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.7215 - accuracy: 0.7468 - val_loss: 1.0023 - val_accuracy: 0.5591\n",
      "Epoch 190/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.7013 - accuracy: 0.7726 - val_loss: 0.9609 - val_accuracy: 0.5484\n",
      "Epoch 191/700\n",
      "387/387 [==============================] - 0s 611us/step - loss: 0.7080 - accuracy: 0.7571 - val_loss: 0.9738 - val_accuracy: 0.5806\n",
      "Epoch 192/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.7214 - accuracy: 0.7287 - val_loss: 0.9798 - val_accuracy: 0.5484\n",
      "Epoch 193/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.7007 - accuracy: 0.7442 - val_loss: 1.0109 - val_accuracy: 0.5484\n",
      "Epoch 194/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.7022 - accuracy: 0.7494 - val_loss: 1.0063 - val_accuracy: 0.5914\n",
      "Epoch 195/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.6999 - accuracy: 0.7390 - val_loss: 1.0334 - val_accuracy: 0.5591\n",
      "Epoch 196/700\n",
      "387/387 [==============================] - 0s 626us/step - loss: 0.7089 - accuracy: 0.7364 - val_loss: 0.9821 - val_accuracy: 0.6022\n",
      "Epoch 197/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.6862 - accuracy: 0.7778 - val_loss: 1.0002 - val_accuracy: 0.5699\n",
      "Epoch 198/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.7008 - accuracy: 0.7416 - val_loss: 0.9852 - val_accuracy: 0.6022\n",
      "Epoch 199/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.6936 - accuracy: 0.7416 - val_loss: 1.0593 - val_accuracy: 0.5161\n",
      "Epoch 200/700\n",
      "387/387 [==============================] - 0s 629us/step - loss: 0.6889 - accuracy: 0.7623 - val_loss: 1.0601 - val_accuracy: 0.5484\n",
      "Epoch 201/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.6892 - accuracy: 0.7442 - val_loss: 0.9770 - val_accuracy: 0.5806\n",
      "Epoch 202/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.6860 - accuracy: 0.7649 - val_loss: 1.0054 - val_accuracy: 0.5806\n",
      "Epoch 203/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.6846 - accuracy: 0.7494 - val_loss: 1.0356 - val_accuracy: 0.5376\n",
      "Epoch 204/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.6870 - accuracy: 0.7674 - val_loss: 1.0053 - val_accuracy: 0.5914\n",
      "Epoch 205/700\n",
      "387/387 [==============================] - 0s 629us/step - loss: 0.6933 - accuracy: 0.7364 - val_loss: 0.9905 - val_accuracy: 0.5591\n",
      "Epoch 206/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.7019 - accuracy: 0.7339 - val_loss: 0.9776 - val_accuracy: 0.5484\n",
      "Epoch 207/700\n",
      "387/387 [==============================] - 0s 636us/step - loss: 0.6860 - accuracy: 0.7390 - val_loss: 0.9855 - val_accuracy: 0.5914\n",
      "Epoch 208/700\n",
      "387/387 [==============================] - 0s 644us/step - loss: 0.6840 - accuracy: 0.7494 - val_loss: 1.0227 - val_accuracy: 0.5376\n",
      "Epoch 209/700\n",
      "387/387 [==============================] - 0s 691us/step - loss: 0.6661 - accuracy: 0.7597 - val_loss: 0.9916 - val_accuracy: 0.5269\n",
      "Epoch 210/700\n",
      "387/387 [==============================] - 0s 682us/step - loss: 0.6855 - accuracy: 0.7468 - val_loss: 1.0756 - val_accuracy: 0.5054\n",
      "Epoch 211/700\n",
      "387/387 [==============================] - 0s 673us/step - loss: 0.6845 - accuracy: 0.7442 - val_loss: 0.9373 - val_accuracy: 0.5699\n",
      "Epoch 212/700\n",
      "387/387 [==============================] - 0s 662us/step - loss: 0.6791 - accuracy: 0.7571 - val_loss: 0.9815 - val_accuracy: 0.5699\n",
      "Epoch 213/700\n",
      "387/387 [==============================] - 0s 678us/step - loss: 0.6728 - accuracy: 0.7597 - val_loss: 0.9518 - val_accuracy: 0.5699\n",
      "Epoch 214/700\n",
      "387/387 [==============================] - 0s 613us/step - loss: 0.6703 - accuracy: 0.7623 - val_loss: 1.0076 - val_accuracy: 0.5591\n",
      "Epoch 215/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.6700 - accuracy: 0.7726 - val_loss: 0.9978 - val_accuracy: 0.5591\n",
      "Epoch 216/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.6689 - accuracy: 0.7623 - val_loss: 1.0012 - val_accuracy: 0.5269\n",
      "Epoch 217/700\n",
      "387/387 [==============================] - 0s 626us/step - loss: 0.6751 - accuracy: 0.7726 - val_loss: 0.9812 - val_accuracy: 0.6344\n",
      "Epoch 218/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.6813 - accuracy: 0.7390 - val_loss: 0.9773 - val_accuracy: 0.5591\n",
      "Epoch 219/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.6740 - accuracy: 0.7804 - val_loss: 0.9800 - val_accuracy: 0.5376\n",
      "Epoch 220/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.6503 - accuracy: 0.7674 - val_loss: 0.9593 - val_accuracy: 0.5914\n",
      "Epoch 221/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.6570 - accuracy: 0.7468 - val_loss: 0.9243 - val_accuracy: 0.5914\n",
      "Epoch 222/700\n",
      "387/387 [==============================] - 0s 619us/step - loss: 0.6735 - accuracy: 0.7597 - val_loss: 0.9668 - val_accuracy: 0.6129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.6561 - accuracy: 0.7597 - val_loss: 0.9533 - val_accuracy: 0.5806\n",
      "Epoch 224/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.6473 - accuracy: 0.8062 - val_loss: 1.0227 - val_accuracy: 0.5484\n",
      "Epoch 225/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.6464 - accuracy: 0.7829 - val_loss: 1.0252 - val_accuracy: 0.5484\n",
      "Epoch 226/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.6361 - accuracy: 0.7907 - val_loss: 1.0395 - val_accuracy: 0.5376\n",
      "Epoch 227/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.6363 - accuracy: 0.7752 - val_loss: 0.9881 - val_accuracy: 0.5591\n",
      "Epoch 228/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.6565 - accuracy: 0.7571 - val_loss: 1.0210 - val_accuracy: 0.5806\n",
      "Epoch 229/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.6506 - accuracy: 0.7649 - val_loss: 0.9393 - val_accuracy: 0.6022\n",
      "Epoch 230/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.6326 - accuracy: 0.7933 - val_loss: 0.9410 - val_accuracy: 0.6022\n",
      "Epoch 231/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.6496 - accuracy: 0.7726 - val_loss: 1.0314 - val_accuracy: 0.5591\n",
      "Epoch 232/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.6536 - accuracy: 0.7700 - val_loss: 0.9919 - val_accuracy: 0.5699\n",
      "Epoch 233/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.6351 - accuracy: 0.7726 - val_loss: 0.9553 - val_accuracy: 0.5914\n",
      "Epoch 234/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.6457 - accuracy: 0.7649 - val_loss: 0.9434 - val_accuracy: 0.6022\n",
      "Epoch 235/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.6436 - accuracy: 0.7778 - val_loss: 0.9902 - val_accuracy: 0.5699\n",
      "Epoch 236/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.6353 - accuracy: 0.7778 - val_loss: 0.9328 - val_accuracy: 0.6022\n",
      "Epoch 237/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.6379 - accuracy: 0.7597 - val_loss: 0.9456 - val_accuracy: 0.5806\n",
      "Epoch 238/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.6352 - accuracy: 0.7804 - val_loss: 0.9366 - val_accuracy: 0.6129\n",
      "Epoch 239/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.6222 - accuracy: 0.7907 - val_loss: 0.9889 - val_accuracy: 0.5591\n",
      "Epoch 240/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 0.6411 - accuracy: 0.7597 - val_loss: 0.9232 - val_accuracy: 0.6022\n",
      "Epoch 241/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.6117 - accuracy: 0.7778 - val_loss: 0.9775 - val_accuracy: 0.6022\n",
      "Epoch 242/700\n",
      "387/387 [==============================] - 0s 579us/step - loss: 0.6234 - accuracy: 0.7804 - val_loss: 0.9727 - val_accuracy: 0.5591\n",
      "Epoch 243/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.6152 - accuracy: 0.7907 - val_loss: 0.9142 - val_accuracy: 0.6022\n",
      "Epoch 244/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.6214 - accuracy: 0.7804 - val_loss: 0.9724 - val_accuracy: 0.6129\n",
      "Epoch 245/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.6219 - accuracy: 0.8036 - val_loss: 0.9290 - val_accuracy: 0.5699\n",
      "Epoch 246/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.6102 - accuracy: 0.7907 - val_loss: 0.9626 - val_accuracy: 0.5806\n",
      "Epoch 247/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.6153 - accuracy: 0.7933 - val_loss: 0.9636 - val_accuracy: 0.6022\n",
      "Epoch 248/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.6111 - accuracy: 0.7829 - val_loss: 0.9126 - val_accuracy: 0.5806\n",
      "Epoch 249/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.6156 - accuracy: 0.7907 - val_loss: 0.9547 - val_accuracy: 0.6559\n",
      "Epoch 250/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.6078 - accuracy: 0.7933 - val_loss: 0.9625 - val_accuracy: 0.5484\n",
      "Epoch 251/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.6002 - accuracy: 0.8062 - val_loss: 1.0382 - val_accuracy: 0.5699\n",
      "Epoch 252/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.6148 - accuracy: 0.7804 - val_loss: 0.9210 - val_accuracy: 0.5914\n",
      "Epoch 253/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.6056 - accuracy: 0.7907 - val_loss: 0.9184 - val_accuracy: 0.6022\n",
      "Epoch 254/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.5975 - accuracy: 0.8114 - val_loss: 0.9964 - val_accuracy: 0.5699\n",
      "Epoch 255/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.6004 - accuracy: 0.8062 - val_loss: 0.9434 - val_accuracy: 0.5806\n",
      "Epoch 256/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.5994 - accuracy: 0.7881 - val_loss: 0.9575 - val_accuracy: 0.6237\n",
      "Epoch 257/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.6042 - accuracy: 0.7907 - val_loss: 0.9391 - val_accuracy: 0.5914\n",
      "Epoch 258/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.5935 - accuracy: 0.8062 - val_loss: 1.0059 - val_accuracy: 0.5484\n",
      "Epoch 259/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.6121 - accuracy: 0.7959 - val_loss: 1.0065 - val_accuracy: 0.5269\n",
      "Epoch 260/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.5991 - accuracy: 0.8036 - val_loss: 0.9654 - val_accuracy: 0.5484\n",
      "Epoch 261/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.5846 - accuracy: 0.8269 - val_loss: 0.9313 - val_accuracy: 0.5591\n",
      "Epoch 262/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.5936 - accuracy: 0.7933 - val_loss: 0.9078 - val_accuracy: 0.6129\n",
      "Epoch 263/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.5937 - accuracy: 0.7933 - val_loss: 0.9299 - val_accuracy: 0.5914\n",
      "Epoch 264/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.5943 - accuracy: 0.7829 - val_loss: 0.9927 - val_accuracy: 0.5806\n",
      "Epoch 265/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.6019 - accuracy: 0.8036 - val_loss: 0.9508 - val_accuracy: 0.6237\n",
      "Epoch 266/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.5822 - accuracy: 0.8062 - val_loss: 0.9735 - val_accuracy: 0.5914\n",
      "Epoch 267/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.5847 - accuracy: 0.8140 - val_loss: 0.8832 - val_accuracy: 0.6022\n",
      "Epoch 268/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.5882 - accuracy: 0.8114 - val_loss: 0.9474 - val_accuracy: 0.5699\n",
      "Epoch 269/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.5813 - accuracy: 0.8088 - val_loss: 0.9222 - val_accuracy: 0.5914\n",
      "Epoch 270/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.5833 - accuracy: 0.7881 - val_loss: 0.9479 - val_accuracy: 0.5914\n",
      "Epoch 271/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.5919 - accuracy: 0.7959 - val_loss: 0.9878 - val_accuracy: 0.5376\n",
      "Epoch 272/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.5816 - accuracy: 0.7933 - val_loss: 0.9263 - val_accuracy: 0.5699\n",
      "Epoch 273/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.5849 - accuracy: 0.8088 - val_loss: 0.8958 - val_accuracy: 0.6022\n",
      "Epoch 274/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.5698 - accuracy: 0.8010 - val_loss: 0.9075 - val_accuracy: 0.6344\n",
      "Epoch 275/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.5726 - accuracy: 0.7984 - val_loss: 0.9237 - val_accuracy: 0.6559\n",
      "Epoch 276/700\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.5970 - accuracy: 0.79 - 0s 625us/step - loss: 0.5813 - accuracy: 0.7984 - val_loss: 0.9475 - val_accuracy: 0.5806\n",
      "Epoch 277/700\n",
      "387/387 [==============================] - 0s 631us/step - loss: 0.5852 - accuracy: 0.7959 - val_loss: 0.8974 - val_accuracy: 0.5699\n",
      "Epoch 278/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 0s 626us/step - loss: 0.5665 - accuracy: 0.8191 - val_loss: 0.9224 - val_accuracy: 0.6022\n",
      "Epoch 279/700\n",
      "387/387 [==============================] - 0s 624us/step - loss: 0.5824 - accuracy: 0.8140 - val_loss: 0.8996 - val_accuracy: 0.5591\n",
      "Epoch 280/700\n",
      "387/387 [==============================] - 0s 629us/step - loss: 0.5752 - accuracy: 0.8165 - val_loss: 0.9386 - val_accuracy: 0.6129\n",
      "Epoch 281/700\n",
      "387/387 [==============================] - 0s 637us/step - loss: 0.5741 - accuracy: 0.8114 - val_loss: 0.9245 - val_accuracy: 0.6129\n",
      "Epoch 282/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.5655 - accuracy: 0.8036 - val_loss: 0.9062 - val_accuracy: 0.6237\n",
      "Epoch 283/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.5710 - accuracy: 0.7933 - val_loss: 0.9374 - val_accuracy: 0.6022\n",
      "Epoch 284/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.5588 - accuracy: 0.8114 - val_loss: 0.8953 - val_accuracy: 0.6129\n",
      "Epoch 285/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.5639 - accuracy: 0.8165 - val_loss: 0.8904 - val_accuracy: 0.6237\n",
      "Epoch 286/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.5623 - accuracy: 0.8036 - val_loss: 0.8909 - val_accuracy: 0.6129\n",
      "Epoch 287/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.5697 - accuracy: 0.8140 - val_loss: 0.8993 - val_accuracy: 0.6237\n",
      "Epoch 288/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.5616 - accuracy: 0.7933 - val_loss: 0.9107 - val_accuracy: 0.6022\n",
      "Epoch 289/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.5528 - accuracy: 0.8269 - val_loss: 0.9013 - val_accuracy: 0.6452\n",
      "Epoch 290/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.5455 - accuracy: 0.8114 - val_loss: 0.8977 - val_accuracy: 0.5914\n",
      "Epoch 291/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.5499 - accuracy: 0.8165 - val_loss: 0.9022 - val_accuracy: 0.6237\n",
      "Epoch 292/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.5522 - accuracy: 0.7984 - val_loss: 0.9261 - val_accuracy: 0.6129\n",
      "Epoch 293/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.5681 - accuracy: 0.7984 - val_loss: 0.8722 - val_accuracy: 0.6452\n",
      "Epoch 294/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.5529 - accuracy: 0.8036 - val_loss: 0.9171 - val_accuracy: 0.6237\n",
      "Epoch 295/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.5340 - accuracy: 0.8372 - val_loss: 0.9455 - val_accuracy: 0.6237\n",
      "Epoch 296/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.5511 - accuracy: 0.7959 - val_loss: 0.9766 - val_accuracy: 0.5591\n",
      "Epoch 297/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.5313 - accuracy: 0.8191 - val_loss: 0.8762 - val_accuracy: 0.6237\n",
      "Epoch 298/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.5473 - accuracy: 0.8140 - val_loss: 0.8809 - val_accuracy: 0.6237\n",
      "Epoch 299/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 0.5302 - accuracy: 0.8346 - val_loss: 0.8771 - val_accuracy: 0.6237\n",
      "Epoch 300/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.5650 - accuracy: 0.8062 - val_loss: 0.9297 - val_accuracy: 0.6344\n",
      "Epoch 301/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.5263 - accuracy: 0.8320 - val_loss: 0.8883 - val_accuracy: 0.6237\n",
      "Epoch 302/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.5426 - accuracy: 0.7984 - val_loss: 0.9243 - val_accuracy: 0.6237\n",
      "Epoch 303/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.5480 - accuracy: 0.8217 - val_loss: 0.9046 - val_accuracy: 0.6022\n",
      "Epoch 304/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.5438 - accuracy: 0.8088 - val_loss: 1.0148 - val_accuracy: 0.5699\n",
      "Epoch 305/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.5502 - accuracy: 0.8010 - val_loss: 0.8861 - val_accuracy: 0.6129\n",
      "Epoch 306/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.5368 - accuracy: 0.8269 - val_loss: 0.8784 - val_accuracy: 0.6129\n",
      "Epoch 307/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.5383 - accuracy: 0.8217 - val_loss: 0.8837 - val_accuracy: 0.5914\n",
      "Epoch 308/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.5393 - accuracy: 0.8165 - val_loss: 0.9488 - val_accuracy: 0.5806\n",
      "Epoch 309/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.5244 - accuracy: 0.7984 - val_loss: 0.9168 - val_accuracy: 0.6129\n",
      "Epoch 310/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.5265 - accuracy: 0.8295 - val_loss: 0.8812 - val_accuracy: 0.6237\n",
      "Epoch 311/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.5371 - accuracy: 0.8217 - val_loss: 0.9451 - val_accuracy: 0.5914\n",
      "Epoch 312/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.5219 - accuracy: 0.8243 - val_loss: 0.8585 - val_accuracy: 0.5806\n",
      "Epoch 313/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.5170 - accuracy: 0.8114 - val_loss: 0.8780 - val_accuracy: 0.6344\n",
      "Epoch 314/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.5241 - accuracy: 0.8295 - val_loss: 0.8649 - val_accuracy: 0.6129\n",
      "Epoch 315/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.5319 - accuracy: 0.8088 - val_loss: 0.8762 - val_accuracy: 0.6129\n",
      "Epoch 316/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.5391 - accuracy: 0.8036 - val_loss: 0.9567 - val_accuracy: 0.5806\n",
      "Epoch 317/700\n",
      "387/387 [==============================] - 0s 611us/step - loss: 0.5239 - accuracy: 0.8191 - val_loss: 0.8916 - val_accuracy: 0.6237\n",
      "Epoch 318/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.5103 - accuracy: 0.8320 - val_loss: 0.9245 - val_accuracy: 0.5699\n",
      "Epoch 319/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.5155 - accuracy: 0.8372 - val_loss: 0.9260 - val_accuracy: 0.6237\n",
      "Epoch 320/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.5147 - accuracy: 0.8450 - val_loss: 0.9136 - val_accuracy: 0.6022\n",
      "Epoch 321/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.5110 - accuracy: 0.8501 - val_loss: 0.8553 - val_accuracy: 0.6237\n",
      "Epoch 322/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.5134 - accuracy: 0.8269 - val_loss: 0.9153 - val_accuracy: 0.6237\n",
      "Epoch 323/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.5225 - accuracy: 0.8424 - val_loss: 0.8628 - val_accuracy: 0.5914\n",
      "Epoch 324/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.5057 - accuracy: 0.8269 - val_loss: 0.8584 - val_accuracy: 0.6129\n",
      "Epoch 325/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.4974 - accuracy: 0.8217 - val_loss: 0.8909 - val_accuracy: 0.6129\n",
      "Epoch 326/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.5009 - accuracy: 0.8398 - val_loss: 0.8569 - val_accuracy: 0.5914\n",
      "Epoch 327/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.5147 - accuracy: 0.8320 - val_loss: 0.9092 - val_accuracy: 0.5806\n",
      "Epoch 328/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.4963 - accuracy: 0.8320 - val_loss: 0.8869 - val_accuracy: 0.6344\n",
      "Epoch 329/700\n",
      "387/387 [==============================] - 0s 576us/step - loss: 0.5040 - accuracy: 0.8346 - val_loss: 0.8594 - val_accuracy: 0.6452\n",
      "Epoch 330/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.5084 - accuracy: 0.8398 - val_loss: 0.8719 - val_accuracy: 0.6022\n",
      "Epoch 331/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.5008 - accuracy: 0.8165 - val_loss: 0.9164 - val_accuracy: 0.6452\n",
      "Epoch 332/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.5092 - accuracy: 0.8398 - val_loss: 0.8550 - val_accuracy: 0.6022\n",
      "Epoch 333/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.4897 - accuracy: 0.8372 - val_loss: 0.9178 - val_accuracy: 0.5914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.4848 - accuracy: 0.8527 - val_loss: 0.8683 - val_accuracy: 0.6344\n",
      "Epoch 335/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.4881 - accuracy: 0.8501 - val_loss: 0.9242 - val_accuracy: 0.5806\n",
      "Epoch 336/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.5004 - accuracy: 0.8501 - val_loss: 0.9129 - val_accuracy: 0.6237\n",
      "Epoch 337/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.4976 - accuracy: 0.8424 - val_loss: 0.8672 - val_accuracy: 0.6022\n",
      "Epoch 338/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.4850 - accuracy: 0.8346 - val_loss: 0.9039 - val_accuracy: 0.6667\n",
      "Epoch 339/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.5013 - accuracy: 0.8320 - val_loss: 0.8837 - val_accuracy: 0.6237\n",
      "Epoch 340/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.4729 - accuracy: 0.8708 - val_loss: 0.8598 - val_accuracy: 0.6667\n",
      "Epoch 341/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.4874 - accuracy: 0.8424 - val_loss: 0.8754 - val_accuracy: 0.6022\n",
      "Epoch 342/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.4883 - accuracy: 0.8450 - val_loss: 0.9074 - val_accuracy: 0.6022\n",
      "Epoch 343/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.4745 - accuracy: 0.8553 - val_loss: 0.8901 - val_accuracy: 0.6022\n",
      "Epoch 344/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.5017 - accuracy: 0.8501 - val_loss: 0.8845 - val_accuracy: 0.6237\n",
      "Epoch 345/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.4871 - accuracy: 0.8553 - val_loss: 0.8739 - val_accuracy: 0.6237\n",
      "Epoch 346/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.4884 - accuracy: 0.8398 - val_loss: 0.9422 - val_accuracy: 0.5591\n",
      "Epoch 347/700\n",
      "387/387 [==============================] - 0s 619us/step - loss: 0.4811 - accuracy: 0.8553 - val_loss: 0.8445 - val_accuracy: 0.6344\n",
      "Epoch 348/700\n",
      "387/387 [==============================] - 0s 611us/step - loss: 0.4776 - accuracy: 0.8450 - val_loss: 0.8612 - val_accuracy: 0.6452\n",
      "Epoch 349/700\n",
      "387/387 [==============================] - 0s 644us/step - loss: 0.4817 - accuracy: 0.8372 - val_loss: 0.9030 - val_accuracy: 0.6129\n",
      "Epoch 350/700\n",
      "387/387 [==============================] - 0s 637us/step - loss: 0.4864 - accuracy: 0.8320 - val_loss: 0.8546 - val_accuracy: 0.5914\n",
      "Epoch 351/700\n",
      "387/387 [==============================] - 0s 635us/step - loss: 0.4757 - accuracy: 0.8424 - val_loss: 0.8665 - val_accuracy: 0.6129\n",
      "Epoch 352/700\n",
      "387/387 [==============================] - 0s 594us/step - loss: 0.4745 - accuracy: 0.8398 - val_loss: 0.8973 - val_accuracy: 0.6237\n",
      "Epoch 353/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.4761 - accuracy: 0.8424 - val_loss: 0.8510 - val_accuracy: 0.6237\n",
      "Epoch 354/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.4757 - accuracy: 0.8605 - val_loss: 0.8438 - val_accuracy: 0.6237\n",
      "Epoch 355/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.4711 - accuracy: 0.8553 - val_loss: 0.8801 - val_accuracy: 0.6559\n",
      "Epoch 356/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.4773 - accuracy: 0.8682 - val_loss: 0.8219 - val_accuracy: 0.6559\n",
      "Epoch 357/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.4761 - accuracy: 0.8346 - val_loss: 0.8890 - val_accuracy: 0.6559\n",
      "Epoch 358/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.4729 - accuracy: 0.8450 - val_loss: 0.9499 - val_accuracy: 0.5914\n",
      "Epoch 359/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.4639 - accuracy: 0.8527 - val_loss: 0.8392 - val_accuracy: 0.6344\n",
      "Epoch 360/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.4793 - accuracy: 0.8320 - val_loss: 0.8869 - val_accuracy: 0.6022\n",
      "Epoch 361/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.4735 - accuracy: 0.8398 - val_loss: 0.8665 - val_accuracy: 0.6344\n",
      "Epoch 362/700\n",
      "387/387 [==============================] - 0s 608us/step - loss: 0.4441 - accuracy: 0.8682 - val_loss: 0.8463 - val_accuracy: 0.6344\n",
      "Epoch 363/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.4609 - accuracy: 0.8501 - val_loss: 0.8315 - val_accuracy: 0.6452\n",
      "Epoch 364/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.4767 - accuracy: 0.8501 - val_loss: 0.8391 - val_accuracy: 0.6559\n",
      "Epoch 365/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.4630 - accuracy: 0.8398 - val_loss: 0.8531 - val_accuracy: 0.6452\n",
      "Epoch 366/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.4657 - accuracy: 0.8527 - val_loss: 0.8747 - val_accuracy: 0.6452\n",
      "Epoch 367/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.4501 - accuracy: 0.8579 - val_loss: 0.8526 - val_accuracy: 0.6022\n",
      "Epoch 368/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.4477 - accuracy: 0.8475 - val_loss: 0.8608 - val_accuracy: 0.6237\n",
      "Epoch 369/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.4457 - accuracy: 0.8475 - val_loss: 0.8640 - val_accuracy: 0.6344\n",
      "Epoch 370/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.4525 - accuracy: 0.8682 - val_loss: 0.8363 - val_accuracy: 0.6129\n",
      "Epoch 371/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.4469 - accuracy: 0.8475 - val_loss: 0.8642 - val_accuracy: 0.6774\n",
      "Epoch 372/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.4578 - accuracy: 0.8527 - val_loss: 0.8510 - val_accuracy: 0.6452\n",
      "Epoch 373/700\n",
      "387/387 [==============================] - 0s 571us/step - loss: 0.4451 - accuracy: 0.8579 - val_loss: 0.8585 - val_accuracy: 0.6344\n",
      "Epoch 374/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.4534 - accuracy: 0.8527 - val_loss: 0.8965 - val_accuracy: 0.6129\n",
      "Epoch 375/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.4501 - accuracy: 0.8760 - val_loss: 0.8229 - val_accuracy: 0.6237\n",
      "Epoch 376/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.4469 - accuracy: 0.8630 - val_loss: 0.8116 - val_accuracy: 0.6344\n",
      "Epoch 377/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.4520 - accuracy: 0.8630 - val_loss: 0.8681 - val_accuracy: 0.6129\n",
      "Epoch 378/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.4332 - accuracy: 0.8837 - val_loss: 0.8799 - val_accuracy: 0.6237\n",
      "Epoch 379/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.4470 - accuracy: 0.8734 - val_loss: 0.8417 - val_accuracy: 0.6344\n",
      "Epoch 380/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.4334 - accuracy: 0.8682 - val_loss: 0.8264 - val_accuracy: 0.6559\n",
      "Epoch 381/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.4448 - accuracy: 0.8579 - val_loss: 0.8329 - val_accuracy: 0.6344\n",
      "Epoch 382/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.4472 - accuracy: 0.8605 - val_loss: 0.8302 - val_accuracy: 0.6129\n",
      "Epoch 383/700\n",
      "387/387 [==============================] - 0s 579us/step - loss: 0.4303 - accuracy: 0.8682 - val_loss: 0.8471 - val_accuracy: 0.6559\n",
      "Epoch 384/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.4381 - accuracy: 0.8811 - val_loss: 0.8941 - val_accuracy: 0.6667\n",
      "Epoch 385/700\n",
      "387/387 [==============================] - 0s 624us/step - loss: 0.4296 - accuracy: 0.8760 - val_loss: 0.8368 - val_accuracy: 0.6022\n",
      "Epoch 386/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 0.4344 - accuracy: 0.8682 - val_loss: 0.8416 - val_accuracy: 0.6774\n",
      "Epoch 387/700\n",
      "387/387 [==============================] - 0s 579us/step - loss: 0.4474 - accuracy: 0.8527 - val_loss: 0.8347 - val_accuracy: 0.6452\n",
      "Epoch 388/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.4281 - accuracy: 0.8734 - val_loss: 0.8595 - val_accuracy: 0.6237\n",
      "Epoch 389/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 0.4483 - accuracy: 0.8527 - val_loss: 0.9407 - val_accuracy: 0.6237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.4174 - accuracy: 0.8837 - val_loss: 0.8718 - val_accuracy: 0.6882\n",
      "Epoch 391/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.4244 - accuracy: 0.8734 - val_loss: 0.8889 - val_accuracy: 0.5806\n",
      "Epoch 392/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.4244 - accuracy: 0.8682 - val_loss: 0.8807 - val_accuracy: 0.6344\n",
      "Epoch 393/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.4177 - accuracy: 0.8605 - val_loss: 0.8580 - val_accuracy: 0.6237\n",
      "Epoch 394/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.4227 - accuracy: 0.8760 - val_loss: 0.8726 - val_accuracy: 0.6559\n",
      "Epoch 395/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.4289 - accuracy: 0.8630 - val_loss: 0.8349 - val_accuracy: 0.6452\n",
      "Epoch 396/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.4297 - accuracy: 0.8656 - val_loss: 0.8432 - val_accuracy: 0.6774\n",
      "Epoch 397/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.4356 - accuracy: 0.8786 - val_loss: 0.8313 - val_accuracy: 0.6667\n",
      "Epoch 398/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.4273 - accuracy: 0.8760 - val_loss: 0.8652 - val_accuracy: 0.6989\n",
      "Epoch 399/700\n",
      "387/387 [==============================] - 0s 591us/step - loss: 0.4230 - accuracy: 0.8605 - val_loss: 0.9078 - val_accuracy: 0.6022\n",
      "Epoch 400/700\n",
      "387/387 [==============================] - 0s 562us/step - loss: 0.4117 - accuracy: 0.8708 - val_loss: 0.9069 - val_accuracy: 0.6237\n",
      "Epoch 401/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.4305 - accuracy: 0.8708 - val_loss: 0.8457 - val_accuracy: 0.6237\n",
      "Epoch 402/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.4223 - accuracy: 0.8605 - val_loss: 0.8906 - val_accuracy: 0.5914\n",
      "Epoch 403/700\n",
      "387/387 [==============================] - 0s 626us/step - loss: 0.4157 - accuracy: 0.8786 - val_loss: 0.9149 - val_accuracy: 0.5806\n",
      "Epoch 404/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.4227 - accuracy: 0.8708 - val_loss: 0.8714 - val_accuracy: 0.6022\n",
      "Epoch 405/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.4159 - accuracy: 0.8734 - val_loss: 0.8472 - val_accuracy: 0.6452\n",
      "Epoch 406/700\n",
      "387/387 [==============================] - 0s 562us/step - loss: 0.4114 - accuracy: 0.8682 - val_loss: 0.8130 - val_accuracy: 0.6559\n",
      "Epoch 407/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.4130 - accuracy: 0.8605 - val_loss: 0.8509 - val_accuracy: 0.6129\n",
      "Epoch 408/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.4165 - accuracy: 0.8605 - val_loss: 0.8337 - val_accuracy: 0.6344\n",
      "Epoch 409/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.4166 - accuracy: 0.8605 - val_loss: 0.8346 - val_accuracy: 0.6129\n",
      "Epoch 410/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.4064 - accuracy: 0.8863 - val_loss: 0.8314 - val_accuracy: 0.6559\n",
      "Epoch 411/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.4054 - accuracy: 0.8682 - val_loss: 0.8718 - val_accuracy: 0.6452\n",
      "Epoch 412/700\n",
      "387/387 [==============================] - 0s 617us/step - loss: 0.4151 - accuracy: 0.8553 - val_loss: 0.8266 - val_accuracy: 0.6452\n",
      "Epoch 413/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.4118 - accuracy: 0.8760 - val_loss: 0.8113 - val_accuracy: 0.6667\n",
      "Epoch 414/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.4104 - accuracy: 0.8786 - val_loss: 0.9671 - val_accuracy: 0.6022\n",
      "Epoch 415/700\n",
      "387/387 [==============================] - 0s 576us/step - loss: 0.3964 - accuracy: 0.8915 - val_loss: 0.8520 - val_accuracy: 0.6344\n",
      "Epoch 416/700\n",
      "387/387 [==============================] - 0s 619us/step - loss: 0.3996 - accuracy: 0.8837 - val_loss: 0.8139 - val_accuracy: 0.6237\n",
      "Epoch 417/700\n",
      "387/387 [==============================] - 0s 634us/step - loss: 0.4061 - accuracy: 0.8682 - val_loss: 0.8348 - val_accuracy: 0.6774\n",
      "Epoch 418/700\n",
      "387/387 [==============================] - 0s 613us/step - loss: 0.4033 - accuracy: 0.8889 - val_loss: 0.8593 - val_accuracy: 0.6237\n",
      "Epoch 419/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.4069 - accuracy: 0.8630 - val_loss: 0.9020 - val_accuracy: 0.6022\n",
      "Epoch 420/700\n",
      "387/387 [==============================] - 0s 621us/step - loss: 0.3914 - accuracy: 0.8837 - val_loss: 0.8536 - val_accuracy: 0.6774\n",
      "Epoch 421/700\n",
      "387/387 [==============================] - 0s 637us/step - loss: 0.3956 - accuracy: 0.8734 - val_loss: 0.8236 - val_accuracy: 0.6882\n",
      "Epoch 422/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.3987 - accuracy: 0.8837 - val_loss: 0.8570 - val_accuracy: 0.6774\n",
      "Epoch 423/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.4005 - accuracy: 0.8863 - val_loss: 0.8114 - val_accuracy: 0.6452\n",
      "Epoch 424/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.3907 - accuracy: 0.8915 - val_loss: 0.8068 - val_accuracy: 0.6667\n",
      "Epoch 425/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.3918 - accuracy: 0.8837 - val_loss: 0.8330 - val_accuracy: 0.6559\n",
      "Epoch 426/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 0.3984 - accuracy: 0.8915 - val_loss: 0.8901 - val_accuracy: 0.6237\n",
      "Epoch 427/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.3732 - accuracy: 0.8966 - val_loss: 0.8340 - val_accuracy: 0.6344\n",
      "Epoch 428/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.3930 - accuracy: 0.8811 - val_loss: 0.8554 - val_accuracy: 0.6237\n",
      "Epoch 429/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.3878 - accuracy: 0.8760 - val_loss: 0.7923 - val_accuracy: 0.6667\n",
      "Epoch 430/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.3871 - accuracy: 0.8708 - val_loss: 0.8709 - val_accuracy: 0.6022\n",
      "Epoch 431/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.3820 - accuracy: 0.8992 - val_loss: 0.8072 - val_accuracy: 0.6237\n",
      "Epoch 432/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.3892 - accuracy: 0.8811 - val_loss: 0.8540 - val_accuracy: 0.6022\n",
      "Epoch 433/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.3834 - accuracy: 0.8734 - val_loss: 0.8386 - val_accuracy: 0.6774\n",
      "Epoch 434/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.4003 - accuracy: 0.8992 - val_loss: 0.9077 - val_accuracy: 0.6237\n",
      "Epoch 435/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.3769 - accuracy: 0.8837 - val_loss: 0.8438 - val_accuracy: 0.6237\n",
      "Epoch 436/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.3665 - accuracy: 0.8966 - val_loss: 0.7828 - val_accuracy: 0.6237\n",
      "Epoch 437/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.3665 - accuracy: 0.8992 - val_loss: 0.8116 - val_accuracy: 0.6452\n",
      "Epoch 438/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.3849 - accuracy: 0.8786 - val_loss: 0.8351 - val_accuracy: 0.6559\n",
      "Epoch 439/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.3775 - accuracy: 0.8966 - val_loss: 0.9127 - val_accuracy: 0.6022\n",
      "Epoch 440/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.3672 - accuracy: 0.9044 - val_loss: 0.8322 - val_accuracy: 0.6237\n",
      "Epoch 441/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.3658 - accuracy: 0.8915 - val_loss: 0.8166 - val_accuracy: 0.6559\n",
      "Epoch 442/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.3828 - accuracy: 0.8837 - val_loss: 0.8342 - val_accuracy: 0.6344\n",
      "Epoch 443/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.3913 - accuracy: 0.8941 - val_loss: 0.8179 - val_accuracy: 0.6129\n",
      "Epoch 444/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.3899 - accuracy: 0.8811 - val_loss: 0.8314 - val_accuracy: 0.6667\n",
      "Epoch 445/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.3715 - accuracy: 0.9018 - val_loss: 0.8278 - val_accuracy: 0.6559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.3727 - accuracy: 0.8786 - val_loss: 0.7972 - val_accuracy: 0.6882\n",
      "Epoch 447/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.3719 - accuracy: 0.8915 - val_loss: 0.8088 - val_accuracy: 0.6774\n",
      "Epoch 448/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.3623 - accuracy: 0.8941 - val_loss: 0.7930 - val_accuracy: 0.6559\n",
      "Epoch 449/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.3716 - accuracy: 0.8863 - val_loss: 0.7753 - val_accuracy: 0.6559\n",
      "Epoch 450/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.3600 - accuracy: 0.9070 - val_loss: 0.7739 - val_accuracy: 0.6559\n",
      "Epoch 451/700\n",
      "387/387 [==============================] - 0s 562us/step - loss: 0.3773 - accuracy: 0.8760 - val_loss: 0.8092 - val_accuracy: 0.6452\n",
      "Epoch 452/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.3667 - accuracy: 0.8811 - val_loss: 0.7893 - val_accuracy: 0.6667\n",
      "Epoch 453/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.3523 - accuracy: 0.9225 - val_loss: 0.8258 - val_accuracy: 0.6989\n",
      "Epoch 454/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.3750 - accuracy: 0.8786 - val_loss: 0.8089 - val_accuracy: 0.6452\n",
      "Epoch 455/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.3593 - accuracy: 0.8837 - val_loss: 0.7978 - val_accuracy: 0.6452\n",
      "Epoch 456/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.3637 - accuracy: 0.8992 - val_loss: 0.7890 - val_accuracy: 0.6559\n",
      "Epoch 457/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.3616 - accuracy: 0.8915 - val_loss: 0.8220 - val_accuracy: 0.6452\n",
      "Epoch 458/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.3489 - accuracy: 0.8966 - val_loss: 0.8320 - val_accuracy: 0.6237\n",
      "Epoch 459/700\n",
      "387/387 [==============================] - 0s 589us/step - loss: 0.3603 - accuracy: 0.8966 - val_loss: 0.8475 - val_accuracy: 0.6452\n",
      "Epoch 460/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.3622 - accuracy: 0.8786 - val_loss: 0.8192 - val_accuracy: 0.6344\n",
      "Epoch 461/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.3452 - accuracy: 0.8992 - val_loss: 0.8510 - val_accuracy: 0.6559\n",
      "Epoch 462/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.3615 - accuracy: 0.8837 - val_loss: 0.8386 - val_accuracy: 0.6452\n",
      "Epoch 463/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.3594 - accuracy: 0.8941 - val_loss: 0.8592 - val_accuracy: 0.6667\n",
      "Epoch 464/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.3461 - accuracy: 0.9070 - val_loss: 0.8026 - val_accuracy: 0.6344\n",
      "Epoch 465/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.3432 - accuracy: 0.8915 - val_loss: 0.8157 - val_accuracy: 0.6452\n",
      "Epoch 466/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.3527 - accuracy: 0.8992 - val_loss: 0.7998 - val_accuracy: 0.6667\n",
      "Epoch 467/700\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.3581 - accuracy: 0.87 - 0s 619us/step - loss: 0.3606 - accuracy: 0.8734 - val_loss: 0.8603 - val_accuracy: 0.6237\n",
      "Epoch 468/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.3502 - accuracy: 0.8992 - val_loss: 0.8086 - val_accuracy: 0.6774\n",
      "Epoch 469/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.3613 - accuracy: 0.8915 - val_loss: 0.7823 - val_accuracy: 0.6559\n",
      "Epoch 470/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.3451 - accuracy: 0.8992 - val_loss: 0.7665 - val_accuracy: 0.6559\n",
      "Epoch 471/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.3443 - accuracy: 0.9096 - val_loss: 0.8453 - val_accuracy: 0.6344\n",
      "Epoch 472/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.3539 - accuracy: 0.8966 - val_loss: 0.8333 - val_accuracy: 0.6022\n",
      "Epoch 473/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.3396 - accuracy: 0.8992 - val_loss: 0.8574 - val_accuracy: 0.6559\n",
      "Epoch 474/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.3524 - accuracy: 0.8889 - val_loss: 0.8131 - val_accuracy: 0.6667\n",
      "Epoch 475/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.3285 - accuracy: 0.8992 - val_loss: 0.7843 - val_accuracy: 0.6559\n",
      "Epoch 476/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.3480 - accuracy: 0.9070 - val_loss: 0.7768 - val_accuracy: 0.6774\n",
      "Epoch 477/700\n",
      "387/387 [==============================] - 0s 579us/step - loss: 0.3374 - accuracy: 0.8941 - val_loss: 0.8674 - val_accuracy: 0.6237\n",
      "Epoch 478/700\n",
      "387/387 [==============================] - 0s 562us/step - loss: 0.3480 - accuracy: 0.9044 - val_loss: 0.8641 - val_accuracy: 0.6344\n",
      "Epoch 479/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.3484 - accuracy: 0.9018 - val_loss: 0.7860 - val_accuracy: 0.6559\n",
      "Epoch 480/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.3380 - accuracy: 0.9070 - val_loss: 0.8337 - val_accuracy: 0.6559\n",
      "Epoch 481/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.3483 - accuracy: 0.9018 - val_loss: 0.8219 - val_accuracy: 0.6882\n",
      "Epoch 482/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.3336 - accuracy: 0.9044 - val_loss: 0.8868 - val_accuracy: 0.6129\n",
      "Epoch 483/700\n",
      "387/387 [==============================] - 0s 592us/step - loss: 0.3187 - accuracy: 0.9302 - val_loss: 0.8307 - val_accuracy: 0.6774\n",
      "Epoch 484/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.3229 - accuracy: 0.8966 - val_loss: 0.8315 - val_accuracy: 0.6344\n",
      "Epoch 485/700\n",
      "387/387 [==============================] - 0s 635us/step - loss: 0.3246 - accuracy: 0.9199 - val_loss: 0.7733 - val_accuracy: 0.6344\n",
      "Epoch 486/700\n",
      "387/387 [==============================] - 0s 631us/step - loss: 0.3535 - accuracy: 0.8786 - val_loss: 0.8060 - val_accuracy: 0.6559\n",
      "Epoch 487/700\n",
      "387/387 [==============================] - 0s 621us/step - loss: 0.3239 - accuracy: 0.9096 - val_loss: 0.8132 - val_accuracy: 0.6989\n",
      "Epoch 488/700\n",
      "387/387 [==============================] - 0s 624us/step - loss: 0.3271 - accuracy: 0.9147 - val_loss: 0.7969 - val_accuracy: 0.6344\n",
      "Epoch 489/700\n",
      "387/387 [==============================] - 0s 637us/step - loss: 0.3257 - accuracy: 0.8941 - val_loss: 0.8154 - val_accuracy: 0.6667\n",
      "Epoch 490/700\n",
      "387/387 [==============================] - 0s 619us/step - loss: 0.3422 - accuracy: 0.9070 - val_loss: 0.8274 - val_accuracy: 0.6237\n",
      "Epoch 491/700\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.90 - 0s 611us/step - loss: 0.3244 - accuracy: 0.9096 - val_loss: 0.8211 - val_accuracy: 0.6667\n",
      "Epoch 492/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.3099 - accuracy: 0.9251 - val_loss: 0.7971 - val_accuracy: 0.6774\n",
      "Epoch 493/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.3236 - accuracy: 0.9096 - val_loss: 0.8090 - val_accuracy: 0.6452\n",
      "Epoch 494/700\n",
      "387/387 [==============================] - 0s 611us/step - loss: 0.3226 - accuracy: 0.9225 - val_loss: 0.8769 - val_accuracy: 0.6452\n",
      "Epoch 495/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.3266 - accuracy: 0.9070 - val_loss: 0.7964 - val_accuracy: 0.6667\n",
      "Epoch 496/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.3316 - accuracy: 0.9070 - val_loss: 0.7951 - val_accuracy: 0.6882\n",
      "Epoch 497/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.3304 - accuracy: 0.8941 - val_loss: 0.8308 - val_accuracy: 0.6344\n",
      "Epoch 498/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.3180 - accuracy: 0.9199 - val_loss: 0.8290 - val_accuracy: 0.6452\n",
      "Epoch 499/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.3272 - accuracy: 0.8941 - val_loss: 0.8219 - val_accuracy: 0.6882\n",
      "Epoch 500/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.3305 - accuracy: 0.8915 - val_loss: 0.7965 - val_accuracy: 0.6989\n",
      "Epoch 501/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 0s 593us/step - loss: 0.3256 - accuracy: 0.9044 - val_loss: 0.8232 - val_accuracy: 0.6667\n",
      "Epoch 502/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.3269 - accuracy: 0.9147 - val_loss: 0.8219 - val_accuracy: 0.6774\n",
      "Epoch 503/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.3200 - accuracy: 0.9147 - val_loss: 0.8788 - val_accuracy: 0.6237\n",
      "Epoch 504/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.3067 - accuracy: 0.9328 - val_loss: 0.8396 - val_accuracy: 0.6667\n",
      "Epoch 505/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.3263 - accuracy: 0.9173 - val_loss: 0.8211 - val_accuracy: 0.6344\n",
      "Epoch 506/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.3074 - accuracy: 0.9147 - val_loss: 0.8047 - val_accuracy: 0.6774\n",
      "Epoch 507/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 0.3326 - accuracy: 0.8941 - val_loss: 0.8047 - val_accuracy: 0.6452\n",
      "Epoch 508/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.3092 - accuracy: 0.9096 - val_loss: 0.7994 - val_accuracy: 0.6344\n",
      "Epoch 509/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.3152 - accuracy: 0.9225 - val_loss: 0.7736 - val_accuracy: 0.7097\n",
      "Epoch 510/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.3156 - accuracy: 0.9225 - val_loss: 0.7859 - val_accuracy: 0.6667\n",
      "Epoch 511/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.2957 - accuracy: 0.9354 - val_loss: 0.8133 - val_accuracy: 0.6559\n",
      "Epoch 512/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.3118 - accuracy: 0.9199 - val_loss: 0.8123 - val_accuracy: 0.6774\n",
      "Epoch 513/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.3043 - accuracy: 0.9199 - val_loss: 0.7964 - val_accuracy: 0.6452\n",
      "Epoch 514/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.3183 - accuracy: 0.9121 - val_loss: 0.7987 - val_accuracy: 0.6667\n",
      "Epoch 515/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.2987 - accuracy: 0.9121 - val_loss: 0.7907 - val_accuracy: 0.6667\n",
      "Epoch 516/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.3151 - accuracy: 0.9070 - val_loss: 0.8170 - val_accuracy: 0.6559\n",
      "Epoch 517/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.2986 - accuracy: 0.9173 - val_loss: 0.8092 - val_accuracy: 0.6559\n",
      "Epoch 518/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.3045 - accuracy: 0.9328 - val_loss: 0.7978 - val_accuracy: 0.7097\n",
      "Epoch 519/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.3101 - accuracy: 0.9225 - val_loss: 0.7702 - val_accuracy: 0.6559\n",
      "Epoch 520/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.3015 - accuracy: 0.9199 - val_loss: 0.8042 - val_accuracy: 0.6667\n",
      "Epoch 521/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.3059 - accuracy: 0.9225 - val_loss: 0.8132 - val_accuracy: 0.6559\n",
      "Epoch 522/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.2995 - accuracy: 0.9225 - val_loss: 0.7906 - val_accuracy: 0.6559\n",
      "Epoch 523/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.3134 - accuracy: 0.9147 - val_loss: 0.8022 - val_accuracy: 0.6882\n",
      "Epoch 524/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.2889 - accuracy: 0.9354 - val_loss: 0.7841 - val_accuracy: 0.6344\n",
      "Epoch 525/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2823 - accuracy: 0.9406 - val_loss: 0.8263 - val_accuracy: 0.6344\n",
      "Epoch 526/700\n",
      "387/387 [==============================] - 0s 599us/step - loss: 0.2901 - accuracy: 0.9328 - val_loss: 0.8131 - val_accuracy: 0.6667\n",
      "Epoch 527/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2919 - accuracy: 0.9199 - val_loss: 0.7576 - val_accuracy: 0.6452\n",
      "Epoch 528/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.2967 - accuracy: 0.9251 - val_loss: 0.7898 - val_accuracy: 0.6667\n",
      "Epoch 529/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.3098 - accuracy: 0.9096 - val_loss: 0.8137 - val_accuracy: 0.6774\n",
      "Epoch 530/700\n",
      "387/387 [==============================] - 0s 607us/step - loss: 0.2855 - accuracy: 0.9225 - val_loss: 0.7820 - val_accuracy: 0.6667\n",
      "Epoch 531/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.2876 - accuracy: 0.9251 - val_loss: 0.7690 - val_accuracy: 0.6774\n",
      "Epoch 532/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.3132 - accuracy: 0.9044 - val_loss: 0.8892 - val_accuracy: 0.6237\n",
      "Epoch 533/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2930 - accuracy: 0.9302 - val_loss: 0.7793 - val_accuracy: 0.6559\n",
      "Epoch 534/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 0.2917 - accuracy: 0.9380 - val_loss: 0.7972 - val_accuracy: 0.6667\n",
      "Epoch 535/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.2899 - accuracy: 0.9251 - val_loss: 0.8243 - val_accuracy: 0.6452\n",
      "Epoch 536/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2878 - accuracy: 0.9302 - val_loss: 0.8145 - val_accuracy: 0.6882\n",
      "Epoch 537/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.3034 - accuracy: 0.9121 - val_loss: 0.7755 - val_accuracy: 0.6882\n",
      "Epoch 538/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2846 - accuracy: 0.9354 - val_loss: 0.8090 - val_accuracy: 0.6667\n",
      "Epoch 539/700\n",
      "387/387 [==============================] - 0s 624us/step - loss: 0.2855 - accuracy: 0.9276 - val_loss: 0.8274 - val_accuracy: 0.6559\n",
      "Epoch 540/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.2874 - accuracy: 0.9276 - val_loss: 0.7861 - val_accuracy: 0.6559\n",
      "Epoch 541/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2856 - accuracy: 0.9354 - val_loss: 0.8105 - val_accuracy: 0.6559\n",
      "Epoch 542/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.2709 - accuracy: 0.9380 - val_loss: 0.8003 - val_accuracy: 0.6559\n",
      "Epoch 543/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.2788 - accuracy: 0.9276 - val_loss: 0.8008 - val_accuracy: 0.6559\n",
      "Epoch 544/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.2914 - accuracy: 0.9199 - val_loss: 0.7612 - val_accuracy: 0.6667\n",
      "Epoch 545/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.2758 - accuracy: 0.9354 - val_loss: 0.8094 - val_accuracy: 0.7097\n",
      "Epoch 546/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.2790 - accuracy: 0.9354 - val_loss: 0.8513 - val_accuracy: 0.6022\n",
      "Epoch 547/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.2809 - accuracy: 0.9225 - val_loss: 0.8612 - val_accuracy: 0.6667\n",
      "Epoch 548/700\n",
      "387/387 [==============================] - 0s 601us/step - loss: 0.2720 - accuracy: 0.9380 - val_loss: 0.7935 - val_accuracy: 0.6452\n",
      "Epoch 549/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.2784 - accuracy: 0.9225 - val_loss: 0.8738 - val_accuracy: 0.6452\n",
      "Epoch 550/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.2721 - accuracy: 0.9457 - val_loss: 0.8085 - val_accuracy: 0.6559\n",
      "Epoch 551/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.2836 - accuracy: 0.9276 - val_loss: 0.7732 - val_accuracy: 0.6452\n",
      "Epoch 552/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.2737 - accuracy: 0.9276 - val_loss: 0.7999 - val_accuracy: 0.6667\n",
      "Epoch 553/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.2742 - accuracy: 0.9225 - val_loss: 0.8239 - val_accuracy: 0.6559\n",
      "Epoch 554/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.2796 - accuracy: 0.9096 - val_loss: 0.7965 - val_accuracy: 0.6667\n",
      "Epoch 555/700\n",
      "387/387 [==============================] - 0s 615us/step - loss: 0.2765 - accuracy: 0.9354 - val_loss: 0.8196 - val_accuracy: 0.6344\n",
      "Epoch 556/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.2752 - accuracy: 0.9380 - val_loss: 0.7897 - val_accuracy: 0.6237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557/700\n",
      "387/387 [==============================] - 0s 665us/step - loss: 0.2804 - accuracy: 0.9406 - val_loss: 0.7775 - val_accuracy: 0.6452\n",
      "Epoch 558/700\n",
      "387/387 [==============================] - 0s 624us/step - loss: 0.2765 - accuracy: 0.9044 - val_loss: 0.8115 - val_accuracy: 0.6774\n",
      "Epoch 559/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.2769 - accuracy: 0.9225 - val_loss: 0.7944 - val_accuracy: 0.6559\n",
      "Epoch 560/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.2778 - accuracy: 0.9199 - val_loss: 0.8533 - val_accuracy: 0.6344\n",
      "Epoch 561/700\n",
      "387/387 [==============================] - 0s 594us/step - loss: 0.2725 - accuracy: 0.9380 - val_loss: 0.7878 - val_accuracy: 0.6559\n",
      "Epoch 562/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.2658 - accuracy: 0.9354 - val_loss: 0.7637 - val_accuracy: 0.6774\n",
      "Epoch 563/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2616 - accuracy: 0.9406 - val_loss: 0.7753 - val_accuracy: 0.6559\n",
      "Epoch 564/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2693 - accuracy: 0.9380 - val_loss: 0.8037 - val_accuracy: 0.6559\n",
      "Epoch 565/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.2645 - accuracy: 0.9251 - val_loss: 0.8372 - val_accuracy: 0.6559\n",
      "Epoch 566/700\n",
      "387/387 [==============================] - 0s 621us/step - loss: 0.2742 - accuracy: 0.9251 - val_loss: 0.8038 - val_accuracy: 0.6882\n",
      "Epoch 567/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.2642 - accuracy: 0.9302 - val_loss: 0.7692 - val_accuracy: 0.6882\n",
      "Epoch 568/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.2610 - accuracy: 0.9302 - val_loss: 0.7922 - val_accuracy: 0.6774\n",
      "Epoch 569/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2688 - accuracy: 0.9225 - val_loss: 0.7746 - val_accuracy: 0.7097\n",
      "Epoch 570/700\n",
      "387/387 [==============================] - 0s 573us/step - loss: 0.2823 - accuracy: 0.9251 - val_loss: 0.7810 - val_accuracy: 0.6989\n",
      "Epoch 571/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.2820 - accuracy: 0.9432 - val_loss: 0.7833 - val_accuracy: 0.6774\n",
      "Epoch 572/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.2612 - accuracy: 0.9328 - val_loss: 0.7633 - val_accuracy: 0.6559\n",
      "Epoch 573/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2502 - accuracy: 0.9406 - val_loss: 0.7850 - val_accuracy: 0.6559\n",
      "Epoch 574/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2432 - accuracy: 0.9457 - val_loss: 0.7608 - val_accuracy: 0.6882\n",
      "Epoch 575/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.2465 - accuracy: 0.9406 - val_loss: 0.8672 - val_accuracy: 0.6344\n",
      "Epoch 576/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.2659 - accuracy: 0.9251 - val_loss: 0.7560 - val_accuracy: 0.6667\n",
      "Epoch 577/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.2597 - accuracy: 0.9406 - val_loss: 0.7516 - val_accuracy: 0.6559\n",
      "Epoch 578/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.2584 - accuracy: 0.9276 - val_loss: 0.8829 - val_accuracy: 0.6559\n",
      "Epoch 579/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.2517 - accuracy: 0.9457 - val_loss: 0.8077 - val_accuracy: 0.6559\n",
      "Epoch 580/700\n",
      "387/387 [==============================] - 0s 608us/step - loss: 0.2502 - accuracy: 0.9302 - val_loss: 0.9257 - val_accuracy: 0.6452\n",
      "Epoch 581/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.2641 - accuracy: 0.9225 - val_loss: 0.8732 - val_accuracy: 0.6129\n",
      "Epoch 582/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2477 - accuracy: 0.9406 - val_loss: 0.8032 - val_accuracy: 0.6774\n",
      "Epoch 583/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.2659 - accuracy: 0.9380 - val_loss: 0.8048 - val_accuracy: 0.6989\n",
      "Epoch 584/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2528 - accuracy: 0.9432 - val_loss: 0.7720 - val_accuracy: 0.6882\n",
      "Epoch 585/700\n",
      "387/387 [==============================] - 0s 606us/step - loss: 0.2422 - accuracy: 0.9354 - val_loss: 0.7991 - val_accuracy: 0.6882\n",
      "Epoch 586/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2519 - accuracy: 0.9406 - val_loss: 0.8022 - val_accuracy: 0.6452\n",
      "Epoch 587/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.2490 - accuracy: 0.9302 - val_loss: 0.8507 - val_accuracy: 0.7312\n",
      "Epoch 588/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.2497 - accuracy: 0.9276 - val_loss: 0.7919 - val_accuracy: 0.6452\n",
      "Epoch 589/700\n",
      "387/387 [==============================] - 0s 613us/step - loss: 0.2240 - accuracy: 0.9561 - val_loss: 0.7689 - val_accuracy: 0.6882\n",
      "Epoch 590/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2418 - accuracy: 0.9328 - val_loss: 0.8179 - val_accuracy: 0.6452\n",
      "Epoch 591/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.2365 - accuracy: 0.9483 - val_loss: 0.8130 - val_accuracy: 0.6774\n",
      "Epoch 592/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.2324 - accuracy: 0.9509 - val_loss: 0.7758 - val_accuracy: 0.6559\n",
      "Epoch 593/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.2371 - accuracy: 0.9457 - val_loss: 0.8166 - val_accuracy: 0.6667\n",
      "Epoch 594/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.2421 - accuracy: 0.9509 - val_loss: 0.7512 - val_accuracy: 0.6882\n",
      "Epoch 595/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.2384 - accuracy: 0.9483 - val_loss: 0.8586 - val_accuracy: 0.7419\n",
      "Epoch 596/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.2515 - accuracy: 0.9354 - val_loss: 0.7891 - val_accuracy: 0.6989\n",
      "Epoch 597/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2460 - accuracy: 0.9432 - val_loss: 0.8394 - val_accuracy: 0.6667\n",
      "Epoch 598/700\n",
      "387/387 [==============================] - 0s 624us/step - loss: 0.2292 - accuracy: 0.9561 - val_loss: 0.8525 - val_accuracy: 0.6667\n",
      "Epoch 599/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2346 - accuracy: 0.9406 - val_loss: 0.8421 - val_accuracy: 0.6452\n",
      "Epoch 600/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.2549 - accuracy: 0.9328 - val_loss: 0.7870 - val_accuracy: 0.6774\n",
      "Epoch 601/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2385 - accuracy: 0.9225 - val_loss: 0.9942 - val_accuracy: 0.6022\n",
      "Epoch 602/700\n",
      "387/387 [==============================] - 0s 607us/step - loss: 0.2437 - accuracy: 0.9406 - val_loss: 0.8272 - val_accuracy: 0.6559\n",
      "Epoch 603/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.2409 - accuracy: 0.9328 - val_loss: 0.8047 - val_accuracy: 0.6882\n",
      "Epoch 604/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.2383 - accuracy: 0.9509 - val_loss: 0.7771 - val_accuracy: 0.6452\n",
      "Epoch 605/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2347 - accuracy: 0.9483 - val_loss: 0.7914 - val_accuracy: 0.7419\n",
      "Epoch 606/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.2314 - accuracy: 0.9483 - val_loss: 0.7869 - val_accuracy: 0.6774\n",
      "Epoch 607/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.2376 - accuracy: 0.9432 - val_loss: 0.7869 - val_accuracy: 0.6667\n",
      "Epoch 608/700\n",
      "387/387 [==============================] - 0s 603us/step - loss: 0.2231 - accuracy: 0.9587 - val_loss: 0.7773 - val_accuracy: 0.6989\n",
      "Epoch 609/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.2371 - accuracy: 0.9457 - val_loss: 0.8240 - val_accuracy: 0.6667\n",
      "Epoch 610/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.2215 - accuracy: 0.9509 - val_loss: 0.8282 - val_accuracy: 0.6452\n",
      "Epoch 611/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.2508 - accuracy: 0.9354 - val_loss: 0.8626 - val_accuracy: 0.6344\n",
      "Epoch 612/700\n",
      "387/387 [==============================] - 0s 613us/step - loss: 0.2235 - accuracy: 0.9509 - val_loss: 0.7991 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2185 - accuracy: 0.9638 - val_loss: 0.7825 - val_accuracy: 0.6559\n",
      "Epoch 614/700\n",
      "387/387 [==============================] - 0s 579us/step - loss: 0.2213 - accuracy: 0.9716 - val_loss: 0.8070 - val_accuracy: 0.6667\n",
      "Epoch 615/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.2213 - accuracy: 0.9432 - val_loss: 0.8709 - val_accuracy: 0.6667\n",
      "Epoch 616/700\n",
      "387/387 [==============================] - 0s 608us/step - loss: 0.2367 - accuracy: 0.9251 - val_loss: 0.8689 - val_accuracy: 0.6344\n",
      "Epoch 617/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.2335 - accuracy: 0.9457 - val_loss: 0.8150 - val_accuracy: 0.7097\n",
      "Epoch 618/700\n",
      "387/387 [==============================] - 0s 563us/step - loss: 0.2213 - accuracy: 0.9587 - val_loss: 0.7814 - val_accuracy: 0.6882\n",
      "Epoch 619/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2143 - accuracy: 0.9535 - val_loss: 0.7783 - val_accuracy: 0.6774\n",
      "Epoch 620/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.2298 - accuracy: 0.9457 - val_loss: 0.8189 - val_accuracy: 0.7204\n",
      "Epoch 621/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.2188 - accuracy: 0.9509 - val_loss: 0.8110 - val_accuracy: 0.6882\n",
      "Epoch 622/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2394 - accuracy: 0.9406 - val_loss: 0.7782 - val_accuracy: 0.6882\n",
      "Epoch 623/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.2278 - accuracy: 0.9354 - val_loss: 0.8155 - val_accuracy: 0.6989\n",
      "Epoch 624/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.2412 - accuracy: 0.9354 - val_loss: 0.7955 - val_accuracy: 0.6989\n",
      "Epoch 625/700\n",
      "387/387 [==============================] - 0s 622us/step - loss: 0.2186 - accuracy: 0.9509 - val_loss: 0.8142 - val_accuracy: 0.6882\n",
      "Epoch 626/700\n",
      "387/387 [==============================] - 0s 647us/step - loss: 0.2334 - accuracy: 0.9406 - val_loss: 0.7498 - val_accuracy: 0.6882\n",
      "Epoch 627/700\n",
      "387/387 [==============================] - 0s 644us/step - loss: 0.2152 - accuracy: 0.9638 - val_loss: 0.7689 - val_accuracy: 0.6774\n",
      "Epoch 628/700\n",
      "387/387 [==============================] - 0s 624us/step - loss: 0.2144 - accuracy: 0.9509 - val_loss: 0.8922 - val_accuracy: 0.6559\n",
      "Epoch 629/700\n",
      "387/387 [==============================] - 0s 621us/step - loss: 0.2153 - accuracy: 0.9612 - val_loss: 0.7669 - val_accuracy: 0.6989\n",
      "Epoch 630/700\n",
      "387/387 [==============================] - 0s 639us/step - loss: 0.2366 - accuracy: 0.9509 - val_loss: 0.7936 - val_accuracy: 0.7204\n",
      "Epoch 631/700\n",
      "387/387 [==============================] - 0s 581us/step - loss: 0.2175 - accuracy: 0.9535 - val_loss: 0.8426 - val_accuracy: 0.7312\n",
      "Epoch 632/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2132 - accuracy: 0.9483 - val_loss: 0.7722 - val_accuracy: 0.6559\n",
      "Epoch 633/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.2253 - accuracy: 0.9509 - val_loss: 0.8394 - val_accuracy: 0.6344\n",
      "Epoch 634/700\n",
      "387/387 [==============================] - 0s 608us/step - loss: 0.2139 - accuracy: 0.9457 - val_loss: 0.8069 - val_accuracy: 0.6452\n",
      "Epoch 635/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.2105 - accuracy: 0.9587 - val_loss: 0.8076 - val_accuracy: 0.6667\n",
      "Epoch 636/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.2082 - accuracy: 0.9535 - val_loss: 0.8106 - val_accuracy: 0.6452\n",
      "Epoch 637/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.2099 - accuracy: 0.9561 - val_loss: 0.7747 - val_accuracy: 0.6882\n",
      "Epoch 638/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.2050 - accuracy: 0.9535 - val_loss: 0.8189 - val_accuracy: 0.6559\n",
      "Epoch 639/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.2152 - accuracy: 0.9535 - val_loss: 0.8066 - val_accuracy: 0.6774\n",
      "Epoch 640/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.2068 - accuracy: 0.9457 - val_loss: 0.7688 - val_accuracy: 0.6559\n",
      "Epoch 641/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.2127 - accuracy: 0.9612 - val_loss: 0.7913 - val_accuracy: 0.6452\n",
      "Epoch 642/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.2117 - accuracy: 0.9380 - val_loss: 0.8853 - val_accuracy: 0.6344\n",
      "Epoch 643/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.2160 - accuracy: 0.9561 - val_loss: 0.8269 - val_accuracy: 0.7312\n",
      "Epoch 644/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.2212 - accuracy: 0.9406 - val_loss: 0.7827 - val_accuracy: 0.7097\n",
      "Epoch 645/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2069 - accuracy: 0.9612 - val_loss: 0.8479 - val_accuracy: 0.6774\n",
      "Epoch 646/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.1978 - accuracy: 0.9561 - val_loss: 0.7954 - val_accuracy: 0.6667\n",
      "Epoch 647/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.2083 - accuracy: 0.9483 - val_loss: 0.7714 - val_accuracy: 0.6774\n",
      "Epoch 648/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.2082 - accuracy: 0.9483 - val_loss: 0.7977 - val_accuracy: 0.7312\n",
      "Epoch 649/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.2004 - accuracy: 0.9638 - val_loss: 0.7829 - val_accuracy: 0.6989\n",
      "Epoch 650/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2022 - accuracy: 0.9638 - val_loss: 0.8111 - val_accuracy: 0.6882\n",
      "Epoch 651/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.1996 - accuracy: 0.9509 - val_loss: 0.8018 - val_accuracy: 0.6559\n",
      "Epoch 652/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.2082 - accuracy: 0.9612 - val_loss: 0.9187 - val_accuracy: 0.6237\n",
      "Epoch 653/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.2037 - accuracy: 0.9612 - val_loss: 0.7871 - val_accuracy: 0.7204\n",
      "Epoch 654/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.2044 - accuracy: 0.9483 - val_loss: 0.8178 - val_accuracy: 0.6667\n",
      "Epoch 655/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.2016 - accuracy: 0.9587 - val_loss: 0.7950 - val_accuracy: 0.7097\n",
      "Epoch 656/700\n",
      "387/387 [==============================] - 0s 575us/step - loss: 0.1985 - accuracy: 0.9561 - val_loss: 0.8707 - val_accuracy: 0.6344\n",
      "Epoch 657/700\n",
      "387/387 [==============================] - 0s 607us/step - loss: 0.1964 - accuracy: 0.9587 - val_loss: 0.8319 - val_accuracy: 0.6774\n",
      "Epoch 658/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.2048 - accuracy: 0.9690 - val_loss: 0.8134 - val_accuracy: 0.6667\n",
      "Epoch 659/700\n",
      "387/387 [==============================] - 0s 600us/step - loss: 0.2074 - accuracy: 0.9457 - val_loss: 0.7956 - val_accuracy: 0.6667\n",
      "Epoch 660/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.2086 - accuracy: 0.9587 - val_loss: 0.8004 - val_accuracy: 0.7204\n",
      "Epoch 661/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.2124 - accuracy: 0.9535 - val_loss: 0.7974 - val_accuracy: 0.6989\n",
      "Epoch 662/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.1982 - accuracy: 0.9638 - val_loss: 0.7843 - val_accuracy: 0.7204\n",
      "Epoch 663/700\n",
      "387/387 [==============================] - 0s 567us/step - loss: 0.1938 - accuracy: 0.9535 - val_loss: 0.8100 - val_accuracy: 0.7204\n",
      "Epoch 664/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.1883 - accuracy: 0.9742 - val_loss: 0.7936 - val_accuracy: 0.6774\n",
      "Epoch 665/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.1837 - accuracy: 0.9638 - val_loss: 0.8503 - val_accuracy: 0.6667\n",
      "Epoch 666/700\n",
      "387/387 [==============================] - 0s 595us/step - loss: 0.1897 - accuracy: 0.9509 - val_loss: 0.8430 - val_accuracy: 0.6667\n",
      "Epoch 667/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.1924 - accuracy: 0.9587 - val_loss: 0.8239 - val_accuracy: 0.6989\n",
      "Epoch 668/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.2057 - accuracy: 0.9535 - val_loss: 0.8104 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.1998 - accuracy: 0.9535 - val_loss: 0.7948 - val_accuracy: 0.6989\n",
      "Epoch 670/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.1914 - accuracy: 0.9716 - val_loss: 0.8041 - val_accuracy: 0.6882\n",
      "Epoch 671/700\n",
      "387/387 [==============================] - 0s 598us/step - loss: 0.1962 - accuracy: 0.9587 - val_loss: 0.7702 - val_accuracy: 0.6882\n",
      "Epoch 672/700\n",
      "387/387 [==============================] - 0s 570us/step - loss: 0.1976 - accuracy: 0.9457 - val_loss: 0.7790 - val_accuracy: 0.7097\n",
      "Epoch 673/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.1802 - accuracy: 0.9742 - val_loss: 0.8349 - val_accuracy: 0.6989\n",
      "Epoch 674/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.1815 - accuracy: 0.9664 - val_loss: 0.8008 - val_accuracy: 0.7097\n",
      "Epoch 675/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.1805 - accuracy: 0.9638 - val_loss: 0.7894 - val_accuracy: 0.6774\n",
      "Epoch 676/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.1912 - accuracy: 0.9612 - val_loss: 0.7741 - val_accuracy: 0.7204\n",
      "Epoch 677/700\n",
      "387/387 [==============================] - 0s 580us/step - loss: 0.1924 - accuracy: 0.9587 - val_loss: 0.7985 - val_accuracy: 0.6774\n",
      "Epoch 678/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.1921 - accuracy: 0.9587 - val_loss: 0.8597 - val_accuracy: 0.6774\n",
      "Epoch 679/700\n",
      "387/387 [==============================] - 0s 579us/step - loss: 0.1879 - accuracy: 0.9612 - val_loss: 0.8469 - val_accuracy: 0.6559\n",
      "Epoch 680/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.1855 - accuracy: 0.9509 - val_loss: 0.8653 - val_accuracy: 0.6344\n",
      "Epoch 681/700\n",
      "387/387 [==============================] - 0s 562us/step - loss: 0.1764 - accuracy: 0.9716 - val_loss: 0.8215 - val_accuracy: 0.6882\n",
      "Epoch 682/700\n",
      "387/387 [==============================] - 0s 588us/step - loss: 0.1913 - accuracy: 0.9638 - val_loss: 0.7668 - val_accuracy: 0.6774\n",
      "Epoch 683/700\n",
      "387/387 [==============================] - 0s 562us/step - loss: 0.1932 - accuracy: 0.9432 - val_loss: 0.8298 - val_accuracy: 0.6667\n",
      "Epoch 684/700\n",
      "387/387 [==============================] - 0s 593us/step - loss: 0.1759 - accuracy: 0.9664 - val_loss: 0.7559 - val_accuracy: 0.6882\n",
      "Epoch 685/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.1840 - accuracy: 0.9561 - val_loss: 0.7914 - val_accuracy: 0.6989\n",
      "Epoch 686/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.1802 - accuracy: 0.9612 - val_loss: 0.7787 - val_accuracy: 0.7097\n",
      "Epoch 687/700\n",
      "387/387 [==============================] - 0s 585us/step - loss: 0.1837 - accuracy: 0.9638 - val_loss: 0.7683 - val_accuracy: 0.7204\n",
      "Epoch 688/700\n",
      "387/387 [==============================] - 0s 577us/step - loss: 0.1824 - accuracy: 0.9638 - val_loss: 0.8161 - val_accuracy: 0.6989\n",
      "Epoch 689/700\n",
      "387/387 [==============================] - 0s 611us/step - loss: 0.1787 - accuracy: 0.9638 - val_loss: 0.8058 - val_accuracy: 0.6667\n",
      "Epoch 690/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.1773 - accuracy: 0.9587 - val_loss: 0.8228 - val_accuracy: 0.6882\n",
      "Epoch 691/700\n",
      "387/387 [==============================] - 0s 564us/step - loss: 0.1755 - accuracy: 0.9638 - val_loss: 0.9062 - val_accuracy: 0.6452\n",
      "Epoch 692/700\n",
      "387/387 [==============================] - 0s 582us/step - loss: 0.1798 - accuracy: 0.9690 - val_loss: 0.7786 - val_accuracy: 0.6882\n",
      "Epoch 693/700\n",
      "387/387 [==============================] - 0s 572us/step - loss: 0.1771 - accuracy: 0.9819 - val_loss: 0.7764 - val_accuracy: 0.7097\n",
      "Epoch 694/700\n",
      "387/387 [==============================] - 0s 590us/step - loss: 0.1715 - accuracy: 0.9716 - val_loss: 0.7798 - val_accuracy: 0.6667\n",
      "Epoch 695/700\n",
      "387/387 [==============================] - 0s 609us/step - loss: 0.1781 - accuracy: 0.9664 - val_loss: 0.8165 - val_accuracy: 0.6559\n",
      "Epoch 696/700\n",
      "387/387 [==============================] - 0s 616us/step - loss: 0.1732 - accuracy: 0.9638 - val_loss: 0.8272 - val_accuracy: 0.6774\n",
      "Epoch 697/700\n",
      "387/387 [==============================] - 0s 624us/step - loss: 0.1735 - accuracy: 0.9664 - val_loss: 0.9273 - val_accuracy: 0.6344\n",
      "Epoch 698/700\n",
      "387/387 [==============================] - 0s 637us/step - loss: 0.1781 - accuracy: 0.9690 - val_loss: 0.8097 - val_accuracy: 0.6882\n",
      "Epoch 699/700\n",
      "387/387 [==============================] - 0s 642us/step - loss: 0.1816 - accuracy: 0.9535 - val_loss: 0.8407 - val_accuracy: 0.6667\n",
      "Epoch 700/700\n",
      "387/387 [==============================] - 0s 619us/step - loss: 0.1734 - accuracy: 0.9664 - val_loss: 0.8112 - val_accuracy: 0.6989\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd5hU5dn48e89s7O9sgUWlmqhioAIIhZEBcEaNWosMSaKJvqLJmqUqDHmTTFv8qoxMRqNRI2KDXtFECyodFSqgCywlG2wvc88vz+es2yHXWB2Zs/en+vimplzzpxzzzB7n+c87YgxBqWUUu7jCXUASimlgkMTvFJKuZQmeKWUcilN8Eop5VKa4JVSyqU0wSullEtpglcKEJGnROT37dw2W0TOONT9KBVsmuCVUsqlNMErpZRLaYJXXYZTNXK7iHwtIuUi8qSI9BSR90SkVETmiUhKo+3PE5E1IlIkIgtFZGijdaNFZIXzvheB6GbHOkdEVjnv/VxERh5kzNeJyCYR2SMib4pIb2e5iMiDIpInIsXOZxrhrJsuImud2HaIyG0H9YWpbk8TvOpqLgLOBI4GzgXeA34NpGF/zz8HEJGjgdnALUA68C7wlohEikgk8DrwX6AH8LKzX5z3jgFmAdcDqcC/gDdFJKojgYrIZOBPwCVAJrAVeMFZPQU4xfkcycClQKGz7kngemNMAjAC+Kgjx1WqniZ41dX83RiTa4zZAXwKLDbGrDTGVAOvAaOd7S4F3jHGfGiMqQX+CsQAJwInAD7gIWNMrTHmFWBpo2NcB/zLGLPYGOM3xjwNVDvv64grgFnGmBVOfDOBCSIyAKgFEoAhgBhj1hljdjnvqwWGiUiiMWavMWZFB4+rFKAJXnU9uY2eV7byOt553htbYgbAGBMAtgN9nHU7TNOZ9rY2et4fuNWpnikSkSKgr/O+jmgeQxm2lN7HGPMR8A/gESBXRB4XkURn04uA6cBWEflYRCZ08LhKAZrglXvtxCZqwNZ5Y5P0DmAX0MdZVq9fo+fbgT8YY5Ib/Ys1xsw+xBjisFU+OwCMMQ8bY44DhmOram53li81xpwPZGCrkl7q4HGVAjTBK/d6CThbRE4XER9wK7aa5XPgC6AO+LmIRIjIhcC4Ru99ArhBRMY7jaFxInK2iCR0MIbngWtEZJRTf/9HbJVStogc7+zfB5QDVYDfaSO4QkSSnKqlEsB/CN+D6sY0wStXMsZsAK4E/g4UYBtkzzXG1BhjaoALgR8Be7H19a82eu8ybD38P5z1m5xtOxrDfOAeYA72quEI4DJndSL2RLIXW41TiG0nALgKyBaREuAG53Mo1WGiN/xQSil30hK8Ukq5lCZ4pZRyKU3wSinlUprglVLKpSJCHUBjaWlpZsCAAaEOQymluozly5cXGGPSW1sXVgl+wIABLFu2LNRhKKVUlyEiW9tap1U0SinlUprglVLKpTTBK6WUS4VVHXxramtrycnJoaqqKtShBFV0dDRZWVn4fL5Qh6KUcomwT/A5OTkkJCQwYMAAmk7+5x7GGAoLC8nJyWHgwIGhDkcp5RJhX0VTVVVFamqqa5M7gIiQmprq+qsUpVTnCvsED7g6udfrDp9RKdW5ukSCP5DckipKq2pDHYZSSoUVVyT4/NJqyqrrgrLvoqIi/vnPf3b4fdOnT6eoqCgIESmlVPu4IsEDEKRp7dtK8H7//m+y8+6775KcnBycoJRSqh3CvhdNewXrtiV33nknmzdvZtSoUfh8PuLj48nMzGTVqlWsXbuWCy64gO3bt1NVVcXNN9/MjBkzgIZpF8rKypg2bRonnXQSn3/+OX369OGNN94gJiYmSBErpZTVpRL8fW+tYe3OkhbLK2rqiPB4iIzo+AXJsN6J3Hvu8DbX33///axevZpVq1axcOFCzj77bFavXr2vO+OsWbPo0aMHlZWVHH/88Vx00UWkpqY22cfGjRuZPXs2TzzxBJdccglz5szhyiv1LmxKqeDqUgk+HIwbN65JX/WHH36Y1157DYDt27ezcePGFgl+4MCBjBo1CoDjjjuO7OzsTotXKdV9dakE31ZJe83OYlJiI+mdHPxqj7i4uH3PFy5cyLx58/jiiy+IjY1l0qRJrfZlj4qK2vfc6/VSWVkZ9DiVUso9jaxBkpCQQGlpaavriouLSUlJITY2lvXr1/Pll192cnRKKdW2LlWC359gNbKmpqYyceJERowYQUxMDD179ty37qyzzuKxxx5j5MiRDB48mBNOOCFIUSilVMeJMcFKjR03duxY0/yGH+vWrWPo0KH7fd+ancUkx0bSpxOqaIKpPZ9VKaUaE5Hlxpixra1zRRWNQPCK8Eop1UW5IsHbFK8ZXimlGnNJgtf0rpRSzbkmwSullGrKHQleZ9pVSqkWgp7gRcQrIitF5O2gHSNYO1ZKqS6sM0rwNwPrgn6UTp5Nsj0eeughKioqDnNESinVPkFN8CKSBZwN/DuYxwkmTfBKqa4q2CNZHwJ+BSS0tYGIzABmAPTr1++gD9QZ0wWfeeaZZGRk8NJLL1FdXc33vvc97rvvPsrLy7nkkkvIycnB7/dzzz33kJuby86dOznttNNIS0tjwYIFQYpQKaVaF7QELyLnAHnGmOUiMqmt7YwxjwOPgx3Jut+dvncn7P6mxeL+NXV4PAIR3o4H2usYmHZ/m6sbTxc8d+5cXnnlFZYsWYIxhvPOO49PPvmE/Px8evfuzTvvvAPYOWqSkpJ44IEHWLBgAWlpaR2PSymlDlEwq2gmAueJSDbwAjBZRJ4N4vGCbu7cucydO5fRo0czZswY1q9fz8aNGznmmGOYN28ed9xxB59++ilJSUmhDlUppYJXgjfGzARmAjgl+NuMMYd2l4s2StrbdpUQFxVB3x6xh7T7AzHGMHPmTK6//voW65YvX867777LzJkzmTJlCr/5zW+CGotSSh2I9oM/gMbTBU+dOpVZs2ZRVlYGwI4dO8jLy2Pnzp3ExsZy5ZVXctttt7FixYoW71VKqc7WKdMFG2MWAguDeowg7bfxdMHTpk3j8ssvZ8KECQDEx8fz7LPPsmnTJm6//XY8Hg8+n49HH30UgBkzZjBt2jQyMzO1kVUp1elcMV3w+t0lxEZG0C/IVTTBptMFK6U6SqcLVkqpbsgVCV6nC1ZKqZa6RIJvTzVSV0/v4VRVppRyh7BP8NHR0RQWFro6ARpjKCwsJDo6OtShKKVcJOxvup2VlUVOTg75+fltbpNbUkWE10NFXmQnRnZ4RUdHk5WVFeowlFIuEvYJ3ufzMXDgwP1u8/MHPubIjHgevfLYTopKKaXCX9hX0bSHCLi4BkcppQ6KOxI8gunyzaxKKXV4uSPBawleKaVacEmCFwKa4JVSqgl3JHig6/eEV0qpw8sdCV6raJRSqgX3JPhQB6GUUmHGHQkecfVIV6WUOhjuSPBagldKqRZckuBF6+CVUqoZdyR4IKAZXimlmnBHgg/iPVmVUqqrckeCR7tJKqVUc+5I8KJz0SilVHPuSPBoCV4ppZpzR4LXkaxKKdWCSxK8VtEopVRz7kjwoLNJKqVUM+5I8IIOZVVKqWbckeD1jk5KKdWCOxK8NrIqpVQL7knwoQ5CKaXCjDsSvE4XrJRSLbgjwWsJXimlWnBJgtfpgpVSqjl3JHjQKhqllGrGHQleq2iUUqoFdyR4tJukUko1544Er3PRKKVUC+5I8GgJXimlmnNHgteRrEop1ULQEryIRIvIEhH5SkTWiMh9QTyWVtAopVQzEUHcdzUw2RhTJiI+4DMRec8Y8+XhPpB2k1RKqZaCluCNzbhlzkuf8y8oWViraJRSqqWg1sGLiFdEVgF5wIfGmMWtbDNDRJaJyLL8/PyDO45OF6yUUi0ENcEbY/zGmFFAFjBOREa0ss3jxpixxpix6enpB3UcLcErpVRLndKLxhhTBCwEzgrG/nUkq1JKtRTMXjTpIpLsPI8BzgDWB+VYOl2wUkq1EMxeNJnA0yLixZ5IXjLGvB2MA2kJXimlWgpmL5qvgdHB2n9jOl2wUkq15I6RrGg/eKWUas4dCV6raJRSqgV3JHi0m6RSSjXnjgSv0wUrpVQL7kjwaAleKaWac0WCR0eyKqVUC65I8B7RgU5KKdWcKxK8oL1olFKqOXckeK2iUUqpFtyR4HW6YKWUasEdCV5L8Eop1YJ7Enyog1BKqTDjigQPOtmYUko154oE7xHQMrxSSjXligQvAgHN70op1YQ7Erze0UkppVpwR4LXRlallGrBHQke7SaplFLNuSPB61w0SinVgisSPGgVjVJKNeeKBO/RSnillGrBFQnedpPUDK+UUo25I8GjBXillGquXQleRG4WkUSxnhSRFSIyJdjBtZdONqaUUi21twT/Y2NMCTAFSAeuAe4PWlQdpDfdVkqpltqb4MV5nA78xxjzVaNlIXdyzhOczMpQh6GUUmGlvQl+uYjMxSb4D0QkAQgEL6yOGb/7eU6Q1aEOQymlwkpEO7f7CTAK+M4YUyEiPbDVNGHBLz58xh/qMJRSKqy0twQ/AdhgjCkSkSuBu4Hi4IXVMQGPlwhqQx2GUkqFlfYm+EeBChE5FvgVsBV4JmhRdVBAfHiNX6crUEqpRtqb4OuMzZ7nA38zxvwNSAheWB0T8PjwSR01/rBpFlBKqZBrb4IvFZGZwFXAOyLiBXzBC6tjjMeHjzqq6zTBK6VUvfYm+EuBamx/+N1AH+AvQYuqg4wnAh9+ajTBK6XUPu1K8E5Sfw5IEpFzgCpjTNjUwRuPjwgtwSulVBPtnargEmAJ8H3gEmCxiFwczMA6xBtJJHVagldKqUba2w/+LuB4Y0wegIikA/OAV4IVWId4ffiooLpO+8IrpVS99tbBe+qTu6OwA+8NOuPxESFagldKqcbaW4J/X0Q+AGY7ry8F3g1OSB0nXu1Fo5RSzbUrwRtjbheRi4CJ2EnGHjfGvLa/94hIX+xgqF7YeWsed/rPH3bijcSHn3JN8EoptU97S/AYY+YAczqw7zrgVmPMCmdysuUi8qExZm1HgzwQiYh0SvBaB6+UUvX2m+BFpJTWb5YkgDHGJLb1XmPMLmCX87xURNZh+88f/gTv9RGh/eCVUqqJ/SZ4Y8xhmY5ARAYAo4HFh2N/LfbviyRStA5eKaUaC3pPGBGJx1bt3OLcFar5+hkiskxEluXn5x/UMTxOCb66VhO8UkrVC2qCFxEfNrk/Z4x5tbVtjDGPG2PGGmPGpqenH9RxvBFR+KijoqbuEKJVSil3aXcja0eJiABPAuuMMQ8E6zgA0dHR1FHH1j0VwTyMUkp1KcEswU/Ezj45WURWOf+mB+NA4vURKQE25pYFY/dKKdUlBa0Eb4z5jM66MXdkHFFUs/S7XDbllXJkRthMVa+UUiETNtMNHJL4DACSAiWs3FYU4mCUUio8uCTB9wQgXYq4/ZWvtT+8UkrhwgQPsGLb3lBGo5RSYcElCd5W0ZyVtA2A7dqbRimlXJLgE7MgvieXVb5IdvTl7MrdFeqIlFIq5NyR4D0euPTZfS+9O5aGMBillAoP7kjwAH3HwZn/A0DR1tVszC0NcUBKKRVa7knwABN/Tr63J9dGvMuvX1ke6miUUiqk3JXggcqJd9BTijhn96Nsy90T6nCUUipkXJfg+42/AICrve9T9NptIY5GKaVCx3UJnrjUfU8z8z4JYSBKKRVa7kvwABNuAiA9kE/2umUhDkYppULDnQl+6h/Y8cMv2UsCKS+cy8Yt34U6IqWU6nTuTPBAn0FDWTrpWRKoJOO5M2H3N1CyM9RhKaVUp3FtggeYMmkSf037HZF1ZfDYSfDAUNijpXmlVPfg6gQPED1sGnP9YxoWFGqCV0p1D65P8NefOohP0y9vWJC3Bl64Aop3hC4opZTqBK5P8FERXk4/9dSGBR/+Bta/DV/NDl1QSinVCVyf4AHOGJHVcqEnaHcrVEqpsNAtErzP6yH/Z+uY7T23YWFZbugCUkqpTtAtEjxAekZvBl32v9xacwOVvhQozgF/XcMGDx0Dix8PXYBKKXWYdZsEDzD+qN58lTadz6sGwLo34c8DYMdyqK2Eom3w3u2hDlEppQ6bbpXgAU46Mo1/1p3HlkBPqCmFr1+CCp11UinlPt0uwV978kCWm8GcVvMggZSBsPgx2PZFqMNSSqnDrtsl+KyUWJ68eiwA22OG2YVzfhLCiJRSKji6XYIHOG1wBmP7p3DudxfwdcqUpiuLcyD/W1j0MJTuhjd/buvolVKqixFjTKhj2Gfs2LFm2bLOmd63oKyaSX9ZSFl1HV/3+TOJhV+13CgyHmrK4KIn4ZiLOyUupZTqCBFZbowZ29q6blmCB0iLj2LJXaczMC2Oy6ruxJz3D/BGNt2opsw+1lV1foBKKXWIum2CB4iNjGDGKYNYW2iYG3Um3LoBftpKg+sbN8LaN+GbV+zrmnJ45zbtfaOUCmvdfrz+BaP68MKSbdz8wkrm3zqJPulDWt/wpavsozHw6rX2uS8GpvxP5wSqlFId1K1L8AAxkV4euWIM/oDhsse/YHdpDcz4GC57HvqMhal/bPqG+uQOUF3aucEqpVQHdPsED7br5FPXjCO3uJorn1zM55VZMORsuG4+TLgRbtsIlzzT8o3FOfDfC+GDu+zrj/8Cu1pprFVKqRDotr1oWnPnnK95Yel2AMYN7MG95w5jeO8ku9IYmP87+PKf0HccbPmk9Z1EJ8OdWxte7/kOygthbzaM/H7L7Wsr7dz0aUce3g+jlOoW9teLptvXwTc2c9pQUuMj2bC7jHnrcnl95Y6GBC8CZ9wLk+8BjweW/QfevqXlTqqK4MN74eRf2vvAPnV2w7ojJtu56FP6w6BJdtnLP4Jv34e78yAiKsifUCnVnWiCbyQp1sftU20j67l//4wnPt1CanwU10wcQFSE127kcWq1xlwNyX1hzxY7t3zjZL/oIXtDkeZTEu9cCW/93D6/bgH0GWOTO0DJDugxqGHbD38Dyf3heB1lq5Q6OFoH34bj+qcAcP9765l4/wLKquuabuDxwJFnwLjrYOw18PNVcPJtDetbm2/+uYsanj9xGqx5reF1ka0aomQXbF8Ci/4G7/xSu2IqpQ6aJvg23D51MHdNH8oNpx5BQVk1I+79gEcXbmZzfhmttlv0GAgn/j/oPQZ6HAEDToZRV9pqmba8/KOG5yufhR0r4KUfwpNnNix//pKD+wDZnzWd777etx/YaRjq7V4Nv02ybQVKKVfRRtYD8AcMVz25mM83F+5bdue0Idxw6hHt38mzF8GmeQfezhcLJtBy5OyMhbbOPzYVUgbAcVe3/v66apvAEzLhyTPglNth8t326iCxj73q+K3TpvDbYvv4zm2w9AmY+ieY8LMDx7jhPcgYauNQSoWcNrIeAq9HeO7a8XyxuZArnlyMMbbaJq+kmvNG9WZYZiKREQe4ELpyjn3010HpLnhoRNP1Zz8AS56A/HWtv//xSU1fJ/SCo6fa5ztX2fr6H8yGzx6CT/4XjvuRs24l7N0KfxtpX89Y2LCP3DXQczj4a+zriGbTNAAs/bdN6BfPgugkCPhh9mUQlwG3b9z/Z1ZKhVzQqmhEZJaI5InI6mAdo7OICCcemcaKu8/kgUuOBWDWoi1c8Mgijr77Papq/e3bkTfCNsxeOQeOvw7+3wo49gcw+kq4+s2G7U69A064sfW+92CrbXYsh3m/hcdPhS0fw4PDbXIHWP6UfazcC0sa3Ybw1RkNzx89EXLXgr/Wvg40+gzFOfD1y/DOrfbK45Wf2G3L8+368ryWMdVWwsvX2O13fwOFm9v+Hvy1dpbOgk1tb6OUOmRBq6IRkVOAMuAZY8yIA20P4VlF05wxhpeX5/CfRdms21UCwNThPXnw0lHERh7iBdH2JRCVYKtA6pXssvPVn3YXFG60ifPzh9vex8Ea/1MY/j3odQz8MbPl+sQ+UFXcMAHbtR9B71HgcXoXzZoG2z5v+p76aqDmtn0Js6ZC/4lwzbv2M3kj7cnvcFj0MAyeBmlHHZ79KRXG9ldFE9Q6eBEZALztpgTf2K9f+4bnF2/b93rCoFQG90rg0uP7MjQzMTgHNQY+vAc+/ztkjoJdqw7v/vuOh+2L27/9z1fZ7px/zGzZdvC9x+GI0+zVxtFn2bEEABveh9mX2udn3Q/v32mnZv7ZF3ZStwk32qqjnGUwYGLH4q8sgj/3h6S+8Isuf/GoDta3c6G6pFtM8x3WCV5EZgAzAPr163fc1q1b29o07Bhj+M+ibLILy1m0qYDN+eX71k0d3pPLx/fn5CPT8Hjk8B/cX2erfKpKbOJ87w5Y9RzEpcPNX9nRsZ8/bLtZnniTTdy/62Hfe/JtNuE+ecbhiWXUFfbY3siGOv3WDD4bTvipU710b8v1CZm2jeLYy8HrgxVP22qs1AM0aH87F75+ES76t+0N9PcxEJUIM7cf2ucKlS2f2P8vHfh28Jp3JnCxsE7wjXW1EnxjBWXVjP19y54yl47ti8cj3HX2UOKjgtymXVkE4oHoNq4eKvdCdRkk9rZVK/N+C589CANPaTr1wo/esb15opNsN8qUAVBbYe9w9fGfodhJnJe/1LQb5+UvwQuXQ6CV7pkH6wcv2Kqh4RfapC+tnCzr/5hn5tjG41lTbY+kM38HWWMhZaCdZiK2h+1V1F5VJYCx30O9ws2w9XMYc1XHPkdNOUTENAyUa0vuGts+cvx1cPZfO3YM1UATPKC9aA6btPgovpx5OilxPgbfbUenjhvQgxeX2WQ4e8k2fnTiAK4+cQAD0+KCE0RM8gHWp9h/9Sb/xnal3PqFbUSdcKPtt997VMM2mcc23cfSJ2yCH/sT25Nnyu9hrpM0+50AfY7rWBVPvcgEqGllds53fwXF2+DtX0Ktc4X0kw/tfED+OljxVMO2y5+C1U6PpdoKeNcZeNbvxIb2gZ7DbVtDcxV7oHCT3W+9vx5lr0ju3duw7InJdjqKkZe0v4Ttr4U/9rYN52f9cf/bVtl2HZ20bj92rLC/9cYjvzuLMbbwU9/2dKg2zYPkAUGbi0pL8EHwbW4pMT4vUT4P97y+mg/WNB3V+ptzhvHmVzsZ3DOBP188MkRRHqTiHNs1c+g59nX+BnhknO3xM+x8W8LNXWOT/4pn7ACu1toJfLE2CZ9+rz2hLP6XnbYhZSDs3bL/GAZPt1ch276E3IOsZ5+xEDbOs/t5o1H//wk32W6mm+bD+3fYZT+ea6eV8PoaSoa/XGff2x5F2+ChY+zz+hJl9mew8UPbznDMxXY0NMB3H8Mz59n2lQufgISeTa8gwF5JrXkNRlwMr/8Uzn/EbtddtKd0Xr/NvUWtX/UdrLn32KrP3+w98NVYW4pz7Elq2HmH5UojJFU0IjIbmASkAbnAvcaYJ/f3Hrck+NZ8sGY31/93eavrrp7QnzumDTn0XjihUlMBkbFtr68utSeCwk22bnn5U3DCz2xJf8jZtjS0+xt756zxP4XXb4D4Xjbx18/VEw6m/AHmOlNDT7gJpv6h6foP7oIvH7WNu95IO/Dsiclwym0NVxP1cxD9bVTTE1n9H/i6t+DFKyFtMBRsgH4T4Mfvw8L7ofdoe+J85nz4bqGttlrzKpz0SzsR3qHI/xa2Lmo40dRr/H8bCNg5kzrS2+nrl22J99hLDy2+eoWbbRsLtC/B/3onRLbjivnla2yhZcRFTZdvmg/xGbZ3WeP93pHd9Gq4I/5vKJTuhF/vauixFqQEH7SMYoz5QbD23RVNHd6L12+cSKTXw2srcwBYu6uERZsKefqLrXy2qYDhvZMYP6gHxZW1zF6yjaKKWhbdOZnEaF+Ioz+A/SV3sF0/s8bafwBn3mcfh53XsE2vY+D6T2zpFOCsP9nqktFXQdrRNrH0GQN56+w8PUPOhti0ht44jU2+Gz76fcvlPY+B3G86/vnq1Sd3gC/+YRuXn7vY9iLqPcpOJQ3wwFDIGgcjLoSy3Q1VWGDnIDr51pZXKf5ae0Xy4pX2dcEG+7jtCzvd9MI/2deDJtlSPkCR0yGhPSXU4h32CqQ4B9KHQES0jW3nStumsOK/UF1sE1x9G059b6frP7FVdYsfgw9mwo1LIH1w+76z+hvkNE/w/jrb0P7FP+CX6yGxla65jRkDn/wFFjQ6qVaVNG1vMgYKNkL60Q3Lqkttgq+ttIP2/DV2VPgF/2xovA8E7IlyzastE/yzF9rH5gl43n12VtiTfrH/uDd+aEvrJ/2iYTBh6U77WBj8wYJdtMjYNY3qa+vIh/Uetm9ZIGB4ZUUOd8z5ms355bz51c4m7xn527m8ddNJJMZE0D81SHX34SShV9M/pqQs+1j/R9vvBPuv3g9etFUYxm8bmQdPtwnviNMhY5i9Klj9iq2H/+Ebtl69qqj1Y4+8DLI/tSeTH75hE/Pu/ZwQHp1gH0t2tBwDkLPElrihofto1vGQsxQ+/b+W+/qftLaP85dGdc3fLWx4vnOlfawsssmttUS/aZ6dKgMaqsUGnGw/J9juqfVjGwAKvm04Ea97y/ksS22C/26Bfb19cfsTfFvevbVhQN7WRQ3dGT/6g62uuyPb9oiqr5uu3Ns0uYO9x0J9z7FTbrNVgvWztdarLrW/qfd+Zdd7ImwngE3zGhJ849/Dsln2t5PS336n9ebebdub6i3/j32ceIv93j+4y548zvqzfV1dYk+mzzmfq/doOHpK09jyNzQ8r9hjOwEcZjoXTZjYW16DL8LDIws28ejC1keBnjW8F5OHZpBXUsVVJwwgKTbMS/bhoLbK/gEn9LKvS3dDmTP3fsBv69FLd9lEl9zX/lFXFEJcmq0OePU6exXhjWxaV18vfQgk94ONcxsSaGuOON2OYH77lobENuEm2zW08ZXBoRj7EzjnAVtaffd2mzSfOb9j+0juD9fOt1VKa19vWN7rmIaT3aBJ9gRYU26/r9oKm9wS+9iT2bL/2KuFkZfA/f3se075FUTF2+1Oud22SRQ5Y0iO+b6t7hjzQ3jsJLvszN/ZXl43LbOJuGAj/KNZLcQlz9jJ+QB+/IG9D8P2L5tuc+1827D+h15Nl4+8DI69zCby8oKmE/yBbWPZ9ZWdmqPeHVvtGIvGbt3BbMEAABQGSURBVPgMeo6A+5wODt9/yl6dvHqt/Zyf/KVh24tn2Sq3B5yBjGN/AsucWuuBpzYdzd4BIesm2VHdOcE3V1JVy0tLt1NdF+Cr7UX4A4b565tOEXDdyQMJGHtyuG3qYDKTogkY2FNeQ3qC9qE+7L5baKdtuOFTe9m/+lUYeam9+XreOpss/ug0vJ5woy3FHX8tVO6BXiPtScNfZ3v6eLwNpda/DrbVJVP/ZKtA6k39I3zw69ZjScyCkpyWy4edD2vfaLk8JsWWgg+XYefbkdeluxqWxaU3TGexP32Os2Mh9ic2DSoKbHXbybfZqqr/TOt4nKf8CjJHNlR9HYrMY1vv3dTWd+uLc074ptmy8pbbwkE3CGuCd4lV24soraplWfZe/ja/Zf3diD6J7CqqorC8ho9uPZWMxGjioyIIBAx+Y/B5dXbooMtda6s8Gne3PJDSXDu/T69j7MyfhRttn/l+J9gS8mcP2C6Bc++xSf37T8Eb/892K73+Eztqd+8W26DbXFJfO9o4f11D6bhe41I5wDkPwttOnXK/CbYKqL56qccgW+f9izW2EbzxvQxCob0nk9a05wTTHj1HNO3Fdfq9MP++ptvEptr2leqS1vdx3I/sFVf/E+304t6O15prgneZQMCwq6QKn1dIivHxzOdbeXDet1TUtD7pWWpcJIXlNfzf949l2jG92FJQTnJsJH2SYzo5cnVIygttUssYYhvv1r8N5zzUUOory7NdViv3wgWP2a6TCZlN5zYqL4C/OHXP9VUcY662JfLIeJg1Bab/1V551FXbBF+511ZlBeoaeqQ8coI9Ed20zJ4I1r1pk/5Jv7R19FsXNY2992i73YSbbMMq2PmMvvi7fd+1H9lqjYxh9nMBeKPAX93ye5j2FzsFxj/G2kbR+rEP9X62GL59zzbuv3OrrV7LGmcbOlc+Y2+7+fS59qY8MSm2Sq6xxmM7oGGkNsC0/7XfQ+8xtkdY/jpn7qOzYNgFdvT1WzfbjgEF39oriOxP7RVIvYuehPdn2qQ/42P7/3kINMF3E9sKK6jx+5m1KJtvcorJLiintPmdqBr53ug+xEV5uem0o+iVFN2JkaqgqSq2ja4p/dveZtM8O+L5iMktG2cLNx94aoj643giGhJ+TYVN7EecZl8/MRkGnWZPLkPOBo/PJuvIODv+YPUc25PFX2PbRVL6294sHg+se9sOphtxkR0nkJQFL17RUGd/2WwYMt1Wl2QMs2MKUvrDw06jduNG+oDfftb9DU6q7/p4waP2qqbnCHtSK9pm3591nJ30r7biwN+NMbYqr98EWzUXl2Grmh4Zb9uCzv2bPWEYYzsG+A69kKUJvpuqrPGzq7iSpBgfuSXVrNpexOurdpCVEsOrK3a0+p7Th2QweWgGZw3vRY+4SORwDhJR6lAEArbEnD609UFGZU4bVXxGx/ZbsNEm2voeW8HSVk+nQ6QJXjVhjGFjXhn9esSSX1rNrS99xZLs1u/9+ttzhzFuYCr//XIrxhjuPXc4Hg8NNyFXSoWUJni1X7X+AGt2ljB/XS5FFbXsrajh7a93tbl9QlQEV584gOo6P4u37OFHJw6gT3IM4weldmLUSinQBK8OQl5JFXml1dQFDN/mlnJEejz/XLCJ+evzGJgWx5aCll29nr92PG9+tZOMxGgwhukjMxncM0GreZQKIk3w6rCo9QdYt6uEkVnJ5JVWUes3PL94K48saPv2fInREZRU1XHtSQO55cyjifF58QZjfnyluilN8Cpo6n8/+aXVPDhvI7uLK8kvqyYlNpJon5dvcorZXdL0Tk/HZiVhgPEDe/DjkwayaFMhNXUBLh/fj7LqOuIivVrqV6qdNMGrkKmpC/DQvG/558LNjOmXzLY9FRSU7eeuT8DRPeO5cEwW3+aWctGYLOKjIqgLGIZlJhITqY27SjWmCV6FlUDAMG9dLpW1fjbllbEsey9ffFdIj7hI9pS3nfwjPMKRGfGcOjgdrwg/O+1IlmbvISnGx5h+KWzMLUXEbqNUd6F3dFJhxeMRpgxvOvlTVa0fEaj1G7ILyimrrqOipo7731uPIGzILSUuKoL1u0tZv9ve+enDtblszLMzIQ5Kj+M75564F47uQ2KMj6tPHEBWSgw+r4ey6jq8InoFoLoVLcGrLqH+d7o5v4zckmpKq2r53VtrKa2q2+9oXYBj+iSRs7eCfqlxPHfteHYWVeIROCI9Xuv6VZenVTTK1V5fuYNnvsjmmx3FJMVE8trPTmTZ1j088OG3bN9TCUBGQhR5pU3nNYmL9GKAxGgft045mj7JMVT7A/TrEUtUhIddxVUcP+Dwz9Gt1OGkCV51W/6A4fPNBYzul8LTn2ezt7yGb3YUs3hL6yN3m/ve6D5Eej1MPCqNozLiqfUHiI+KoKy6jt7JMSRER+ioXhVSmuCVamZrYTm1fkNdIIAg3PvmaqrrAqzc1sbdnvbjlRsmcGRGPFsKyhncK4GoCO3rrzqPJnil2qmq1s/8dXlkJEYxNDORiuo6/MawfOteyqrqqPEHmLNiB19tbzgRiDS9u1u9jIQoTj4qneLKGuaty+NfVx3H1OG9KKqoYXdJFUdnJODRE4E6RJrglTrMHvt4MwJMHpLBvz/dwtY95WzOL2dMv2Q+WJPb5vsGpceRXVCOwZ4UEqIjOHNYT84f1YfqWj+9k2OIivBwVM+ETvssqmvTBK9UJ8otqSK3pAqf18P7q3fTMzGaf3y0kaLKWgLGMH1EJhvzyvhmR3Gb+4iK8JAY46N3cgyj+yaTGhfJoPR4TjoqjR17K3lv9S5uOeNovB6hzh9g254KBqVr///uSBO8UiFW/3dmjB0HEAgY1u4qYWBaHEWVtWzOK2PD7lJ2l1Sxekcx63aVUFK1/+6fwzITSUuI4rv8MnL2VnLBqN5cNWEAX20vondyNL2SYhjVN7kzPp4KIU3wSnUh9X+TVbUBvisoo0dcJPe8voZ563I5Z2QmO4sqWdGBxuDICA8Y+MWZR7NgQx4bdpdy29TBJMf4GD+oB9W1AWIivfSIjWRDbik+r3BkhlYRdRWa4JXq4gIBQ0Wtn/goO/h8+54KPlyby4QjUlm7s4Qpw3vy5Xd7eHj+RnaXVJFf2sq9TA/gojFZzFmRA8DY/ilcf+oRjOiTyJIte+jbI5ZAwDC8dxKb88uorvNzXH8dIxAONMEr1c2UVdcRHxXB1sJyKmv9FJTWsH53CaP6JlNe4+fNVTv3JfOje8bzbW5Zh49x+pAMvB4hZ28lV5/Yn7T4KCIjPNTUBTh9aE+WbNlDeXUd0T4vE45IJRAw2msoCDTBK6VaqKipo6iilt7JMVTV+rnvrTWkx0eRlhBFSWUtjyzYzKlHpzN+UA827C7lyIx4fv/Ounbt+4rx/Xhu8bZ9r8f0S6asuo4/XzSS5NhINuaWMmV4L4wxVDlVRG2pqvUT6fXoyaENmuCVUh1WVesn2tc08e4sqqSipo6U2Egenr+R/LJqqmsDiAi9k6NZlr2XtbtKOnysXonRAET5PGSlxHDCwFS+2VFMvx6xPL9kGxOPTOPBS0eRX1rNgNRYckuqqakL0C819rB81q5ME7xSqtMs2bKH2EgvfXvEsmNvJUN6JbCrpIrsgnIWbSrg1RU7iPZ5iPZ5980MOn5gDyK8QozPy9c5xS3mDQJ7L+DmE8uN6pvM9GN68f3j+hLt8/Lc4q0kxvhYuCGPs0ZkctbwXkRGeNhbXsMLS7dz7ckD8Xk9+94fCBjqAsY2RHdRmuCVUl1GWXUdc9fspldSNHvKaxjZJ5mfPrecNTtLiPF5ifAKpa10IY2K8FBdF2iyrPlJ4fLx/Vi6ZQ+j+yUzf10ehc79B/7n/OHMWbGD80f1ZvKQDPqnxu17T4Fzh7JwnX5CE7xSqkurqvWzpaCcIb3sTdwDAUNheQ17K2qY8uAnAJx7bG+OTI9n7trdxEZ6mTq8F2t2lvDayh0dPt7kIRks37qX+KgIdhVXkpkUwzkjM0lPiKKixs/QzESMsTeuiYzw8LvzRpBXWs3XOUVMGpxBhEc6rc1AE7xSyrWKKmqIjYxos5ql/uRQWlXHtj0VjOmXzNy1ueytqOG6kwcxZ3kO2YXlVNb42VVcRUFZNbuKq6io8dMnOYb8Mlvfvz/DeyeSs7eS4spaAAb3TOCIjDh2FlUR4/OSV1rFkRnxTBqcwdE9E0iKiSA5NpLYSC9rd5YwJDNxXxfYjtIEr5RSHWCMrZv3eT0EAob56/PonxrL7uIqslJi2F1SRc6eSs49tjezl2zjkQWbSIr1cWR6PF83utH8qL7JrNp+4EFpQ3olMOenJxJ3EEleE7xSSnUSf8CwctteMhKi6Zcay9LsPRgD2QXljOybxOa8cnJLqli9sxivCLGRXuKjI7h96pCDOp7ek1UppTqJ1yOMbXQnsPq7go0baB+H9ErstFi6bt8gpZRS+6UJXimlXEoTvFJKuVRQE7yInCUiG0Rkk4jcGcxjKaWUaipoCV5EvMAjwDRgGPADERkWrOMppZRqKpgl+HHAJmPMd8aYGuAF4PwgHk8ppVQjwUzwfYDtjV7nOMuaEJEZIrJMRJbl5+cHMRyllOpegpngW5uIocWoKmPM48aYscaYsenp6UEMRymlupdgDnTKAfo2ep0F7NzfG5YvX14gIlsP8nhpQMFBvrezdaVYoWvF25ViBY03mLpSrHDw8fZva0XQpioQkQjgW+B0YAewFLjcGLMmSMdb1tZw3XDTlWKFrhVvV4oVNN5g6kqxQnDiDVoJ3hhTJyI3AR8AXmBWsJK7UkqploI6F40x5l3g3WAeQymlVOvcNJL18VAH0AFdKVboWvF2pVhB4w2mrhQrBCHesJouWCml1OHjphK8UkqpRjTBK6WUS3X5BB+OE5qJyCwRyROR1Y2W9RCRD0Vko/OY4iwXEXnYif9rERnTybH2FZEFIrJORNaIyM1hHm+0iCwRka+ceO9zlg8UkcVOvC+KSKSzPMp5vclZP6Az43Vi8IrIShF5uwvEmi0i34jIKhFZ5iwL199Csoi8IiLrnd/vhDCOdbDzndb/KxGRW4IerzGmy/7Ddr/cDAwCIoGvgGFhENcpwBhgdaNl/wvc6Ty/E/iz83w68B525O8JwOJOjjUTGOM8T8COXRgWxvEKEO889wGLnTheAi5zlj8G/NR5/jPgMef5ZcCLIfg9/BJ4HnjbeR3OsWYDac2Whetv4WngWud5JJAcrrE2i9sL7MYOUApqvCH5gIfxi5oAfNDo9UxgZqjjcmIZ0CzBbwAyneeZwAbn+b+AH7S2XYjifgM4syvEC8QCK4Dx2BGAEc1/F9hxGBOc5xHOdtKJMWYB84HJwNvOH2xYxuoct7UEH3a/BSAR2NL8+wnHWFuJfQqwqDPi7epVNO2a0CxM9DTG7AJwHjOc5WHzGZwqgdHYUnHYxutUeawC8oAPsVdxRcaYulZi2hevs74YSO3EcB8CfgUEnNephG+sYOeLmisiy0VkhrMsHH8Lg4B84D9O9de/RSQuTGNt7jJgtvM8qPF29QTfrgnNwlxYfAYRiQfmALcYY0r2t2kryzo1XmOM3xgzCls6HgcM3U9MIYtXRM4B8owxyxsv3k88If9ugYnGmDHY+zjcKCKn7GfbUMYbga0GfdQYMxoox1ZxtCUcvluc9pbzgJcPtGkryzocb1dP8B2e0CyEckUkE8B5zHOWh/wziIgPm9yfM8a86iwO23jrGWOKgIXYOspksfMfNY9pX7zO+iRgTyeFOBE4T0SysfdDmIwt0YdjrAAYY3Y6j3nAa9gTaDj+FnKAHGPMYuf1K9iEH46xNjYNWGGMyXVeBzXerp7glwJHOb0SIrGXPm+GOKa2vAlc7Ty/GlvXXb/8h06r+QlAcf0lW2cQEQGeBNYZYx7oAvGmi0iy8zwGOANYBywALm4j3vrPcTHwkXEqNYPNGDPTGJNljBmA/W1+ZIy5IhxjBRCROBFJqH+OrSteTRj+Fowxu4HtIjLYWXQ6sDYcY23mBzRUz9THFbx4Q9HIcJgbLKZje35sBu4KdTxOTLOBXUAt9kz8E2xd6nxgo/PYw9lWsLc23Ax8A4zt5FhPwl76fQ2scv5ND+N4RwIrnXhXA79xlg8ClgCbsJe/Uc7yaOf1Jmf9oBD9JibR0IsmLGN14vrK+bem/u8pjH8Lo4Blzm/hdSAlXGN1YogFCoGkRsuCGq9OVaCUUi7V1atolFJKtUETvFJKuZQmeKWUcilN8Eop5VKa4JVSyqU0wSt1GIjIJHFmi1QqXGiCV0opl9IEr7oVEblS7Hzyq0TkX87EZWUi8n8iskJE5otIurPtKBH50pmP+7VGc3UfKSLzxM5Jv0JEjnB2H99ofvLnnFHCSoWMJnjVbYjIUOBS7IRaowA/cAUQh50fZAzwMXCv85ZngDuMMSOxownrlz8HPGKMORY4ETtqGexMnLdg59MfhJ2LRqmQiTjwJkq5xunAccBSp3Adg53cKQC86GzzLPCqiCQBycaYj53lTwMvO3O19DHGvAZgjKkCcPa3xBiT47xehb0nwGfB/1hKtU4TvOpOBHjaGDOzyUKRe5ptt7/5O/ZX7VLd6Lkf/ftSIaZVNKo7mQ9cLCIZsO9eo/2xfwf1szteDnxmjCkG9orIyc7yq4CPjZ0rP0dELnD2ESUisZ36KZRqJy1hqG7DGLNWRO7G3rHIg53t80bszSKGi8hy7F2ULnXecjXwmJPAvwOucZZfBfxLRH7n7OP7nfgxlGo3nU1SdXsiUmaMiQ91HEodblpFo5RSLqUleKWUciktwSullEtpgldKKZfSBK+UUi6lCV4ppVxKE7xSSrnU/webtZVhsyPLHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\ioann\\saved_models\\Emotion_Voice_Detection_Model_savee.h5 \n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "model_name = 'Emotion_Voice_Detection_Model_savee.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 69.89%\n"
     ]
    }
   ],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model_savee.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = loaded_model.predict(x_testcnn, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.72214621e-03, 1.82703659e-01, 2.72176549e-04, 4.33182548e-04,\n",
       "        1.72870189e-01, 6.33969069e-01, 2.96624530e-05],\n",
       "       [1.57671529e-05, 1.52465641e-01, 1.07902168e-04, 3.55773159e-06,\n",
       "        4.78269011e-01, 3.69129241e-01, 8.75446131e-06],\n",
       "       [1.84776320e-04, 6.77942753e-01, 5.96795289e-04, 8.89200674e-05,\n",
       "        5.22573129e-04, 3.20002943e-01, 6.61231286e-04],\n",
       "       [1.72843244e-02, 1.67673250e-04, 3.30005854e-01, 2.31451124e-01,\n",
       "        3.99381648e-08, 4.46521852e-07, 4.21090603e-01],\n",
       "       [1.89345464e-01, 2.01867819e-01, 5.26722968e-01, 2.73236800e-02,\n",
       "        6.90840650e-04, 3.82446265e-03, 5.02247848e-02],\n",
       "       [4.40858543e-01, 4.40986343e-02, 1.65767834e-01, 2.47645140e-01,\n",
       "        1.14709837e-03, 5.42592164e-03, 9.50568467e-02],\n",
       "       [5.34190112e-05, 9.23530012e-03, 1.34856487e-03, 4.30291620e-05,\n",
       "        3.97308111e-01, 5.91931581e-01, 7.99993941e-05],\n",
       "       [4.32703091e-04, 8.16606553e-05, 6.34886697e-02, 3.14998813e-02,\n",
       "        1.05991376e-07, 6.97563785e-09, 9.04496968e-01],\n",
       "       [3.57355297e-01, 9.52510256e-03, 5.40794013e-03, 6.02060199e-01,\n",
       "        2.33896080e-05, 4.69102059e-04, 2.51589511e-02],\n",
       "       [1.35203972e-01, 4.99377202e-04, 4.39410424e-03, 8.41110170e-01,\n",
       "        6.67357153e-06, 2.21301925e-05, 1.87634937e-02],\n",
       "       [3.69571649e-06, 5.74864773e-03, 2.94519964e-07, 2.77437891e-07,\n",
       "        9.93599415e-01, 6.47598936e-04, 6.23177385e-08],\n",
       "       [2.70689106e-05, 1.79833472e-01, 1.33253474e-04, 6.43053954e-06,\n",
       "        2.29177577e-03, 8.17691088e-01, 1.68377901e-05],\n",
       "       [7.37617552e-01, 2.88252644e-02, 1.99170876e-03, 2.15192214e-01,\n",
       "        6.83405524e-05, 3.22492087e-05, 1.62726529e-02],\n",
       "       [6.41939841e-05, 5.31697599e-03, 9.30159271e-01, 3.06940847e-03,\n",
       "        1.09968951e-07, 4.47045778e-07, 6.13896176e-02],\n",
       "       [3.99987176e-02, 1.10583060e-04, 1.39698815e-02, 4.61377978e-01,\n",
       "        1.05630944e-08, 1.10107557e-07, 4.84542668e-01],\n",
       "       [7.91783929e-01, 2.01056786e-02, 1.30223706e-01, 1.45434812e-02,\n",
       "        4.40915202e-04, 1.88914328e-05, 4.28833924e-02],\n",
       "       [1.48694208e-02, 3.89786856e-03, 4.15957645e-02, 3.81246269e-01,\n",
       "        6.86542171e-06, 7.74623113e-05, 5.58306396e-01],\n",
       "       [1.51070287e-06, 7.43691921e-02, 2.94261213e-07, 1.16266925e-07,\n",
       "        8.87689233e-01, 3.79397720e-02, 4.19489226e-08],\n",
       "       [9.61254776e-01, 3.51202004e-02, 7.96306085e-06, 2.92245066e-03,\n",
       "        6.25578163e-04, 6.98016675e-06, 6.22194784e-05],\n",
       "       [7.35266328e-01, 1.89365834e-01, 6.19137078e-04, 7.13778213e-02,\n",
       "        1.64700381e-04, 9.92357614e-04, 2.21380917e-03],\n",
       "       [4.62302560e-04, 6.94696382e-02, 7.01851604e-06, 7.88838006e-05,\n",
       "        9.26903367e-01, 3.07411072e-03, 4.74584613e-06],\n",
       "       [1.76697224e-03, 7.86449702e-04, 2.60056287e-01, 5.96261211e-02,\n",
       "        1.40798207e-07, 1.04842492e-07, 6.77763939e-01],\n",
       "       [1.47719996e-03, 2.28980818e-04, 1.22585528e-01, 3.15403938e-02,\n",
       "        3.23537321e-08, 2.61767036e-06, 8.44165206e-01],\n",
       "       [1.08522045e-05, 5.25998697e-02, 9.91037632e-06, 8.94451773e-07,\n",
       "        9.45482135e-01, 1.89555751e-03, 8.13046427e-07],\n",
       "       [2.09472364e-06, 1.94069522e-03, 2.75530255e-07, 7.89486023e-07,\n",
       "        6.53357685e-01, 3.44698280e-01, 4.02590423e-08],\n",
       "       [9.90186453e-01, 1.84098849e-06, 2.51097408e-05, 9.63976420e-03,\n",
       "        2.70837918e-11, 4.39717951e-08, 1.46776278e-04],\n",
       "       [6.80454314e-01, 2.40471348e-01, 3.84592004e-02, 1.33454166e-02,\n",
       "        1.24347408e-03, 4.59489785e-03, 2.14314032e-02],\n",
       "       [9.58483160e-01, 4.21439836e-06, 5.26984986e-05, 4.02263664e-02,\n",
       "        2.06598094e-09, 1.12080507e-07, 1.23341859e-03],\n",
       "       [8.29231343e-04, 2.27507623e-03, 1.14806397e-02, 1.59830888e-04,\n",
       "        3.61265347e-06, 9.84730065e-01, 5.21526090e-04],\n",
       "       [8.30868841e-04, 4.60634291e-01, 1.21289508e-04, 8.83428002e-05,\n",
       "        3.29345949e-02, 5.05371809e-01, 1.88183112e-05],\n",
       "       [2.06326913e-05, 3.69152501e-02, 5.18508705e-06, 2.46240029e-06,\n",
       "        1.52743030e-02, 9.47779655e-01, 2.51306551e-06],\n",
       "       [2.77286830e-07, 2.29478674e-03, 5.00845907e-08, 2.56562487e-08,\n",
       "        9.88689721e-01, 9.01524164e-03, 1.09083258e-08],\n",
       "       [2.07510951e-04, 5.13835810e-03, 1.80985796e-06, 2.11753413e-05,\n",
       "        8.92990768e-01, 1.01640143e-01, 2.64932197e-07],\n",
       "       [3.86760439e-06, 4.42671793e-04, 1.63707821e-08, 3.14581115e-07,\n",
       "        9.99472797e-01, 8.03496441e-05, 3.95490396e-09],\n",
       "       [4.50166881e-01, 1.48157205e-05, 1.46787934e-05, 5.49647272e-01,\n",
       "        4.77409623e-09, 1.64320696e-07, 1.56109658e-04],\n",
       "       [3.06477523e-06, 2.41929210e-05, 9.39095318e-01, 5.90029347e-04,\n",
       "        4.63210942e-10, 4.08697243e-10, 6.02874272e-02],\n",
       "       [6.09474318e-06, 2.54322857e-01, 8.41808742e-06, 6.19903631e-07,\n",
       "        6.24595940e-01, 1.21064618e-01, 1.47063838e-06],\n",
       "       [3.59715998e-01, 2.58976343e-05, 4.67431266e-04, 6.19686902e-01,\n",
       "        3.11927484e-09, 1.28559168e-06, 2.01025456e-02],\n",
       "       [5.21266181e-03, 4.63149786e-01, 1.72398277e-02, 2.42363076e-05,\n",
       "        1.96763515e-01, 3.16385984e-01, 1.22388254e-03],\n",
       "       [2.82155668e-08, 1.33244379e-03, 2.68934564e-08, 3.00323322e-08,\n",
       "        5.53936303e-01, 4.44731206e-01, 3.60031249e-09],\n",
       "       [3.39109392e-04, 4.33763489e-04, 3.89753878e-01, 2.80763526e-02,\n",
       "        2.50818533e-10, 7.25150448e-06, 5.81389606e-01],\n",
       "       [9.64710116e-01, 5.70666569e-04, 2.37756860e-04, 3.43685038e-02,\n",
       "        1.06220000e-07, 2.54842817e-05, 8.73496610e-05],\n",
       "       [5.39908709e-04, 9.07567859e-01, 2.36498749e-06, 1.99222104e-05,\n",
       "        8.69264528e-02, 4.93932748e-03, 4.17873889e-06],\n",
       "       [5.88397942e-02, 7.59317398e-01, 2.79368367e-02, 4.36716992e-03,\n",
       "        8.81189927e-02, 5.71669675e-02, 4.25287150e-03],\n",
       "       [5.42638684e-03, 3.59360361e-04, 6.13871845e-04, 7.19984472e-01,\n",
       "        9.89044624e-10, 1.84657665e-06, 2.73614019e-01],\n",
       "       [5.87639261e-05, 9.67462957e-01, 1.19512267e-02, 5.57758939e-03,\n",
       "        2.65286890e-05, 1.40945544e-04, 1.47819733e-02],\n",
       "       [4.58414899e-03, 5.95651984e-01, 1.74114339e-05, 2.55114195e-04,\n",
       "        3.95976663e-01, 3.48528218e-03, 2.94042911e-05],\n",
       "       [3.12452464e-08, 7.07306387e-03, 1.98220221e-07, 7.54956631e-08,\n",
       "        9.68996882e-01, 2.39296351e-02, 7.97563473e-08],\n",
       "       [5.94377987e-08, 7.68208679e-08, 5.57380132e-02, 1.57725444e-05,\n",
       "        1.64250002e-09, 3.51850428e-12, 9.44245994e-01],\n",
       "       [1.79092124e-01, 3.65877058e-03, 1.99906781e-01, 2.76512027e-01,\n",
       "        8.57669022e-07, 2.41507863e-04, 3.40588033e-01],\n",
       "       [4.38864017e-03, 2.26820335e-01, 5.00011607e-04, 2.80782301e-03,\n",
       "        5.81902146e-01, 1.81565911e-01, 2.01519579e-03],\n",
       "       [6.80857524e-03, 2.19883189e-01, 4.96775378e-03, 6.94765709e-04,\n",
       "        2.90120602e-01, 4.77479368e-01, 4.57090173e-05],\n",
       "       [4.14342340e-03, 9.61185694e-01, 6.04317349e-04, 3.60251470e-05,\n",
       "        3.30980197e-02, 7.76233210e-04, 1.56438953e-04],\n",
       "       [4.51041125e-02, 5.88643318e-03, 4.17189859e-02, 2.85847187e-01,\n",
       "        1.28838601e-05, 1.37998752e-04, 6.21292412e-01],\n",
       "       [3.11037116e-02, 9.30377185e-01, 1.65048186e-04, 1.46748964e-02,\n",
       "        4.83798236e-03, 1.77984685e-02, 1.04277662e-03],\n",
       "       [2.24110112e-01, 2.33667344e-03, 1.26795815e-02, 7.35795557e-01,\n",
       "        1.59060917e-07, 2.66743009e-03, 2.24104151e-02],\n",
       "       [3.84969682e-01, 3.09596973e-04, 6.38175476e-03, 3.83267403e-01,\n",
       "        3.38585764e-08, 2.85287251e-06, 2.25068793e-01],\n",
       "       [2.32959865e-04, 8.46654326e-02, 1.54796408e-06, 1.15289720e-06,\n",
       "        9.12304878e-01, 2.79387250e-03, 1.18115111e-07],\n",
       "       [9.06805290e-05, 5.39743364e-01, 2.21094433e-05, 2.50116245e-05,\n",
       "        4.58409429e-01, 1.61361799e-03, 9.57160009e-05],\n",
       "       [5.02337627e-02, 4.43605557e-02, 2.50229407e-02, 7.16743231e-01,\n",
       "        1.05293147e-04, 1.39118376e-04, 1.63395062e-01],\n",
       "       [7.68324211e-02, 4.68832925e-02, 7.65489312e-05, 1.12057729e-02,\n",
       "        7.02632129e-01, 1.62317470e-01, 5.23474082e-05],\n",
       "       [4.19532806e-01, 3.19797009e-01, 1.28090560e-01, 1.83796622e-02,\n",
       "        2.77991295e-02, 8.07986483e-02, 5.60229877e-03],\n",
       "       [1.35567689e-07, 2.24878065e-07, 9.86202300e-01, 7.25155987e-04,\n",
       "        1.96371201e-11, 1.78158703e-11, 1.30722355e-02],\n",
       "       [5.98360384e-06, 3.16524936e-04, 1.23693585e-01, 7.47980131e-03,\n",
       "        4.05476708e-10, 1.33148715e-04, 8.68370891e-01],\n",
       "       [1.04978405e-01, 3.52441669e-01, 9.27318888e-06, 4.60482930e-04,\n",
       "        5.12720406e-01, 2.93859839e-02, 3.81178234e-06],\n",
       "       [1.12195676e-02, 3.08049135e-02, 1.17751015e-02, 8.05110931e-01,\n",
       "        7.60241746e-05, 1.08002685e-03, 1.39933452e-01],\n",
       "       [1.72506207e-05, 2.76796389e-02, 1.53391341e-06, 4.16948787e-05,\n",
       "        9.69474852e-01, 2.78294622e-03, 2.03970058e-06],\n",
       "       [9.96498624e-04, 1.83632108e-06, 8.38614404e-01, 3.45896371e-02,\n",
       "        5.86903200e-15, 5.84826048e-05, 1.25739202e-01],\n",
       "       [1.65284975e-04, 1.94250587e-02, 7.96775877e-01, 4.76610567e-03,\n",
       "        2.34096067e-08, 5.82448691e-02, 1.20622836e-01],\n",
       "       [4.67466634e-05, 2.38372759e-05, 2.14963645e-01, 5.76573946e-02,\n",
       "        1.83404003e-09, 1.68856584e-09, 7.27308333e-01],\n",
       "       [1.10297808e-02, 1.23474263e-01, 3.41263674e-02, 1.29644396e-02,\n",
       "        7.97054470e-01, 1.79632343e-02, 3.38745676e-03],\n",
       "       [1.89191883e-03, 1.04311027e-01, 3.30308010e-03, 2.48207041e-04,\n",
       "        7.59106994e-01, 1.30401984e-01, 7.36812595e-04],\n",
       "       [5.24159931e-02, 1.68948458e-03, 4.37398329e-02, 8.08568299e-02,\n",
       "        2.00697443e-07, 1.85916142e-05, 8.21279109e-01],\n",
       "       [2.94850353e-04, 3.01680379e-02, 7.57302344e-01, 1.23746870e-02,\n",
       "        5.98088377e-07, 6.73768052e-04, 1.99185684e-01],\n",
       "       [3.66637755e-06, 1.51105609e-03, 6.05599098e-07, 8.51204095e-06,\n",
       "        7.80858994e-01, 2.17617095e-01, 1.22301429e-07],\n",
       "       [1.54526720e-06, 1.71457231e-02, 1.36893359e-05, 2.43403224e-06,\n",
       "        8.70097935e-01, 1.12737104e-01, 1.52992186e-06],\n",
       "       [4.52837721e-03, 2.39912816e-03, 2.12991118e-01, 4.73179445e-02,\n",
       "        2.38789517e-06, 5.20629214e-07, 7.32760549e-01],\n",
       "       [1.23571704e-06, 3.02200504e-02, 6.82688153e-07, 5.06520230e-08,\n",
       "        9.45023537e-01, 2.47545149e-02, 2.01926103e-08],\n",
       "       [5.21703303e-01, 3.89641345e-01, 3.20724025e-03, 2.14902256e-02,\n",
       "        2.85294984e-04, 5.96308783e-02, 4.04173089e-03],\n",
       "       [2.12002732e-03, 1.58241228e-03, 1.09025789e-02, 5.78232884e-01,\n",
       "        1.14615943e-06, 5.24734787e-06, 4.07155722e-01],\n",
       "       [6.42024361e-06, 2.13693038e-01, 2.31805700e-03, 1.80193474e-05,\n",
       "        5.70414662e-01, 2.13367730e-01, 1.82015690e-04],\n",
       "       [6.12480198e-06, 6.65490297e-05, 3.37562352e-01, 3.41352867e-03,\n",
       "        5.63412925e-08, 3.21165561e-09, 6.58951402e-01],\n",
       "       [4.99018352e-04, 1.50963869e-02, 4.67952450e-05, 5.35476545e-04,\n",
       "        6.04013622e-01, 3.79795790e-01, 1.29124455e-05],\n",
       "       [3.43406640e-07, 4.50394168e-07, 9.10160720e-01, 8.67524445e-02,\n",
       "        6.97379437e-14, 1.08853322e-10, 3.08600836e-03],\n",
       "       [8.44190617e-06, 3.15583078e-04, 6.25792384e-01, 8.34342465e-03,\n",
       "        4.17310027e-08, 7.88260905e-08, 3.65539998e-01],\n",
       "       [1.46133561e-05, 6.21912815e-03, 1.71555044e-07, 2.53283952e-06,\n",
       "        9.93206143e-01, 5.57250751e-04, 1.06395255e-07],\n",
       "       [1.07484218e-02, 3.91323984e-01, 2.35281348e-01, 1.41830640e-02,\n",
       "        1.21079184e-01, 1.85160056e-01, 4.22239006e-02],\n",
       "       [1.59066603e-01, 1.64048359e-01, 1.78082377e-01, 1.10301398e-01,\n",
       "        3.37318093e-01, 4.67781201e-02, 4.40500304e-03],\n",
       "       [1.55642501e-05, 1.00913839e-02, 7.00952853e-07, 5.56102918e-07,\n",
       "        9.88527656e-01, 1.36403134e-03, 8.13603194e-08],\n",
       "       [2.43420567e-04, 1.38919117e-04, 1.11924827e-01, 9.28520188e-02,\n",
       "        1.74476220e-08, 6.11683717e-08, 7.94840753e-01],\n",
       "       [9.97070789e-01, 1.97673739e-06, 9.85299812e-06, 2.88436748e-03,\n",
       "        1.06664855e-08, 8.79018386e-11, 3.29286340e-05],\n",
       "       [4.06071922e-06, 5.11429331e-04, 1.76831643e-04, 6.11850646e-06,\n",
       "        3.25434115e-07, 9.99258101e-01, 4.30966575e-05],\n",
       "       [1.91953313e-03, 1.46901139e-05, 1.30420923e-01, 4.36870800e-03,\n",
       "        2.61473274e-11, 8.61149311e-01, 2.12684716e-03]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 1, 6, 2, 0, 5, 6, 3, 3, 4, 5, 0, 2, 6, 0, 6, 4, 0, 0, 4, 6,\n",
       "       6, 4, 4, 0, 0, 0, 5, 5, 5, 4, 4, 4, 3, 2, 4, 3, 1, 4, 6, 0, 1, 1,\n",
       "       3, 1, 1, 4, 6, 6, 4, 5, 1, 6, 1, 3, 0, 4, 1, 3, 4, 0, 2, 6, 4, 3,\n",
       "       4, 2, 2, 6, 4, 4, 6, 2, 4, 4, 6, 4, 0, 3, 4, 6, 4, 2, 2, 4, 1, 4,\n",
       "       4, 6, 0, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1=preds.argmax(axis=1)\n",
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = preds1.astype(int).flatten()\n",
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgusted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predictedvalues\n",
       "0             sad\n",
       "1         neutral\n",
       "2       disgusted\n",
       "3       surprised\n",
       "4         fearful\n",
       "5           angry\n",
       "6             sad\n",
       "7       surprised\n",
       "8           happy\n",
       "9           happy"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgusted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actualvalues\n",
       "0      neutral\n",
       "1      neutral\n",
       "2    disgusted\n",
       "3    surprised\n",
       "4      fearful\n",
       "5      fearful\n",
       "6      neutral\n",
       "7    surprised\n",
       "8        happy\n",
       "9        angry"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgusted</td>\n",
       "      <td>disgusted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprised</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fearful</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neutral</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>surprised</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>angry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fearful</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>happy</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>disgusted</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>disgusted</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>surprised</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>happy</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>surprised</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>disgusted</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>surprised</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>fearful</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>sad</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>surprised</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>sad</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>fearful</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>sad</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>surprised</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>fearful</td>\n",
       "      <td>disgusted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>fearful</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>surprised</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   actualvalues predictedvalues\n",
       "0       neutral             sad\n",
       "1       neutral         neutral\n",
       "2     disgusted       disgusted\n",
       "3     surprised       surprised\n",
       "4       fearful         fearful\n",
       "5       fearful           angry\n",
       "6       neutral             sad\n",
       "7     surprised       surprised\n",
       "8         happy           happy\n",
       "9         angry           happy\n",
       "10      neutral         neutral\n",
       "11          sad             sad\n",
       "12        angry           angry\n",
       "13      fearful         fearful\n",
       "14      fearful       surprised\n",
       "15        angry           angry\n",
       "16        happy       surprised\n",
       "17    disgusted         neutral\n",
       "18        angry           angry\n",
       "19    disgusted           angry\n",
       "20      neutral         neutral\n",
       "21    surprised       surprised\n",
       "22        happy       surprised\n",
       "23      neutral         neutral\n",
       "24      neutral         neutral\n",
       "25        angry           angry\n",
       "26        angry           angry\n",
       "27        angry           angry\n",
       "28          sad             sad\n",
       "29          sad             sad\n",
       "..          ...             ...\n",
       "63    surprised       surprised\n",
       "64    disgusted         neutral\n",
       "65        happy           happy\n",
       "66      neutral         neutral\n",
       "67      fearful         fearful\n",
       "68      fearful         fearful\n",
       "69    surprised       surprised\n",
       "70      neutral         neutral\n",
       "71      neutral         neutral\n",
       "72      fearful       surprised\n",
       "73      fearful         fearful\n",
       "74          sad         neutral\n",
       "75      neutral         neutral\n",
       "76    surprised       surprised\n",
       "77      neutral         neutral\n",
       "78          sad           angry\n",
       "79        happy           happy\n",
       "80      neutral         neutral\n",
       "81      fearful       surprised\n",
       "82          sad         neutral\n",
       "83      fearful         fearful\n",
       "84    surprised         fearful\n",
       "85      neutral         neutral\n",
       "86      fearful       disgusted\n",
       "87      fearful         neutral\n",
       "88      neutral         neutral\n",
       "89    surprised       surprised\n",
       "90        angry           angry\n",
       "91          sad             sad\n",
       "92          sad             sad\n",
       "\n",
       "[93 rows x 2 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actualvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgusted</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fearful</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprised</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predictedvalues\n",
       "actualvalues                 \n",
       "angry                      10\n",
       "disgusted                  12\n",
       "fearful                    16\n",
       "happy                      10\n",
       "neutral                    23\n",
       "sad                        12\n",
       "surprised                  10"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('actualvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictedvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgusted</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fearful</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprised</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 actualvalues\n",
       "predictedvalues              \n",
       "angry                      13\n",
       "disgusted                  10\n",
       "fearful                     9\n",
       "happy                       9\n",
       "neutral                    27\n",
       "sad                         9\n",
       "surprised                  16"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
