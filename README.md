# Speech-Emotion-Recognition-through-machine-learning-and-signal-processing
Human uses speech as a basic mean of communication. Through speech 
emotions are expressed. Automatic Recognition of human emotion is a fascinating and 
a challenging task. The need for a reliable speech emotion recognition is imperative for 
our everyday life and the human computer interaction.
In present master’s thesis, a deep learning model is built for speech emotion 
recognition. The databases that are used for the training and the evaluation of the 
models are: the Ryerson Audio-Visual Database of Emotional Speech and Song or 
RAVDESS, the Interactive Emotional Dyadic Motion Capture or IEMOCAP and a 
combination of them. Convolutional neural networks are chosen as the classification 
method. 
From the evaluation of the models, it’s clear that the results are comparable with 
the state of the art.
